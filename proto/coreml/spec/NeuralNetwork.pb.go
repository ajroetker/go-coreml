// Copyright (c) 2017-2019, Apple Inc. All rights reserved.
//
// Use of this source code is governed by a BSD-3-clause license that can be
// found in LICENSE.txt or at https://opensource.org/licenses/BSD-3-Clause

//
// A neural network is defined through a collection of layers
// and represents a directed acyclic graph (DAG).
// Each layer has a name, a layer type,
// a list of input names, a list of output names,
// and a collection of parameters specific to the layer type.
//
// The graph structure and connectivity of the neural network
// is inferred from the input and output names.
// A neural network starts with the layer
// whose input name is equal to the value specified in
// ``Model.description.input.name``,
// and ends with the layer
// whose output name is equal to the value specified in
// ``Model.description.output.name``.
// Layers must have unique input and output names,
// and a layer may not have input or output names that
// refer to layers that are not yet defined.
//
// For Core ML specification version <=3,
// all inputs are mapped to static rank 5 tensors, with axis notations
// [Sequence, Batch, Channel, Height, Width].
//
// From specification version 4 onwards (iOS >= 13, macOS >= 10.15), more options are available
// (see enums ``NeuralNetworkMultiArrayShapeMapping``, ``NeuralNetworkImageShapeMapping``)
// to map inputs to generic N-Dimensional (or N rank) tensors, where N >= 1.
//
// Each layer type may have specific constraints on the ranks of its inputs and outputs.
//
// Some of the layers (such as softmax, reduce, etc) have parameters that have been described in
// terms of notational axis "Channel", "Height", "Width" or "Sequence". They can be re-interpreted easily in
// the general ND setting by using the following rule:
// "width" is same as axis = -1 (i.e. the last axis from the end)
// "height" is same as axis = -2 (i.e. the second last axis from the end)
// "channel" is same as axis = -3 (i.e. the third last axis from the end)
// "sequence" is same as axis = -5 (i.e. the fifth last axis from the end)
//
// Several layers are available in 3 different variations, with the names ending
// in identifiers: ``like``, ``static`` and ``dynamic``. For instance, ``FillLike``,
// ``FillStatic`` and ``FillDynamic``. The ``static`` variation generally will have
// a property corresponding to the shape of the output. For instance, if the
// output of the ``FillStatic`` layer is desired to be of shape (10, 4), the
// property ``targetShape`` will have to be set to [10, 4]. In the ``dynamic`` case,
// the shape is an input, hence it can be changed at runtime. For instance, for
// a ``FillDynamic`` layer, the input would have to be an array containing the
// values 10 and 4, if the desired output is of shape (10, 4). Whereas in the
// ``like`` case, the additional input's shape is used as the output shape, ignoring
// its values. For instance, for a ``FillLike`` layer, for an input with shape
// (10, 4), the output generated will also be of shape (10, 4), values of the
// input will be ignored.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v6.33.2
// source: NeuralNetwork.proto

package spec

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type NeuralNetworkMultiArrayShapeMapping int32

const (
	// Default legacy value. Only supported for Core ML Specification version <= 3.
	//
	// The default legacy shape mapping resolves all input shapes to a rank 5 equivalent
	// with axis notation of [Seq, Batch, Channel, Height, Width].
	//
	// When this enum value is selected,
	// the repeated shape field in the message "ArrayFeatureType" in feature types proto,
	// must be either length 1 or length 3.
	//
	// The following rule is used to map the values in the shape field to the actual tensor shape:
	// rank 1 shape is mapped to shape [1,1,C,1,1]
	// rank 3 shape is mapped to shape [1,1,C,H,W]
	// At runtime, the first two dimensions (Seq or Batch) can be presented as well, with non-1 values.
	//
	// It is invalid to use this enum value if any of the layers added
	// Specification version 4 (iOS >= 13, macOS >= 10.15) onwards are used in the network.
	// Validator will raise an error in that case.
	NeuralNetworkMultiArrayShapeMapping_RANK5_ARRAY_MAPPING NeuralNetworkMultiArrayShapeMapping = 0
	// The exact shape and rank (i.e. number of dimensions in the shape) of the input,
	// as specified in the message "ArrayFeatureType", is passed through to the layers.
	// Supported only for Specification version >= 4 (iOS >= 13, macOS >= 10.15).
	NeuralNetworkMultiArrayShapeMapping_EXACT_ARRAY_MAPPING NeuralNetworkMultiArrayShapeMapping = 1
)

// Enum value maps for NeuralNetworkMultiArrayShapeMapping.
var (
	NeuralNetworkMultiArrayShapeMapping_name = map[int32]string{
		0: "RANK5_ARRAY_MAPPING",
		1: "EXACT_ARRAY_MAPPING",
	}
	NeuralNetworkMultiArrayShapeMapping_value = map[string]int32{
		"RANK5_ARRAY_MAPPING": 0,
		"EXACT_ARRAY_MAPPING": 1,
	}
)

func (x NeuralNetworkMultiArrayShapeMapping) Enum() *NeuralNetworkMultiArrayShapeMapping {
	p := new(NeuralNetworkMultiArrayShapeMapping)
	*p = x
	return p
}

func (x NeuralNetworkMultiArrayShapeMapping) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (NeuralNetworkMultiArrayShapeMapping) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[0].Descriptor()
}

func (NeuralNetworkMultiArrayShapeMapping) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[0]
}

func (x NeuralNetworkMultiArrayShapeMapping) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use NeuralNetworkMultiArrayShapeMapping.Descriptor instead.
func (NeuralNetworkMultiArrayShapeMapping) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{0}
}

type NeuralNetworkImageShapeMapping int32

const (
	// In this case, image input is mapped to a rank 5 tensor.
	// For Color images, input tensor is shaped as [1,1,3,H,W].
	// For Gray images, input tensor is shaped as [1,1,1,H,W].
	NeuralNetworkImageShapeMapping_RANK5_IMAGE_MAPPING NeuralNetworkImageShapeMapping = 0
	// For Color images, input tensor is shaped as [1,3,H,W].
	// For Gray images, input tensor is shaped as [1,1,H,W].
	// Supported only for Specification version >= 4 (iOS >= 13, macOS >= 10.15).
	NeuralNetworkImageShapeMapping_RANK4_IMAGE_MAPPING NeuralNetworkImageShapeMapping = 1
)

// Enum value maps for NeuralNetworkImageShapeMapping.
var (
	NeuralNetworkImageShapeMapping_name = map[int32]string{
		0: "RANK5_IMAGE_MAPPING",
		1: "RANK4_IMAGE_MAPPING",
	}
	NeuralNetworkImageShapeMapping_value = map[string]int32{
		"RANK5_IMAGE_MAPPING": 0,
		"RANK4_IMAGE_MAPPING": 1,
	}
)

func (x NeuralNetworkImageShapeMapping) Enum() *NeuralNetworkImageShapeMapping {
	p := new(NeuralNetworkImageShapeMapping)
	*p = x
	return p
}

func (x NeuralNetworkImageShapeMapping) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (NeuralNetworkImageShapeMapping) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[1].Descriptor()
}

func (NeuralNetworkImageShapeMapping) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[1]
}

func (x NeuralNetworkImageShapeMapping) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use NeuralNetworkImageShapeMapping.Descriptor instead.
func (NeuralNetworkImageShapeMapping) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{1}
}

// Scatter accumulation mode.
type ScatterMode int32

const (
	ScatterMode_SCATTER_UPDATE ScatterMode = 0
	ScatterMode_SCATTER_ADD    ScatterMode = 1 // add
	ScatterMode_SCATTER_SUB    ScatterMode = 2 // subtract
	ScatterMode_SCATTER_MUL    ScatterMode = 3 // multiply
	ScatterMode_SCATTER_DIV    ScatterMode = 4 // divide
	ScatterMode_SCATTER_MAX    ScatterMode = 5 // maximum
	ScatterMode_SCATTER_MIN    ScatterMode = 6 // minimum
)

// Enum value maps for ScatterMode.
var (
	ScatterMode_name = map[int32]string{
		0: "SCATTER_UPDATE",
		1: "SCATTER_ADD",
		2: "SCATTER_SUB",
		3: "SCATTER_MUL",
		4: "SCATTER_DIV",
		5: "SCATTER_MAX",
		6: "SCATTER_MIN",
	}
	ScatterMode_value = map[string]int32{
		"SCATTER_UPDATE": 0,
		"SCATTER_ADD":    1,
		"SCATTER_SUB":    2,
		"SCATTER_MUL":    3,
		"SCATTER_DIV":    4,
		"SCATTER_MAX":    5,
		"SCATTER_MIN":    6,
	}
)

func (x ScatterMode) Enum() *ScatterMode {
	p := new(ScatterMode)
	*p = x
	return p
}

func (x ScatterMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ScatterMode) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[2].Descriptor()
}

func (ScatterMode) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[2]
}

func (x ScatterMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ScatterMode.Descriptor instead.
func (ScatterMode) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{2}
}

type SamePadding_SamePaddingMode int32

const (
	SamePadding_BOTTOM_RIGHT_HEAVY SamePadding_SamePaddingMode = 0
	SamePadding_TOP_LEFT_HEAVY     SamePadding_SamePaddingMode = 1
)

// Enum value maps for SamePadding_SamePaddingMode.
var (
	SamePadding_SamePaddingMode_name = map[int32]string{
		0: "BOTTOM_RIGHT_HEAVY",
		1: "TOP_LEFT_HEAVY",
	}
	SamePadding_SamePaddingMode_value = map[string]int32{
		"BOTTOM_RIGHT_HEAVY": 0,
		"TOP_LEFT_HEAVY":     1,
	}
)

func (x SamePadding_SamePaddingMode) Enum() *SamePadding_SamePaddingMode {
	p := new(SamePadding_SamePaddingMode)
	*p = x
	return p
}

func (x SamePadding_SamePaddingMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SamePadding_SamePaddingMode) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[3].Descriptor()
}

func (SamePadding_SamePaddingMode) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[3]
}

func (x SamePadding_SamePaddingMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SamePadding_SamePaddingMode.Descriptor instead.
func (SamePadding_SamePaddingMode) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{37, 0}
}

type SamplingMode_Method int32

const (
	// start = 0, end = X-1
	// grid points = numpy.linspace(start, end)
	SamplingMode_STRICT_ALIGN_ENDPOINTS_MODE SamplingMode_Method = 0
	// if N == 1: start = end = (X-1)/2
	// otherwise, start = 0, end = X-1
	// grid points = numpy.linspace(start, end)
	SamplingMode_ALIGN_ENDPOINTS_MODE SamplingMode_Method = 1
	// start = 0, end = X - X/N
	// grid points = min(X-1, numpy.linspace(start, end))
	// This is same as the mode used in the upsample layer in this specification, when used with bilinear interpolation. In that case N/X = upsample ratio.
	SamplingMode_UPSAMPLE_MODE SamplingMode_Method = 2
	// spacing = max(1, X-1)/N
	// start = 0.5 * spacing
	// end = start + (N-1) * spacing
	// grid points = min(X-1, numpy.linspace(start, end))
	SamplingMode_ROI_ALIGN_MODE SamplingMode_Method = 3
)

// Enum value maps for SamplingMode_Method.
var (
	SamplingMode_Method_name = map[int32]string{
		0: "STRICT_ALIGN_ENDPOINTS_MODE",
		1: "ALIGN_ENDPOINTS_MODE",
		2: "UPSAMPLE_MODE",
		3: "ROI_ALIGN_MODE",
	}
	SamplingMode_Method_value = map[string]int32{
		"STRICT_ALIGN_ENDPOINTS_MODE": 0,
		"ALIGN_ENDPOINTS_MODE":        1,
		"UPSAMPLE_MODE":               2,
		"ROI_ALIGN_MODE":              3,
	}
)

func (x SamplingMode_Method) Enum() *SamplingMode_Method {
	p := new(SamplingMode_Method)
	*p = x
	return p
}

func (x SamplingMode_Method) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SamplingMode_Method) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[4].Descriptor()
}

func (SamplingMode_Method) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[4]
}

func (x SamplingMode_Method) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SamplingMode_Method.Descriptor instead.
func (SamplingMode_Method) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{38, 0}
}

type BoxCoordinatesMode_Coordinates int32

const (
	// [h_start, w_start, h_end, w_end]
	BoxCoordinatesMode_CORNERS_HEIGHT_FIRST BoxCoordinatesMode_Coordinates = 0
	// [w_start, h_start, w_end, h_end]
	BoxCoordinatesMode_CORNERS_WIDTH_FIRST BoxCoordinatesMode_Coordinates = 1
	// [h_center, w_center, box_height, box_width]
	BoxCoordinatesMode_CENTER_SIZE_HEIGHT_FIRST BoxCoordinatesMode_Coordinates = 2
	// [w_center, h_center, box_width, box_height]
	BoxCoordinatesMode_CENTER_SIZE_WIDTH_FIRST BoxCoordinatesMode_Coordinates = 3
)

// Enum value maps for BoxCoordinatesMode_Coordinates.
var (
	BoxCoordinatesMode_Coordinates_name = map[int32]string{
		0: "CORNERS_HEIGHT_FIRST",
		1: "CORNERS_WIDTH_FIRST",
		2: "CENTER_SIZE_HEIGHT_FIRST",
		3: "CENTER_SIZE_WIDTH_FIRST",
	}
	BoxCoordinatesMode_Coordinates_value = map[string]int32{
		"CORNERS_HEIGHT_FIRST":     0,
		"CORNERS_WIDTH_FIRST":      1,
		"CENTER_SIZE_HEIGHT_FIRST": 2,
		"CENTER_SIZE_WIDTH_FIRST":  3,
	}
)

func (x BoxCoordinatesMode_Coordinates) Enum() *BoxCoordinatesMode_Coordinates {
	p := new(BoxCoordinatesMode_Coordinates)
	*p = x
	return p
}

func (x BoxCoordinatesMode_Coordinates) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (BoxCoordinatesMode_Coordinates) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[5].Descriptor()
}

func (BoxCoordinatesMode_Coordinates) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[5]
}

func (x BoxCoordinatesMode_Coordinates) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use BoxCoordinatesMode_Coordinates.Descriptor instead.
func (BoxCoordinatesMode_Coordinates) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{39, 0}
}

// The type of padding.
// All padding types pad the input shape with zeros.
// CUSTOM padding will add the custom padding values specified below to their respective
// dimensions, e.g., `customPaddingFront` number of zeros will be added to one side of the
// input's depth dimension and `customPaddingBack` number of zeros will be added to the other
// side of the input's depth dimension.
// VALID padding adds no padding to any dimension. In this case, the last convolution along
// each dimension will be dropped if the input dimension and the kernel size, stride, and
// dilation do not match.
// SAME padding adds enough padding to each dimension such that the output of the convolution
// has size “Ceiling(inputShape / stride)“. Padding is added evenly to both sides of each
// dimension unless the total padding to add is odd, in which case it is added to the
// back/bottom/right side of the respective dimension. For example, if the total padding needed
// in the depth dimension is 3, 1 zero will be added to the front side of the depth dimension
// and 2 zeros will be added to the back side.
type Convolution3DLayerParams_PaddingType int32

const (
	Convolution3DLayerParams_CUSTOM Convolution3DLayerParams_PaddingType = 0
	Convolution3DLayerParams_VALID  Convolution3DLayerParams_PaddingType = 1
	Convolution3DLayerParams_SAME   Convolution3DLayerParams_PaddingType = 2
)

// Enum value maps for Convolution3DLayerParams_PaddingType.
var (
	Convolution3DLayerParams_PaddingType_name = map[int32]string{
		0: "CUSTOM",
		1: "VALID",
		2: "SAME",
	}
	Convolution3DLayerParams_PaddingType_value = map[string]int32{
		"CUSTOM": 0,
		"VALID":  1,
		"SAME":   2,
	}
)

func (x Convolution3DLayerParams_PaddingType) Enum() *Convolution3DLayerParams_PaddingType {
	p := new(Convolution3DLayerParams_PaddingType)
	*p = x
	return p
}

func (x Convolution3DLayerParams_PaddingType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Convolution3DLayerParams_PaddingType) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[6].Descriptor()
}

func (Convolution3DLayerParams_PaddingType) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[6]
}

func (x Convolution3DLayerParams_PaddingType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Convolution3DLayerParams_PaddingType.Descriptor instead.
func (Convolution3DLayerParams_PaddingType) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{45, 0}
}

type PoolingLayerParams_PoolingType int32

const (
	PoolingLayerParams_MAX     PoolingLayerParams_PoolingType = 0
	PoolingLayerParams_AVERAGE PoolingLayerParams_PoolingType = 1
	PoolingLayerParams_L2      PoolingLayerParams_PoolingType = 2
)

// Enum value maps for PoolingLayerParams_PoolingType.
var (
	PoolingLayerParams_PoolingType_name = map[int32]string{
		0: "MAX",
		1: "AVERAGE",
		2: "L2",
	}
	PoolingLayerParams_PoolingType_value = map[string]int32{
		"MAX":     0,
		"AVERAGE": 1,
		"L2":      2,
	}
)

func (x PoolingLayerParams_PoolingType) Enum() *PoolingLayerParams_PoolingType {
	p := new(PoolingLayerParams_PoolingType)
	*p = x
	return p
}

func (x PoolingLayerParams_PoolingType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (PoolingLayerParams_PoolingType) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[7].Descriptor()
}

func (PoolingLayerParams_PoolingType) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[7]
}

func (x PoolingLayerParams_PoolingType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use PoolingLayerParams_PoolingType.Descriptor instead.
func (PoolingLayerParams_PoolingType) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{50, 0}
}

type Pooling3DLayerParams_PoolingType3D int32

const (
	Pooling3DLayerParams_MAX     Pooling3DLayerParams_PoolingType3D = 0
	Pooling3DLayerParams_AVERAGE Pooling3DLayerParams_PoolingType3D = 1
)

// Enum value maps for Pooling3DLayerParams_PoolingType3D.
var (
	Pooling3DLayerParams_PoolingType3D_name = map[int32]string{
		0: "MAX",
		1: "AVERAGE",
	}
	Pooling3DLayerParams_PoolingType3D_value = map[string]int32{
		"MAX":     0,
		"AVERAGE": 1,
	}
)

func (x Pooling3DLayerParams_PoolingType3D) Enum() *Pooling3DLayerParams_PoolingType3D {
	p := new(Pooling3DLayerParams_PoolingType3D)
	*p = x
	return p
}

func (x Pooling3DLayerParams_PoolingType3D) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Pooling3DLayerParams_PoolingType3D) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[8].Descriptor()
}

func (Pooling3DLayerParams_PoolingType3D) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[8]
}

func (x Pooling3DLayerParams_PoolingType3D) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Pooling3DLayerParams_PoolingType3D.Descriptor instead.
func (Pooling3DLayerParams_PoolingType3D) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{51, 0}
}

// The type of padding.
// All padding types pad the input shape with zeros.
// CUSTOM padding will add the custom padding values specified below to their respective
// dimensions, e.g., `customPaddingFront` number of zeros will be added to one side of the
// input's depth dimension and `customPaddingBack` number of zeros will be added to the other
// side of the input's depth dimension.
// VALID padding adds no padding to any dimension. In this case, the last pool along
// each dimension will be dropped if the input dimension and the kernel size, and stride do not match.
// SAME padding adds enough padding to each dimension such that the output
// has the same spatial dimensions as the input. Padding is added evenly to both
// sides of each dimension unless the total padding to add is odd, in which case the extra padding
// is added to the back/bottom/right side of the respective dimension.  For example, if the the
// total horizontal padding is 3, then there will be 1 padding on the left, and 2 padding on the right.
type Pooling3DLayerParams_Pooling3DPaddingType int32

const (
	Pooling3DLayerParams_CUSTOM Pooling3DLayerParams_Pooling3DPaddingType = 0
	Pooling3DLayerParams_VALID  Pooling3DLayerParams_Pooling3DPaddingType = 1
	Pooling3DLayerParams_SAME   Pooling3DLayerParams_Pooling3DPaddingType = 2
)

// Enum value maps for Pooling3DLayerParams_Pooling3DPaddingType.
var (
	Pooling3DLayerParams_Pooling3DPaddingType_name = map[int32]string{
		0: "CUSTOM",
		1: "VALID",
		2: "SAME",
	}
	Pooling3DLayerParams_Pooling3DPaddingType_value = map[string]int32{
		"CUSTOM": 0,
		"VALID":  1,
		"SAME":   2,
	}
)

func (x Pooling3DLayerParams_Pooling3DPaddingType) Enum() *Pooling3DLayerParams_Pooling3DPaddingType {
	p := new(Pooling3DLayerParams_Pooling3DPaddingType)
	*p = x
	return p
}

func (x Pooling3DLayerParams_Pooling3DPaddingType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Pooling3DLayerParams_Pooling3DPaddingType) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[9].Descriptor()
}

func (Pooling3DLayerParams_Pooling3DPaddingType) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[9]
}

func (x Pooling3DLayerParams_Pooling3DPaddingType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Pooling3DLayerParams_Pooling3DPaddingType.Descriptor instead.
func (Pooling3DLayerParams_Pooling3DPaddingType) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{51, 1}
}

type GlobalPooling3DLayerParams_GlobalPoolingType3D int32

const (
	GlobalPooling3DLayerParams_MAX     GlobalPooling3DLayerParams_GlobalPoolingType3D = 0
	GlobalPooling3DLayerParams_AVERAGE GlobalPooling3DLayerParams_GlobalPoolingType3D = 1
)

// Enum value maps for GlobalPooling3DLayerParams_GlobalPoolingType3D.
var (
	GlobalPooling3DLayerParams_GlobalPoolingType3D_name = map[int32]string{
		0: "MAX",
		1: "AVERAGE",
	}
	GlobalPooling3DLayerParams_GlobalPoolingType3D_value = map[string]int32{
		"MAX":     0,
		"AVERAGE": 1,
	}
)

func (x GlobalPooling3DLayerParams_GlobalPoolingType3D) Enum() *GlobalPooling3DLayerParams_GlobalPoolingType3D {
	p := new(GlobalPooling3DLayerParams_GlobalPoolingType3D)
	*p = x
	return p
}

func (x GlobalPooling3DLayerParams_GlobalPoolingType3D) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (GlobalPooling3DLayerParams_GlobalPoolingType3D) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[10].Descriptor()
}

func (GlobalPooling3DLayerParams_GlobalPoolingType3D) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[10]
}

func (x GlobalPooling3DLayerParams_GlobalPoolingType3D) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use GlobalPooling3DLayerParams_GlobalPoolingType3D.Descriptor instead.
func (GlobalPooling3DLayerParams_GlobalPoolingType3D) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{52, 0}
}

// A unary operator.
//
// The following functions are supported:
//
// “SQRT“
//
//	.. math:: f(x) = \sqrt{x}
//
// “RSQRT“
//
//	.. math:: f(x) = \dfrac{1}{\sqrt{x + \epsilon}}
//
// “INVERSE“
//
//	.. math:: f(x) = \dfrac{1}{x + \epsilon}
//
// “POWER“
//
//	.. math:: f(x) = x^\alpha
//
// “EXP“
//
//	.. math:: f(x) = e^x
//
// “LOG“
//
//	.. math:: f(x) = \log x
//
// “ABS“
//
//	.. math:: f(x) = |x|
//
// “THRESHOLD“
//
//	.. math:: f(x) = \text{max}(\alpha, x)
type UnaryFunctionLayerParams_Operation int32

const (
	UnaryFunctionLayerParams_SQRT      UnaryFunctionLayerParams_Operation = 0
	UnaryFunctionLayerParams_RSQRT     UnaryFunctionLayerParams_Operation = 1
	UnaryFunctionLayerParams_INVERSE   UnaryFunctionLayerParams_Operation = 2
	UnaryFunctionLayerParams_POWER     UnaryFunctionLayerParams_Operation = 3
	UnaryFunctionLayerParams_EXP       UnaryFunctionLayerParams_Operation = 4
	UnaryFunctionLayerParams_LOG       UnaryFunctionLayerParams_Operation = 5
	UnaryFunctionLayerParams_ABS       UnaryFunctionLayerParams_Operation = 6
	UnaryFunctionLayerParams_THRESHOLD UnaryFunctionLayerParams_Operation = 7
)

// Enum value maps for UnaryFunctionLayerParams_Operation.
var (
	UnaryFunctionLayerParams_Operation_name = map[int32]string{
		0: "SQRT",
		1: "RSQRT",
		2: "INVERSE",
		3: "POWER",
		4: "EXP",
		5: "LOG",
		6: "ABS",
		7: "THRESHOLD",
	}
	UnaryFunctionLayerParams_Operation_value = map[string]int32{
		"SQRT":      0,
		"RSQRT":     1,
		"INVERSE":   2,
		"POWER":     3,
		"EXP":       4,
		"LOG":       5,
		"ABS":       6,
		"THRESHOLD": 7,
	}
)

func (x UnaryFunctionLayerParams_Operation) Enum() *UnaryFunctionLayerParams_Operation {
	p := new(UnaryFunctionLayerParams_Operation)
	*p = x
	return p
}

func (x UnaryFunctionLayerParams_Operation) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (UnaryFunctionLayerParams_Operation) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[11].Descriptor()
}

func (UnaryFunctionLayerParams_Operation) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[11]
}

func (x UnaryFunctionLayerParams_Operation) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use UnaryFunctionLayerParams_Operation.Descriptor instead.
func (UnaryFunctionLayerParams_Operation) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{60, 0}
}

// Overall mode for interpolating new elements when upsampling.
// NN - Nearest Neighbors - simply pick the nearest true value for interpolated values.
// BILINEAR - Use bilinear interpolation. See LinearUpsamplingMode for behavior.
type UpsampleLayerParams_InterpolationMode int32

const (
	UpsampleLayerParams_NN       UpsampleLayerParams_InterpolationMode = 0 // Nearest Neighbour
	UpsampleLayerParams_BILINEAR UpsampleLayerParams_InterpolationMode = 1 // Bilinear
)

// Enum value maps for UpsampleLayerParams_InterpolationMode.
var (
	UpsampleLayerParams_InterpolationMode_name = map[int32]string{
		0: "NN",
		1: "BILINEAR",
	}
	UpsampleLayerParams_InterpolationMode_value = map[string]int32{
		"NN":       0,
		"BILINEAR": 1,
	}
)

func (x UpsampleLayerParams_InterpolationMode) Enum() *UpsampleLayerParams_InterpolationMode {
	p := new(UpsampleLayerParams_InterpolationMode)
	*p = x
	return p
}

func (x UpsampleLayerParams_InterpolationMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (UpsampleLayerParams_InterpolationMode) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[12].Descriptor()
}

func (UpsampleLayerParams_InterpolationMode) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[12]
}

func (x UpsampleLayerParams_InterpolationMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use UpsampleLayerParams_InterpolationMode.Descriptor instead.
func (UpsampleLayerParams_InterpolationMode) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{61, 0}
}

// LinearUpsampleMode specifies the behavior for linear upsampling. Only valid when Interpolation Mode is BILINEAR.
// If input grid is [0, Xin-1] (corresponding to an input size of Xin), and if the output size is Xout,
// then the grid points are sampled in the following manner:
// DEFAULT:
//
//	spacing = (Xin-Xin/Xout) / (Xout-1)
//	grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,….,Xout-1
//
// ALIGN_CORNERS_TRUE:
//
//	spacing = (Xin-1) / (Xout-1)
//	grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,….,Xout-1
//
// ALIGN_CORNERS_FALSE:
//
//	spacing = Xin / Xout
//	grid_point[i] = min(Xin-1, max(0, i * spacing + 0.5 * spacing - 0.5)), for i = 0,1,2,….,Xout-1
type UpsampleLayerParams_LinearUpsampleMode int32

const (
	UpsampleLayerParams_DEFAULT             UpsampleLayerParams_LinearUpsampleMode = 0
	UpsampleLayerParams_ALIGN_CORNERS_TRUE  UpsampleLayerParams_LinearUpsampleMode = 1
	UpsampleLayerParams_ALIGN_CORNERS_FALSE UpsampleLayerParams_LinearUpsampleMode = 2
)

// Enum value maps for UpsampleLayerParams_LinearUpsampleMode.
var (
	UpsampleLayerParams_LinearUpsampleMode_name = map[int32]string{
		0: "DEFAULT",
		1: "ALIGN_CORNERS_TRUE",
		2: "ALIGN_CORNERS_FALSE",
	}
	UpsampleLayerParams_LinearUpsampleMode_value = map[string]int32{
		"DEFAULT":             0,
		"ALIGN_CORNERS_TRUE":  1,
		"ALIGN_CORNERS_FALSE": 2,
	}
)

func (x UpsampleLayerParams_LinearUpsampleMode) Enum() *UpsampleLayerParams_LinearUpsampleMode {
	p := new(UpsampleLayerParams_LinearUpsampleMode)
	*p = x
	return p
}

func (x UpsampleLayerParams_LinearUpsampleMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (UpsampleLayerParams_LinearUpsampleMode) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[13].Descriptor()
}

func (UpsampleLayerParams_LinearUpsampleMode) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[13]
}

func (x UpsampleLayerParams_LinearUpsampleMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use UpsampleLayerParams_LinearUpsampleMode.Descriptor instead.
func (UpsampleLayerParams_LinearUpsampleMode) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{61, 1}
}

type FlattenLayerParams_FlattenOrder int32

const (
	FlattenLayerParams_CHANNEL_FIRST FlattenLayerParams_FlattenOrder = 0
	FlattenLayerParams_CHANNEL_LAST  FlattenLayerParams_FlattenOrder = 1
)

// Enum value maps for FlattenLayerParams_FlattenOrder.
var (
	FlattenLayerParams_FlattenOrder_name = map[int32]string{
		0: "CHANNEL_FIRST",
		1: "CHANNEL_LAST",
	}
	FlattenLayerParams_FlattenOrder_value = map[string]int32{
		"CHANNEL_FIRST": 0,
		"CHANNEL_LAST":  1,
	}
)

func (x FlattenLayerParams_FlattenOrder) Enum() *FlattenLayerParams_FlattenOrder {
	p := new(FlattenLayerParams_FlattenOrder)
	*p = x
	return p
}

func (x FlattenLayerParams_FlattenOrder) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (FlattenLayerParams_FlattenOrder) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[14].Descriptor()
}

func (FlattenLayerParams_FlattenOrder) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[14]
}

func (x FlattenLayerParams_FlattenOrder) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use FlattenLayerParams_FlattenOrder.Descriptor instead.
func (FlattenLayerParams_FlattenOrder) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{68, 0}
}

type ReshapeLayerParams_ReshapeOrder int32

const (
	ReshapeLayerParams_CHANNEL_FIRST ReshapeLayerParams_ReshapeOrder = 0
	ReshapeLayerParams_CHANNEL_LAST  ReshapeLayerParams_ReshapeOrder = 1
)

// Enum value maps for ReshapeLayerParams_ReshapeOrder.
var (
	ReshapeLayerParams_ReshapeOrder_name = map[int32]string{
		0: "CHANNEL_FIRST",
		1: "CHANNEL_LAST",
	}
	ReshapeLayerParams_ReshapeOrder_value = map[string]int32{
		"CHANNEL_FIRST": 0,
		"CHANNEL_LAST":  1,
	}
)

func (x ReshapeLayerParams_ReshapeOrder) Enum() *ReshapeLayerParams_ReshapeOrder {
	p := new(ReshapeLayerParams_ReshapeOrder)
	*p = x
	return p
}

func (x ReshapeLayerParams_ReshapeOrder) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ReshapeLayerParams_ReshapeOrder) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[15].Descriptor()
}

func (ReshapeLayerParams_ReshapeOrder) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[15]
}

func (x ReshapeLayerParams_ReshapeOrder) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ReshapeLayerParams_ReshapeOrder.Descriptor instead.
func (ReshapeLayerParams_ReshapeOrder) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{69, 0}
}

type ReorganizeDataLayerParams_ReorganizationType int32

const (
	ReorganizeDataLayerParams_SPACE_TO_DEPTH ReorganizeDataLayerParams_ReorganizationType = 0
	ReorganizeDataLayerParams_DEPTH_TO_SPACE ReorganizeDataLayerParams_ReorganizationType = 1
	ReorganizeDataLayerParams_PIXEL_SHUFFLE  ReorganizeDataLayerParams_ReorganizationType = 2
)

// Enum value maps for ReorganizeDataLayerParams_ReorganizationType.
var (
	ReorganizeDataLayerParams_ReorganizationType_name = map[int32]string{
		0: "SPACE_TO_DEPTH",
		1: "DEPTH_TO_SPACE",
		2: "PIXEL_SHUFFLE",
	}
	ReorganizeDataLayerParams_ReorganizationType_value = map[string]int32{
		"SPACE_TO_DEPTH": 0,
		"DEPTH_TO_SPACE": 1,
		"PIXEL_SHUFFLE":  2,
	}
)

func (x ReorganizeDataLayerParams_ReorganizationType) Enum() *ReorganizeDataLayerParams_ReorganizationType {
	p := new(ReorganizeDataLayerParams_ReorganizationType)
	*p = x
	return p
}

func (x ReorganizeDataLayerParams_ReorganizationType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ReorganizeDataLayerParams_ReorganizationType) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[16].Descriptor()
}

func (ReorganizeDataLayerParams_ReorganizationType) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[16]
}

func (x ReorganizeDataLayerParams_ReorganizationType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ReorganizeDataLayerParams_ReorganizationType.Descriptor instead.
func (ReorganizeDataLayerParams_ReorganizationType) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{71, 0}
}

type SliceLayerParams_SliceAxis int32

const (
	SliceLayerParams_CHANNEL_AXIS SliceLayerParams_SliceAxis = 0
	SliceLayerParams_HEIGHT_AXIS  SliceLayerParams_SliceAxis = 1
	SliceLayerParams_WIDTH_AXIS   SliceLayerParams_SliceAxis = 2
)

// Enum value maps for SliceLayerParams_SliceAxis.
var (
	SliceLayerParams_SliceAxis_name = map[int32]string{
		0: "CHANNEL_AXIS",
		1: "HEIGHT_AXIS",
		2: "WIDTH_AXIS",
	}
	SliceLayerParams_SliceAxis_value = map[string]int32{
		"CHANNEL_AXIS": 0,
		"HEIGHT_AXIS":  1,
		"WIDTH_AXIS":   2,
	}
)

func (x SliceLayerParams_SliceAxis) Enum() *SliceLayerParams_SliceAxis {
	p := new(SliceLayerParams_SliceAxis)
	*p = x
	return p
}

func (x SliceLayerParams_SliceAxis) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SliceLayerParams_SliceAxis) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[17].Descriptor()
}

func (SliceLayerParams_SliceAxis) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[17]
}

func (x SliceLayerParams_SliceAxis) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SliceLayerParams_SliceAxis.Descriptor instead.
func (SliceLayerParams_SliceAxis) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{72, 0}
}

// The following reduction operations are supported
// and are applied on the specified axis of the input array:
//
// “SUM“
//
//	Sum of all elements
//
//	.. math:: \sum{x_i}
//
// “AVG“
//
//	Sum of all elements divided by the number of elements
//
//	.. math:: \dfrac{\sum^n{x_i}}{n}
//
// “PROD“
//
//	Product of all elements
//
//	.. math:: \prod{x_i}
//
// “LOGSUM“
//
//	Sum of the natural logarithm of all elements
//
//	.. math:: \sum{\ln{(x_i + \epsilon)}}
//
// “SUMSQUARE“
//
//	Sum of squares of all elements
//
//	.. math:: \sum{x^2}
//
// “L1“
//
//	L1 normalization of all elements
//
//	.. math:: ||x||_1 = \sum{|x_i|}
//
// “L2“
//
//	L2 normalization of all elements
//
//	.. math:: ||x||_2 = \sqrt{\sum{x_i^2}}
//
// “MAX“
//
//	Maximum of all elements
//
//	.. math:: \text{max}(x_i)
//
// “MIN“
//
//	Minimum of all elements
//
//	.. math:: \text{min}(x_i)
//
// “ARGMAX“
//
//	Argument of the maximum of all elements
//
//	.. math:: \text{argmax}(x_i)
type ReduceLayerParams_ReduceOperation int32

const (
	ReduceLayerParams_SUM       ReduceLayerParams_ReduceOperation = 0
	ReduceLayerParams_AVG       ReduceLayerParams_ReduceOperation = 1
	ReduceLayerParams_PROD      ReduceLayerParams_ReduceOperation = 2
	ReduceLayerParams_LOGSUM    ReduceLayerParams_ReduceOperation = 3
	ReduceLayerParams_SUMSQUARE ReduceLayerParams_ReduceOperation = 4
	ReduceLayerParams_L1        ReduceLayerParams_ReduceOperation = 5
	ReduceLayerParams_L2        ReduceLayerParams_ReduceOperation = 6
	ReduceLayerParams_MAX       ReduceLayerParams_ReduceOperation = 7
	ReduceLayerParams_MIN       ReduceLayerParams_ReduceOperation = 8
	ReduceLayerParams_ARGMAX    ReduceLayerParams_ReduceOperation = 9 // only supported with axis = C, H or W.
)

// Enum value maps for ReduceLayerParams_ReduceOperation.
var (
	ReduceLayerParams_ReduceOperation_name = map[int32]string{
		0: "SUM",
		1: "AVG",
		2: "PROD",
		3: "LOGSUM",
		4: "SUMSQUARE",
		5: "L1",
		6: "L2",
		7: "MAX",
		8: "MIN",
		9: "ARGMAX",
	}
	ReduceLayerParams_ReduceOperation_value = map[string]int32{
		"SUM":       0,
		"AVG":       1,
		"PROD":      2,
		"LOGSUM":    3,
		"SUMSQUARE": 4,
		"L1":        5,
		"L2":        6,
		"MAX":       7,
		"MIN":       8,
		"ARGMAX":    9,
	}
)

func (x ReduceLayerParams_ReduceOperation) Enum() *ReduceLayerParams_ReduceOperation {
	p := new(ReduceLayerParams_ReduceOperation)
	*p = x
	return p
}

func (x ReduceLayerParams_ReduceOperation) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ReduceLayerParams_ReduceOperation) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[18].Descriptor()
}

func (ReduceLayerParams_ReduceOperation) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[18]
}

func (x ReduceLayerParams_ReduceOperation) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ReduceLayerParams_ReduceOperation.Descriptor instead.
func (ReduceLayerParams_ReduceOperation) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{73, 0}
}

type ReduceLayerParams_ReduceAxis int32

const (
	ReduceLayerParams_CHW ReduceLayerParams_ReduceAxis = 0
	ReduceLayerParams_HW  ReduceLayerParams_ReduceAxis = 1
	ReduceLayerParams_C   ReduceLayerParams_ReduceAxis = 2
	ReduceLayerParams_H   ReduceLayerParams_ReduceAxis = 3
	ReduceLayerParams_W   ReduceLayerParams_ReduceAxis = 4
)

// Enum value maps for ReduceLayerParams_ReduceAxis.
var (
	ReduceLayerParams_ReduceAxis_name = map[int32]string{
		0: "CHW",
		1: "HW",
		2: "C",
		3: "H",
		4: "W",
	}
	ReduceLayerParams_ReduceAxis_value = map[string]int32{
		"CHW": 0,
		"HW":  1,
		"C":   2,
		"H":   3,
		"W":   4,
	}
)

func (x ReduceLayerParams_ReduceAxis) Enum() *ReduceLayerParams_ReduceAxis {
	p := new(ReduceLayerParams_ReduceAxis)
	*p = x
	return p
}

func (x ReduceLayerParams_ReduceAxis) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ReduceLayerParams_ReduceAxis) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[19].Descriptor()
}

func (ReduceLayerParams_ReduceAxis) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[19]
}

func (x ReduceLayerParams_ReduceAxis) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ReduceLayerParams_ReduceAxis.Descriptor instead.
func (ReduceLayerParams_ReduceAxis) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{73, 1}
}

type GeluLayerParams_GeluMode int32

const (
	GeluLayerParams_EXACT                 GeluLayerParams_GeluMode = 0
	GeluLayerParams_TANH_APPROXIMATION    GeluLayerParams_GeluMode = 1
	GeluLayerParams_SIGMOID_APPROXIMATION GeluLayerParams_GeluMode = 2
)

// Enum value maps for GeluLayerParams_GeluMode.
var (
	GeluLayerParams_GeluMode_name = map[int32]string{
		0: "EXACT",
		1: "TANH_APPROXIMATION",
		2: "SIGMOID_APPROXIMATION",
	}
	GeluLayerParams_GeluMode_value = map[string]int32{
		"EXACT":                 0,
		"TANH_APPROXIMATION":    1,
		"SIGMOID_APPROXIMATION": 2,
	}
)

func (x GeluLayerParams_GeluMode) Enum() *GeluLayerParams_GeluMode {
	p := new(GeluLayerParams_GeluMode)
	*p = x
	return p
}

func (x GeluLayerParams_GeluMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (GeluLayerParams_GeluMode) Descriptor() protoreflect.EnumDescriptor {
	return file_NeuralNetwork_proto_enumTypes[20].Descriptor()
}

func (GeluLayerParams_GeluMode) Type() protoreflect.EnumType {
	return &file_NeuralNetwork_proto_enumTypes[20]
}

func (x GeluLayerParams_GeluMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use GeluLayerParams_GeluMode.Descriptor instead.
func (GeluLayerParams_GeluMode) EnumDescriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{177, 0}
}

// A neural network.
type NeuralNetwork struct {
	state         protoimpl.MessageState        `protogen:"open.v1"`
	Layers        []*NeuralNetworkLayer         `protobuf:"bytes,1,rep,name=layers,proto3" json:"layers,omitempty"`
	Preprocessing []*NeuralNetworkPreprocessing `protobuf:"bytes,2,rep,name=preprocessing,proto3" json:"preprocessing,omitempty"`
	// use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs
	ArrayInputShapeMapping NeuralNetworkMultiArrayShapeMapping `protobuf:"varint,5,opt,name=arrayInputShapeMapping,proto3,enum=CoreML.Specification.NeuralNetworkMultiArrayShapeMapping" json:"arrayInputShapeMapping,omitempty"`
	// use this enum value to determine the input tensor shapes to the neural network, for image inputs
	ImageInputShapeMapping NeuralNetworkImageShapeMapping `protobuf:"varint,6,opt,name=imageInputShapeMapping,proto3,enum=CoreML.Specification.NeuralNetworkImageShapeMapping" json:"imageInputShapeMapping,omitempty"`
	UpdateParams           *NetworkUpdateParameters       `protobuf:"bytes,10,opt,name=updateParams,proto3" json:"updateParams,omitempty"`
	unknownFields          protoimpl.UnknownFields
	sizeCache              protoimpl.SizeCache
}

func (x *NeuralNetwork) Reset() {
	*x = NeuralNetwork{}
	mi := &file_NeuralNetwork_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetwork) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetwork) ProtoMessage() {}

func (x *NeuralNetwork) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetwork.ProtoReflect.Descriptor instead.
func (*NeuralNetwork) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{0}
}

func (x *NeuralNetwork) GetLayers() []*NeuralNetworkLayer {
	if x != nil {
		return x.Layers
	}
	return nil
}

func (x *NeuralNetwork) GetPreprocessing() []*NeuralNetworkPreprocessing {
	if x != nil {
		return x.Preprocessing
	}
	return nil
}

func (x *NeuralNetwork) GetArrayInputShapeMapping() NeuralNetworkMultiArrayShapeMapping {
	if x != nil {
		return x.ArrayInputShapeMapping
	}
	return NeuralNetworkMultiArrayShapeMapping_RANK5_ARRAY_MAPPING
}

func (x *NeuralNetwork) GetImageInputShapeMapping() NeuralNetworkImageShapeMapping {
	if x != nil {
		return x.ImageInputShapeMapping
	}
	return NeuralNetworkImageShapeMapping_RANK5_IMAGE_MAPPING
}

func (x *NeuralNetwork) GetUpdateParams() *NetworkUpdateParameters {
	if x != nil {
		return x.UpdateParams
	}
	return nil
}

// A neural network preprocessor that
// performs a scalar multiplication of an image
// followed by addition of scalar biases to the channels.
//
// Input: X
//
//	An image in BGR or RGB format with shape ``[3, H, W]``
//	or in grayscale format with shape ``[1, H, W]``.
//
// Output: Y
//
//	An image with format and shape corresponding to the input.
//
// If the input image is in BGR format:
//
// .. code::
//
//	Y[0, :, :] = channelScale * X[0, :, :] + blueBias
//	Y[1, :, :] = channelScale * X[1, :, :] + greenBias
//	Y[2, :, :] = channelScale * X[2, :, :] + redBias
//
// If the input image is in RGB format:
//
// .. code::
//
//	Y[0, :, :] = channelScale * X[0, :, :] + redBias
//	Y[1, :, :] = channelScale * X[1, :, :] + greenBias
//	Y[2, :, :] = channelScale * X[2, :, :] + blueBias
//
// If the input image is in grayscale format:
//
// .. code::
//
//	Y[0, :, :] = channelScale * X[0, :, :] + grayBias
type NeuralNetworkImageScaler struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ChannelScale  float32                `protobuf:"fixed32,10,opt,name=channelScale,proto3" json:"channelScale,omitempty"` // Scalar to be multiplied.
	BlueBias      float32                `protobuf:"fixed32,20,opt,name=blueBias,proto3" json:"blueBias,omitempty"`         // Scalar blue bias to be added.
	GreenBias     float32                `protobuf:"fixed32,21,opt,name=greenBias,proto3" json:"greenBias,omitempty"`       // Scalar green bias to be added.
	RedBias       float32                `protobuf:"fixed32,22,opt,name=redBias,proto3" json:"redBias,omitempty"`           // Scalar red bias to be added.
	GrayBias      float32                `protobuf:"fixed32,30,opt,name=grayBias,proto3" json:"grayBias,omitempty"`         // Scalar bias to be added for grayscale images.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NeuralNetworkImageScaler) Reset() {
	*x = NeuralNetworkImageScaler{}
	mi := &file_NeuralNetwork_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetworkImageScaler) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetworkImageScaler) ProtoMessage() {}

func (x *NeuralNetworkImageScaler) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetworkImageScaler.ProtoReflect.Descriptor instead.
func (*NeuralNetworkImageScaler) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{1}
}

func (x *NeuralNetworkImageScaler) GetChannelScale() float32 {
	if x != nil {
		return x.ChannelScale
	}
	return 0
}

func (x *NeuralNetworkImageScaler) GetBlueBias() float32 {
	if x != nil {
		return x.BlueBias
	}
	return 0
}

func (x *NeuralNetworkImageScaler) GetGreenBias() float32 {
	if x != nil {
		return x.GreenBias
	}
	return 0
}

func (x *NeuralNetworkImageScaler) GetRedBias() float32 {
	if x != nil {
		return x.RedBias
	}
	return 0
}

func (x *NeuralNetworkImageScaler) GetGrayBias() float32 {
	if x != nil {
		return x.GrayBias
	}
	return 0
}

// A neural network preprocessor that
// subtracts the provided mean image from the input image.
// The mean image is subtracted from the input named
// “NeuralNetworkPreprocessing.featureName“.
type NeuralNetworkMeanImage struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Mean image stored as a flattened array of floats,
	// representing shape [Channel,Height,Width].
	MeanImage     []float32 `protobuf:"fixed32,1,rep,packed,name=meanImage,proto3" json:"meanImage,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NeuralNetworkMeanImage) Reset() {
	*x = NeuralNetworkMeanImage{}
	mi := &file_NeuralNetwork_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetworkMeanImage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetworkMeanImage) ProtoMessage() {}

func (x *NeuralNetworkMeanImage) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetworkMeanImage.ProtoReflect.Descriptor instead.
func (*NeuralNetworkMeanImage) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{2}
}

func (x *NeuralNetworkMeanImage) GetMeanImage() []float32 {
	if x != nil {
		return x.MeanImage
	}
	return nil
}

// Preprocessing parameters for image inputs.
type NeuralNetworkPreprocessing struct {
	state       protoimpl.MessageState `protogen:"open.v1"`
	FeatureName string                 `protobuf:"bytes,1,opt,name=featureName,proto3" json:"featureName,omitempty"` // must be equal to the input name to which the preprocessing is applied
	// Types that are valid to be assigned to Preprocessor:
	//
	//	*NeuralNetworkPreprocessing_Scaler
	//	*NeuralNetworkPreprocessing_MeanImage
	Preprocessor  isNeuralNetworkPreprocessing_Preprocessor `protobuf_oneof:"preprocessor"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NeuralNetworkPreprocessing) Reset() {
	*x = NeuralNetworkPreprocessing{}
	mi := &file_NeuralNetwork_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetworkPreprocessing) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetworkPreprocessing) ProtoMessage() {}

func (x *NeuralNetworkPreprocessing) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetworkPreprocessing.ProtoReflect.Descriptor instead.
func (*NeuralNetworkPreprocessing) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{3}
}

func (x *NeuralNetworkPreprocessing) GetFeatureName() string {
	if x != nil {
		return x.FeatureName
	}
	return ""
}

func (x *NeuralNetworkPreprocessing) GetPreprocessor() isNeuralNetworkPreprocessing_Preprocessor {
	if x != nil {
		return x.Preprocessor
	}
	return nil
}

func (x *NeuralNetworkPreprocessing) GetScaler() *NeuralNetworkImageScaler {
	if x != nil {
		if x, ok := x.Preprocessor.(*NeuralNetworkPreprocessing_Scaler); ok {
			return x.Scaler
		}
	}
	return nil
}

func (x *NeuralNetworkPreprocessing) GetMeanImage() *NeuralNetworkMeanImage {
	if x != nil {
		if x, ok := x.Preprocessor.(*NeuralNetworkPreprocessing_MeanImage); ok {
			return x.MeanImage
		}
	}
	return nil
}

type isNeuralNetworkPreprocessing_Preprocessor interface {
	isNeuralNetworkPreprocessing_Preprocessor()
}

type NeuralNetworkPreprocessing_Scaler struct {
	Scaler *NeuralNetworkImageScaler `protobuf:"bytes,10,opt,name=scaler,proto3,oneof"`
}

type NeuralNetworkPreprocessing_MeanImage struct {
	MeanImage *NeuralNetworkMeanImage `protobuf:"bytes,11,opt,name=meanImage,proto3,oneof"`
}

func (*NeuralNetworkPreprocessing_Scaler) isNeuralNetworkPreprocessing_Preprocessor() {}

func (*NeuralNetworkPreprocessing_MeanImage) isNeuralNetworkPreprocessing_Preprocessor() {}

// A rectified linear unit (ReLU) activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \text{max}(0, x)
type ActivationReLU struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationReLU) Reset() {
	*x = ActivationReLU{}
	mi := &file_NeuralNetwork_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationReLU) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationReLU) ProtoMessage() {}

func (x *ActivationReLU) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationReLU.ProtoReflect.Descriptor instead.
func (*ActivationReLU) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{4}
}

// A leaky rectified linear unit (ReLU) activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \begin{cases}
//	        x      & \text{if } x \geq 0 \\
//	        \alpha x & \text{if } x < 0
//	       \end{cases}
type ActivationLeakyReLU struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"` //negative slope value for leakyReLU
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationLeakyReLU) Reset() {
	*x = ActivationLeakyReLU{}
	mi := &file_NeuralNetwork_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationLeakyReLU) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationLeakyReLU) ProtoMessage() {}

func (x *ActivationLeakyReLU) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationLeakyReLU.ProtoReflect.Descriptor instead.
func (*ActivationLeakyReLU) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{5}
}

func (x *ActivationLeakyReLU) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// A hyperbolic tangent activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \dfrac{1 - e^{-2x}}{1 + e^{-2x}}
type ActivationTanh struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationTanh) Reset() {
	*x = ActivationTanh{}
	mi := &file_NeuralNetwork_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationTanh) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationTanh) ProtoMessage() {}

func (x *ActivationTanh) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationTanh.ProtoReflect.Descriptor instead.
func (*ActivationTanh) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{6}
}

// A scaled hyperbolic tangent activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \alpha \tanh(\beta x)
type ActivationScaledTanh struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta          float32                `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationScaledTanh) Reset() {
	*x = ActivationScaledTanh{}
	mi := &file_NeuralNetwork_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationScaledTanh) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationScaledTanh) ProtoMessage() {}

func (x *ActivationScaledTanh) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationScaledTanh.ProtoReflect.Descriptor instead.
func (*ActivationScaledTanh) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{7}
}

func (x *ActivationScaledTanh) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

func (x *ActivationScaledTanh) GetBeta() float32 {
	if x != nil {
		return x.Beta
	}
	return 0
}

// A sigmoid activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \dfrac{1}{1 + e^{-x}}
type ActivationSigmoid struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationSigmoid) Reset() {
	*x = ActivationSigmoid{}
	mi := &file_NeuralNetwork_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationSigmoid) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationSigmoid) ProtoMessage() {}

func (x *ActivationSigmoid) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationSigmoid.ProtoReflect.Descriptor instead.
func (*ActivationSigmoid) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{8}
}

// A linear activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \alpha x + \beta
type ActivationLinear struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta          float32                `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationLinear) Reset() {
	*x = ActivationLinear{}
	mi := &file_NeuralNetwork_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationLinear) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationLinear) ProtoMessage() {}

func (x *ActivationLinear) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationLinear.ProtoReflect.Descriptor instead.
func (*ActivationLinear) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{9}
}

func (x *ActivationLinear) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

func (x *ActivationLinear) GetBeta() float32 {
	if x != nil {
		return x.Beta
	}
	return 0
}

// A hard sigmoid activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \text{min}(\text{max}(\alpha x + \beta, 0), 1)
type ActivationSigmoidHard struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta          float32                `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationSigmoidHard) Reset() {
	*x = ActivationSigmoidHard{}
	mi := &file_NeuralNetwork_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationSigmoidHard) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationSigmoidHard) ProtoMessage() {}

func (x *ActivationSigmoidHard) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationSigmoidHard.ProtoReflect.Descriptor instead.
func (*ActivationSigmoidHard) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{10}
}

func (x *ActivationSigmoidHard) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

func (x *ActivationSigmoidHard) GetBeta() float32 {
	if x != nil {
		return x.Beta
	}
	return 0
}

// A parameterized rectified linear unit (PReLU) activation function.
// Input must be at least rank 3. Axis = -3 is denoted by "C", or channels.
// "alpha" parameter can be a vector of length C.
//
// This function has the following formula:
//
// .. math::
//
//	f(x_i) = \begin{cases}
//	             x_i          & \text{if } x_i \geq 0 \\
//	             \alpha_i x_i & \text{if } x_i < 0
//	         \end{cases} \;,\;i=1,...,C
type ActivationPReLU struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// parameter of length C or 1.
	// If length is 1, same value is used for all channels
	Alpha         *WeightParams `protobuf:"bytes,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationPReLU) Reset() {
	*x = ActivationPReLU{}
	mi := &file_NeuralNetwork_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationPReLU) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationPReLU) ProtoMessage() {}

func (x *ActivationPReLU) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationPReLU.ProtoReflect.Descriptor instead.
func (*ActivationPReLU) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{11}
}

func (x *ActivationPReLU) GetAlpha() *WeightParams {
	if x != nil {
		return x.Alpha
	}
	return nil
}

// An exponential linear unit (ELU) activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \begin{cases}
//	        x              & \text{if } x \geq 0 \\
//	        \alpha (e^x - 1) & \text{if } x < 0
//	       \end{cases}
type ActivationELU struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationELU) Reset() {
	*x = ActivationELU{}
	mi := &file_NeuralNetwork_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationELU) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationELU) ProtoMessage() {}

func (x *ActivationELU) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationELU.ProtoReflect.Descriptor instead.
func (*ActivationELU) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{12}
}

func (x *ActivationELU) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// A thresholded rectified linear unit (ReLU) activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \begin{cases}
//	        x & \text{if } x \geq \alpha \\
//	        0 & \text{if } x < \alpha
//	       \end{cases}
type ActivationThresholdedReLU struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationThresholdedReLU) Reset() {
	*x = ActivationThresholdedReLU{}
	mi := &file_NeuralNetwork_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationThresholdedReLU) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationThresholdedReLU) ProtoMessage() {}

func (x *ActivationThresholdedReLU) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationThresholdedReLU.ProtoReflect.Descriptor instead.
func (*ActivationThresholdedReLU) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{13}
}

func (x *ActivationThresholdedReLU) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// A softsign activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \dfrac{x}{1 + |x|}
type ActivationSoftsign struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationSoftsign) Reset() {
	*x = ActivationSoftsign{}
	mi := &file_NeuralNetwork_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationSoftsign) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationSoftsign) ProtoMessage() {}

func (x *ActivationSoftsign) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationSoftsign.ProtoReflect.Descriptor instead.
func (*ActivationSoftsign) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{14}
}

// A softplus activation function.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \text{log}(1 + e^x)
type ActivationSoftplus struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationSoftplus) Reset() {
	*x = ActivationSoftplus{}
	mi := &file_NeuralNetwork_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationSoftplus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationSoftplus) ProtoMessage() {}

func (x *ActivationSoftplus) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationSoftplus.ProtoReflect.Descriptor instead.
func (*ActivationSoftplus) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{15}
}

// A parametric softplus activation function.
// Input must be at least rank 3. axis = -3 is denoted by "C", or channels.
// "alpha"/"beta" parameter can be a vector of length C.
//
// This function has the following formula:
//
// .. math::
//
//	f(x_i) = \alpha_i \text{log}(1 + e^{\beta_i x_i}) \;,\;i=1,...,C
type ActivationParametricSoftplus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If length is 1, same value is used for all channels
	Alpha         *WeightParams `protobuf:"bytes,1,opt,name=alpha,proto3" json:"alpha,omitempty"` //parameter of length C or 1
	Beta          *WeightParams `protobuf:"bytes,2,opt,name=beta,proto3" json:"beta,omitempty"`   //parameter of length C or 1
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ActivationParametricSoftplus) Reset() {
	*x = ActivationParametricSoftplus{}
	mi := &file_NeuralNetwork_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationParametricSoftplus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationParametricSoftplus) ProtoMessage() {}

func (x *ActivationParametricSoftplus) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationParametricSoftplus.ProtoReflect.Descriptor instead.
func (*ActivationParametricSoftplus) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{16}
}

func (x *ActivationParametricSoftplus) GetAlpha() *WeightParams {
	if x != nil {
		return x.Alpha
	}
	return nil
}

func (x *ActivationParametricSoftplus) GetBeta() *WeightParams {
	if x != nil {
		return x.Beta
	}
	return nil
}

type ActivationParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to NonlinearityType:
	//
	//	*ActivationParams_Linear
	//	*ActivationParams_ReLU
	//	*ActivationParams_LeakyReLU
	//	*ActivationParams_ThresholdedReLU
	//	*ActivationParams_PReLU
	//	*ActivationParams_Tanh
	//	*ActivationParams_ScaledTanh
	//	*ActivationParams_Sigmoid
	//	*ActivationParams_SigmoidHard
	//	*ActivationParams_ELU
	//	*ActivationParams_Softsign
	//	*ActivationParams_Softplus
	//	*ActivationParams_ParametricSoftplus
	NonlinearityType isActivationParams_NonlinearityType `protobuf_oneof:"NonlinearityType"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *ActivationParams) Reset() {
	*x = ActivationParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ActivationParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ActivationParams) ProtoMessage() {}

func (x *ActivationParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ActivationParams.ProtoReflect.Descriptor instead.
func (*ActivationParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{17}
}

func (x *ActivationParams) GetNonlinearityType() isActivationParams_NonlinearityType {
	if x != nil {
		return x.NonlinearityType
	}
	return nil
}

func (x *ActivationParams) GetLinear() *ActivationLinear {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_Linear); ok {
			return x.Linear
		}
	}
	return nil
}

func (x *ActivationParams) GetReLU() *ActivationReLU {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_ReLU); ok {
			return x.ReLU
		}
	}
	return nil
}

func (x *ActivationParams) GetLeakyReLU() *ActivationLeakyReLU {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_LeakyReLU); ok {
			return x.LeakyReLU
		}
	}
	return nil
}

func (x *ActivationParams) GetThresholdedReLU() *ActivationThresholdedReLU {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_ThresholdedReLU); ok {
			return x.ThresholdedReLU
		}
	}
	return nil
}

func (x *ActivationParams) GetPReLU() *ActivationPReLU {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_PReLU); ok {
			return x.PReLU
		}
	}
	return nil
}

func (x *ActivationParams) GetTanh() *ActivationTanh {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_Tanh); ok {
			return x.Tanh
		}
	}
	return nil
}

func (x *ActivationParams) GetScaledTanh() *ActivationScaledTanh {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_ScaledTanh); ok {
			return x.ScaledTanh
		}
	}
	return nil
}

func (x *ActivationParams) GetSigmoid() *ActivationSigmoid {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_Sigmoid); ok {
			return x.Sigmoid
		}
	}
	return nil
}

func (x *ActivationParams) GetSigmoidHard() *ActivationSigmoidHard {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_SigmoidHard); ok {
			return x.SigmoidHard
		}
	}
	return nil
}

func (x *ActivationParams) GetELU() *ActivationELU {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_ELU); ok {
			return x.ELU
		}
	}
	return nil
}

func (x *ActivationParams) GetSoftsign() *ActivationSoftsign {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_Softsign); ok {
			return x.Softsign
		}
	}
	return nil
}

func (x *ActivationParams) GetSoftplus() *ActivationSoftplus {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_Softplus); ok {
			return x.Softplus
		}
	}
	return nil
}

func (x *ActivationParams) GetParametricSoftplus() *ActivationParametricSoftplus {
	if x != nil {
		if x, ok := x.NonlinearityType.(*ActivationParams_ParametricSoftplus); ok {
			return x.ParametricSoftplus
		}
	}
	return nil
}

type isActivationParams_NonlinearityType interface {
	isActivationParams_NonlinearityType()
}

type ActivationParams_Linear struct {
	Linear *ActivationLinear `protobuf:"bytes,5,opt,name=linear,proto3,oneof"`
}

type ActivationParams_ReLU struct {
	ReLU *ActivationReLU `protobuf:"bytes,10,opt,name=ReLU,proto3,oneof"`
}

type ActivationParams_LeakyReLU struct {
	LeakyReLU *ActivationLeakyReLU `protobuf:"bytes,15,opt,name=leakyReLU,proto3,oneof"`
}

type ActivationParams_ThresholdedReLU struct {
	ThresholdedReLU *ActivationThresholdedReLU `protobuf:"bytes,20,opt,name=thresholdedReLU,proto3,oneof"`
}

type ActivationParams_PReLU struct {
	PReLU *ActivationPReLU `protobuf:"bytes,25,opt,name=PReLU,proto3,oneof"`
}

type ActivationParams_Tanh struct {
	Tanh *ActivationTanh `protobuf:"bytes,30,opt,name=tanh,proto3,oneof"`
}

type ActivationParams_ScaledTanh struct {
	ScaledTanh *ActivationScaledTanh `protobuf:"bytes,31,opt,name=scaledTanh,proto3,oneof"`
}

type ActivationParams_Sigmoid struct {
	Sigmoid *ActivationSigmoid `protobuf:"bytes,40,opt,name=sigmoid,proto3,oneof"`
}

type ActivationParams_SigmoidHard struct {
	SigmoidHard *ActivationSigmoidHard `protobuf:"bytes,41,opt,name=sigmoidHard,proto3,oneof"`
}

type ActivationParams_ELU struct {
	ELU *ActivationELU `protobuf:"bytes,50,opt,name=ELU,proto3,oneof"`
}

type ActivationParams_Softsign struct {
	Softsign *ActivationSoftsign `protobuf:"bytes,60,opt,name=softsign,proto3,oneof"`
}

type ActivationParams_Softplus struct {
	Softplus *ActivationSoftplus `protobuf:"bytes,70,opt,name=softplus,proto3,oneof"`
}

type ActivationParams_ParametricSoftplus struct {
	ParametricSoftplus *ActivationParametricSoftplus `protobuf:"bytes,71,opt,name=parametricSoftplus,proto3,oneof"`
}

func (*ActivationParams_Linear) isActivationParams_NonlinearityType() {}

func (*ActivationParams_ReLU) isActivationParams_NonlinearityType() {}

func (*ActivationParams_LeakyReLU) isActivationParams_NonlinearityType() {}

func (*ActivationParams_ThresholdedReLU) isActivationParams_NonlinearityType() {}

func (*ActivationParams_PReLU) isActivationParams_NonlinearityType() {}

func (*ActivationParams_Tanh) isActivationParams_NonlinearityType() {}

func (*ActivationParams_ScaledTanh) isActivationParams_NonlinearityType() {}

func (*ActivationParams_Sigmoid) isActivationParams_NonlinearityType() {}

func (*ActivationParams_SigmoidHard) isActivationParams_NonlinearityType() {}

func (*ActivationParams_ELU) isActivationParams_NonlinearityType() {}

func (*ActivationParams_Softsign) isActivationParams_NonlinearityType() {}

func (*ActivationParams_Softplus) isActivationParams_NonlinearityType() {}

func (*ActivationParams_ParametricSoftplus) isActivationParams_NonlinearityType() {}

// Representation of the intermediate tensors
type Tensor struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Number of dimensions in the tensor shape
	Rank uint32 `protobuf:"varint,1,opt,name=rank,proto3" json:"rank,omitempty"`
	// actual value of the tensor shape.
	// must be of length "rank". Can contain -1s for unknown dimensions.
	DimValue      []int64 `protobuf:"varint,2,rep,packed,name=dimValue,proto3" json:"dimValue,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Tensor) Reset() {
	*x = Tensor{}
	mi := &file_NeuralNetwork_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Tensor) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Tensor) ProtoMessage() {}

func (x *Tensor) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Tensor.ProtoReflect.Descriptor instead.
func (*Tensor) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{18}
}

func (x *Tensor) GetRank() uint32 {
	if x != nil {
		return x.Rank
	}
	return 0
}

func (x *Tensor) GetDimValue() []int64 {
	if x != nil {
		return x.DimValue
	}
	return nil
}

// A single neural network layer.
type NeuralNetworkLayer struct {
	state        protoimpl.MessageState `protogen:"open.v1"`
	Name         string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"` //descriptive name of the layer
	Input        []string               `protobuf:"bytes,2,rep,name=input,proto3" json:"input,omitempty"`
	Output       []string               `protobuf:"bytes,3,rep,name=output,proto3" json:"output,omitempty"`
	InputTensor  []*Tensor              `protobuf:"bytes,4,rep,name=inputTensor,proto3" json:"inputTensor,omitempty"`   // must be the same length as the "input" field
	OutputTensor []*Tensor              `protobuf:"bytes,5,rep,name=outputTensor,proto3" json:"outputTensor,omitempty"` // must be the same length as the "output" field
	// Must be set to true to mark the layer as updatable.
	// If true, the weightParams in the layer's properties must also be set to updatable
	// If false, the value of the isUpdatable parameter within the layer's weights are ignored
	IsUpdatable bool `protobuf:"varint,10,opt,name=isUpdatable,proto3" json:"isUpdatable,omitempty"`
	// Types that are valid to be assigned to Layer:
	//
	//	*NeuralNetworkLayer_Convolution
	//	*NeuralNetworkLayer_Pooling
	//	*NeuralNetworkLayer_Activation
	//	*NeuralNetworkLayer_InnerProduct
	//	*NeuralNetworkLayer_Embedding
	//	*NeuralNetworkLayer_Batchnorm
	//	*NeuralNetworkLayer_Mvn
	//	*NeuralNetworkLayer_L2Normalize
	//	*NeuralNetworkLayer_Softmax
	//	*NeuralNetworkLayer_Lrn
	//	*NeuralNetworkLayer_Crop
	//	*NeuralNetworkLayer_Padding
	//	*NeuralNetworkLayer_Upsample
	//	*NeuralNetworkLayer_ResizeBilinear
	//	*NeuralNetworkLayer_CropResize
	//	*NeuralNetworkLayer_Unary
	//	*NeuralNetworkLayer_Add
	//	*NeuralNetworkLayer_Multiply
	//	*NeuralNetworkLayer_Average
	//	*NeuralNetworkLayer_Scale
	//	*NeuralNetworkLayer_Bias
	//	*NeuralNetworkLayer_Max
	//	*NeuralNetworkLayer_Min
	//	*NeuralNetworkLayer_Dot
	//	*NeuralNetworkLayer_Reduce
	//	*NeuralNetworkLayer_LoadConstant
	//	*NeuralNetworkLayer_Reshape
	//	*NeuralNetworkLayer_Flatten
	//	*NeuralNetworkLayer_Permute
	//	*NeuralNetworkLayer_Concat
	//	*NeuralNetworkLayer_Split
	//	*NeuralNetworkLayer_SequenceRepeat
	//	*NeuralNetworkLayer_ReorganizeData
	//	*NeuralNetworkLayer_Slice
	//	*NeuralNetworkLayer_SimpleRecurrent
	//	*NeuralNetworkLayer_Gru
	//	*NeuralNetworkLayer_UniDirectionalLSTM
	//	*NeuralNetworkLayer_BiDirectionalLSTM
	//	*NeuralNetworkLayer_Custom
	//	*NeuralNetworkLayer_Copy
	//	*NeuralNetworkLayer_Branch
	//	*NeuralNetworkLayer_Loop
	//	*NeuralNetworkLayer_LoopBreak
	//	*NeuralNetworkLayer_LoopContinue
	//	*NeuralNetworkLayer_RangeStatic
	//	*NeuralNetworkLayer_RangeDynamic
	//	*NeuralNetworkLayer_Clip
	//	*NeuralNetworkLayer_Ceil
	//	*NeuralNetworkLayer_Floor
	//	*NeuralNetworkLayer_Sign
	//	*NeuralNetworkLayer_Round
	//	*NeuralNetworkLayer_Exp2
	//	*NeuralNetworkLayer_Sin
	//	*NeuralNetworkLayer_Cos
	//	*NeuralNetworkLayer_Tan
	//	*NeuralNetworkLayer_Asin
	//	*NeuralNetworkLayer_Acos
	//	*NeuralNetworkLayer_Atan
	//	*NeuralNetworkLayer_Sinh
	//	*NeuralNetworkLayer_Cosh
	//	*NeuralNetworkLayer_Tanh
	//	*NeuralNetworkLayer_Asinh
	//	*NeuralNetworkLayer_Acosh
	//	*NeuralNetworkLayer_Atanh
	//	*NeuralNetworkLayer_Erf
	//	*NeuralNetworkLayer_Gelu
	//	*NeuralNetworkLayer_Equal
	//	*NeuralNetworkLayer_NotEqual
	//	*NeuralNetworkLayer_LessThan
	//	*NeuralNetworkLayer_LessEqual
	//	*NeuralNetworkLayer_GreaterThan
	//	*NeuralNetworkLayer_GreaterEqual
	//	*NeuralNetworkLayer_LogicalOr
	//	*NeuralNetworkLayer_LogicalXor
	//	*NeuralNetworkLayer_LogicalNot
	//	*NeuralNetworkLayer_LogicalAnd
	//	*NeuralNetworkLayer_ModBroadcastable
	//	*NeuralNetworkLayer_MinBroadcastable
	//	*NeuralNetworkLayer_MaxBroadcastable
	//	*NeuralNetworkLayer_AddBroadcastable
	//	*NeuralNetworkLayer_PowBroadcastable
	//	*NeuralNetworkLayer_DivideBroadcastable
	//	*NeuralNetworkLayer_FloorDivBroadcastable
	//	*NeuralNetworkLayer_MultiplyBroadcastable
	//	*NeuralNetworkLayer_SubtractBroadcastable
	//	*NeuralNetworkLayer_Tile
	//	*NeuralNetworkLayer_Stack
	//	*NeuralNetworkLayer_Gather
	//	*NeuralNetworkLayer_Scatter
	//	*NeuralNetworkLayer_GatherND
	//	*NeuralNetworkLayer_ScatterND
	//	*NeuralNetworkLayer_SoftmaxND
	//	*NeuralNetworkLayer_GatherAlongAxis
	//	*NeuralNetworkLayer_ScatterAlongAxis
	//	*NeuralNetworkLayer_Reverse
	//	*NeuralNetworkLayer_ReverseSeq
	//	*NeuralNetworkLayer_SplitND
	//	*NeuralNetworkLayer_ConcatND
	//	*NeuralNetworkLayer_Transpose
	//	*NeuralNetworkLayer_SliceStatic
	//	*NeuralNetworkLayer_SliceDynamic
	//	*NeuralNetworkLayer_SlidingWindows
	//	*NeuralNetworkLayer_TopK
	//	*NeuralNetworkLayer_ArgMin
	//	*NeuralNetworkLayer_ArgMax
	//	*NeuralNetworkLayer_EmbeddingND
	//	*NeuralNetworkLayer_BatchedMatmul
	//	*NeuralNetworkLayer_GetShape
	//	*NeuralNetworkLayer_LoadConstantND
	//	*NeuralNetworkLayer_FillLike
	//	*NeuralNetworkLayer_FillStatic
	//	*NeuralNetworkLayer_FillDynamic
	//	*NeuralNetworkLayer_BroadcastToLike
	//	*NeuralNetworkLayer_BroadcastToStatic
	//	*NeuralNetworkLayer_BroadcastToDynamic
	//	*NeuralNetworkLayer_Squeeze
	//	*NeuralNetworkLayer_ExpandDims
	//	*NeuralNetworkLayer_FlattenTo2D
	//	*NeuralNetworkLayer_ReshapeLike
	//	*NeuralNetworkLayer_ReshapeStatic
	//	*NeuralNetworkLayer_ReshapeDynamic
	//	*NeuralNetworkLayer_RankPreservingReshape
	//	*NeuralNetworkLayer_ConstantPad
	//	*NeuralNetworkLayer_RandomNormalLike
	//	*NeuralNetworkLayer_RandomNormalStatic
	//	*NeuralNetworkLayer_RandomNormalDynamic
	//	*NeuralNetworkLayer_RandomUniformLike
	//	*NeuralNetworkLayer_RandomUniformStatic
	//	*NeuralNetworkLayer_RandomUniformDynamic
	//	*NeuralNetworkLayer_RandomBernoulliLike
	//	*NeuralNetworkLayer_RandomBernoulliStatic
	//	*NeuralNetworkLayer_RandomBernoulliDynamic
	//	*NeuralNetworkLayer_CategoricalDistribution
	//	*NeuralNetworkLayer_ReduceL1
	//	*NeuralNetworkLayer_ReduceL2
	//	*NeuralNetworkLayer_ReduceMax
	//	*NeuralNetworkLayer_ReduceMin
	//	*NeuralNetworkLayer_ReduceSum
	//	*NeuralNetworkLayer_ReduceProd
	//	*NeuralNetworkLayer_ReduceMean
	//	*NeuralNetworkLayer_ReduceLogSum
	//	*NeuralNetworkLayer_ReduceSumSquare
	//	*NeuralNetworkLayer_ReduceLogSumExp
	//	*NeuralNetworkLayer_WhereNonZero
	//	*NeuralNetworkLayer_MatrixBandPart
	//	*NeuralNetworkLayer_LowerTriangular
	//	*NeuralNetworkLayer_UpperTriangular
	//	*NeuralNetworkLayer_WhereBroadcastable
	//	*NeuralNetworkLayer_LayerNormalization
	//	*NeuralNetworkLayer_NonMaximumSuppression
	//	*NeuralNetworkLayer_OneHot
	//	*NeuralNetworkLayer_CumSum
	//	*NeuralNetworkLayer_ClampedReLU
	//	*NeuralNetworkLayer_ArgSort
	//	*NeuralNetworkLayer_Pooling3D
	//	*NeuralNetworkLayer_GlobalPooling3D
	//	*NeuralNetworkLayer_SliceBySize
	//	*NeuralNetworkLayer_Convolution3D
	Layer         isNeuralNetworkLayer_Layer `protobuf_oneof:"layer"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NeuralNetworkLayer) Reset() {
	*x = NeuralNetworkLayer{}
	mi := &file_NeuralNetwork_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetworkLayer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetworkLayer) ProtoMessage() {}

func (x *NeuralNetworkLayer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetworkLayer.ProtoReflect.Descriptor instead.
func (*NeuralNetworkLayer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{19}
}

func (x *NeuralNetworkLayer) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *NeuralNetworkLayer) GetInput() []string {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *NeuralNetworkLayer) GetOutput() []string {
	if x != nil {
		return x.Output
	}
	return nil
}

func (x *NeuralNetworkLayer) GetInputTensor() []*Tensor {
	if x != nil {
		return x.InputTensor
	}
	return nil
}

func (x *NeuralNetworkLayer) GetOutputTensor() []*Tensor {
	if x != nil {
		return x.OutputTensor
	}
	return nil
}

func (x *NeuralNetworkLayer) GetIsUpdatable() bool {
	if x != nil {
		return x.IsUpdatable
	}
	return false
}

func (x *NeuralNetworkLayer) GetLayer() isNeuralNetworkLayer_Layer {
	if x != nil {
		return x.Layer
	}
	return nil
}

func (x *NeuralNetworkLayer) GetConvolution() *ConvolutionLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Convolution); ok {
			return x.Convolution
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetPooling() *PoolingLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Pooling); ok {
			return x.Pooling
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetActivation() *ActivationParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Activation); ok {
			return x.Activation
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetInnerProduct() *InnerProductLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_InnerProduct); ok {
			return x.InnerProduct
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetEmbedding() *EmbeddingLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Embedding); ok {
			return x.Embedding
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBatchnorm() *BatchnormLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Batchnorm); ok {
			return x.Batchnorm
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMvn() *MeanVarianceNormalizeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Mvn); ok {
			return x.Mvn
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetL2Normalize() *L2NormalizeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_L2Normalize); ok {
			return x.L2Normalize
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSoftmax() *SoftmaxLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Softmax); ok {
			return x.Softmax
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLrn() *LRNLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Lrn); ok {
			return x.Lrn
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCrop() *CropLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Crop); ok {
			return x.Crop
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetPadding() *PaddingLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Padding); ok {
			return x.Padding
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetUpsample() *UpsampleLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Upsample); ok {
			return x.Upsample
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetResizeBilinear() *ResizeBilinearLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ResizeBilinear); ok {
			return x.ResizeBilinear
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCropResize() *CropResizeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_CropResize); ok {
			return x.CropResize
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetUnary() *UnaryFunctionLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Unary); ok {
			return x.Unary
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAdd() *AddLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Add); ok {
			return x.Add
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMultiply() *MultiplyLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Multiply); ok {
			return x.Multiply
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAverage() *AverageLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Average); ok {
			return x.Average
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetScale() *ScaleLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Scale); ok {
			return x.Scale
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBias() *BiasLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Bias); ok {
			return x.Bias
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMax() *MaxLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Max); ok {
			return x.Max
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMin() *MinLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Min); ok {
			return x.Min
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetDot() *DotProductLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Dot); ok {
			return x.Dot
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduce() *ReduceLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Reduce); ok {
			return x.Reduce
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLoadConstant() *LoadConstantLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LoadConstant); ok {
			return x.LoadConstant
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReshape() *ReshapeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Reshape); ok {
			return x.Reshape
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFlatten() *FlattenLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Flatten); ok {
			return x.Flatten
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetPermute() *PermuteLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Permute); ok {
			return x.Permute
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetConcat() *ConcatLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Concat); ok {
			return x.Concat
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSplit() *SplitLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Split); ok {
			return x.Split
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSequenceRepeat() *SequenceRepeatLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SequenceRepeat); ok {
			return x.SequenceRepeat
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReorganizeData() *ReorganizeDataLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReorganizeData); ok {
			return x.ReorganizeData
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSlice() *SliceLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Slice); ok {
			return x.Slice
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSimpleRecurrent() *SimpleRecurrentLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SimpleRecurrent); ok {
			return x.SimpleRecurrent
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGru() *GRULayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Gru); ok {
			return x.Gru
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetUniDirectionalLSTM() *UniDirectionalLSTMLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_UniDirectionalLSTM); ok {
			return x.UniDirectionalLSTM
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBiDirectionalLSTM() *BiDirectionalLSTMLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_BiDirectionalLSTM); ok {
			return x.BiDirectionalLSTM
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCustom() *CustomLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Custom); ok {
			return x.Custom
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCopy() *CopyLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Copy); ok {
			return x.Copy
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBranch() *BranchLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Branch); ok {
			return x.Branch
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLoop() *LoopLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Loop); ok {
			return x.Loop
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLoopBreak() *LoopBreakLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LoopBreak); ok {
			return x.LoopBreak
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLoopContinue() *LoopContinueLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LoopContinue); ok {
			return x.LoopContinue
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRangeStatic() *RangeStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RangeStatic); ok {
			return x.RangeStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRangeDynamic() *RangeDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RangeDynamic); ok {
			return x.RangeDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetClip() *ClipLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Clip); ok {
			return x.Clip
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCeil() *CeilLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Ceil); ok {
			return x.Ceil
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFloor() *FloorLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Floor); ok {
			return x.Floor
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSign() *SignLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Sign); ok {
			return x.Sign
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRound() *RoundLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Round); ok {
			return x.Round
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetExp2() *Exp2LayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Exp2); ok {
			return x.Exp2
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSin() *SinLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Sin); ok {
			return x.Sin
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCos() *CosLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Cos); ok {
			return x.Cos
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetTan() *TanLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Tan); ok {
			return x.Tan
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAsin() *AsinLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Asin); ok {
			return x.Asin
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAcos() *AcosLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Acos); ok {
			return x.Acos
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAtan() *AtanLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Atan); ok {
			return x.Atan
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSinh() *SinhLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Sinh); ok {
			return x.Sinh
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCosh() *CoshLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Cosh); ok {
			return x.Cosh
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetTanh() *TanhLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Tanh); ok {
			return x.Tanh
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAsinh() *AsinhLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Asinh); ok {
			return x.Asinh
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAcosh() *AcoshLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Acosh); ok {
			return x.Acosh
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAtanh() *AtanhLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Atanh); ok {
			return x.Atanh
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetErf() *ErfLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Erf); ok {
			return x.Erf
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGelu() *GeluLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Gelu); ok {
			return x.Gelu
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetEqual() *EqualLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Equal); ok {
			return x.Equal
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetNotEqual() *NotEqualLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_NotEqual); ok {
			return x.NotEqual
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLessThan() *LessThanLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LessThan); ok {
			return x.LessThan
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLessEqual() *LessEqualLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LessEqual); ok {
			return x.LessEqual
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGreaterThan() *GreaterThanLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_GreaterThan); ok {
			return x.GreaterThan
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGreaterEqual() *GreaterEqualLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_GreaterEqual); ok {
			return x.GreaterEqual
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLogicalOr() *LogicalOrLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LogicalOr); ok {
			return x.LogicalOr
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLogicalXor() *LogicalXorLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LogicalXor); ok {
			return x.LogicalXor
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLogicalNot() *LogicalNotLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LogicalNot); ok {
			return x.LogicalNot
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLogicalAnd() *LogicalAndLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LogicalAnd); ok {
			return x.LogicalAnd
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetModBroadcastable() *ModBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ModBroadcastable); ok {
			return x.ModBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMinBroadcastable() *MinBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_MinBroadcastable); ok {
			return x.MinBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMaxBroadcastable() *MaxBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_MaxBroadcastable); ok {
			return x.MaxBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetAddBroadcastable() *AddBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_AddBroadcastable); ok {
			return x.AddBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetPowBroadcastable() *PowBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_PowBroadcastable); ok {
			return x.PowBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetDivideBroadcastable() *DivideBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_DivideBroadcastable); ok {
			return x.DivideBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFloorDivBroadcastable() *FloorDivBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_FloorDivBroadcastable); ok {
			return x.FloorDivBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMultiplyBroadcastable() *MultiplyBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_MultiplyBroadcastable); ok {
			return x.MultiplyBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSubtractBroadcastable() *SubtractBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SubtractBroadcastable); ok {
			return x.SubtractBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetTile() *TileLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Tile); ok {
			return x.Tile
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetStack() *StackLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Stack); ok {
			return x.Stack
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGather() *GatherLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Gather); ok {
			return x.Gather
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetScatter() *ScatterLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Scatter); ok {
			return x.Scatter
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGatherND() *GatherNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_GatherND); ok {
			return x.GatherND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetScatterND() *ScatterNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ScatterND); ok {
			return x.ScatterND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSoftmaxND() *SoftmaxNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SoftmaxND); ok {
			return x.SoftmaxND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGatherAlongAxis() *GatherAlongAxisLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_GatherAlongAxis); ok {
			return x.GatherAlongAxis
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetScatterAlongAxis() *ScatterAlongAxisLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ScatterAlongAxis); ok {
			return x.ScatterAlongAxis
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReverse() *ReverseLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Reverse); ok {
			return x.Reverse
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReverseSeq() *ReverseSeqLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReverseSeq); ok {
			return x.ReverseSeq
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSplitND() *SplitNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SplitND); ok {
			return x.SplitND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetConcatND() *ConcatNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ConcatND); ok {
			return x.ConcatND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetTranspose() *TransposeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Transpose); ok {
			return x.Transpose
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSliceStatic() *SliceStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SliceStatic); ok {
			return x.SliceStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSliceDynamic() *SliceDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SliceDynamic); ok {
			return x.SliceDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSlidingWindows() *SlidingWindowsLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SlidingWindows); ok {
			return x.SlidingWindows
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetTopK() *TopKLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_TopK); ok {
			return x.TopK
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetArgMin() *ArgMinLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ArgMin); ok {
			return x.ArgMin
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetArgMax() *ArgMaxLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ArgMax); ok {
			return x.ArgMax
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetEmbeddingND() *EmbeddingNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_EmbeddingND); ok {
			return x.EmbeddingND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBatchedMatmul() *BatchedMatMulLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_BatchedMatmul); ok {
			return x.BatchedMatmul
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGetShape() *GetShapeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_GetShape); ok {
			return x.GetShape
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLoadConstantND() *LoadConstantNDLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LoadConstantND); ok {
			return x.LoadConstantND
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFillLike() *FillLikeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_FillLike); ok {
			return x.FillLike
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFillStatic() *FillStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_FillStatic); ok {
			return x.FillStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFillDynamic() *FillDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_FillDynamic); ok {
			return x.FillDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBroadcastToLike() *BroadcastToLikeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_BroadcastToLike); ok {
			return x.BroadcastToLike
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBroadcastToStatic() *BroadcastToStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_BroadcastToStatic); ok {
			return x.BroadcastToStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetBroadcastToDynamic() *BroadcastToDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_BroadcastToDynamic); ok {
			return x.BroadcastToDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSqueeze() *SqueezeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Squeeze); ok {
			return x.Squeeze
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetExpandDims() *ExpandDimsLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ExpandDims); ok {
			return x.ExpandDims
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetFlattenTo2D() *FlattenTo2DLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_FlattenTo2D); ok {
			return x.FlattenTo2D
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReshapeLike() *ReshapeLikeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReshapeLike); ok {
			return x.ReshapeLike
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReshapeStatic() *ReshapeStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReshapeStatic); ok {
			return x.ReshapeStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReshapeDynamic() *ReshapeDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReshapeDynamic); ok {
			return x.ReshapeDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRankPreservingReshape() *RankPreservingReshapeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RankPreservingReshape); ok {
			return x.RankPreservingReshape
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetConstantPad() *ConstantPaddingLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ConstantPad); ok {
			return x.ConstantPad
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomNormalLike() *RandomNormalLikeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomNormalLike); ok {
			return x.RandomNormalLike
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomNormalStatic() *RandomNormalStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomNormalStatic); ok {
			return x.RandomNormalStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomNormalDynamic() *RandomNormalDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomNormalDynamic); ok {
			return x.RandomNormalDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomUniformLike() *RandomUniformLikeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomUniformLike); ok {
			return x.RandomUniformLike
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomUniformStatic() *RandomUniformStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomUniformStatic); ok {
			return x.RandomUniformStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomUniformDynamic() *RandomUniformDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomUniformDynamic); ok {
			return x.RandomUniformDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomBernoulliLike() *RandomBernoulliLikeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomBernoulliLike); ok {
			return x.RandomBernoulliLike
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomBernoulliStatic() *RandomBernoulliStaticLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomBernoulliStatic); ok {
			return x.RandomBernoulliStatic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetRandomBernoulliDynamic() *RandomBernoulliDynamicLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_RandomBernoulliDynamic); ok {
			return x.RandomBernoulliDynamic
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCategoricalDistribution() *CategoricalDistributionLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_CategoricalDistribution); ok {
			return x.CategoricalDistribution
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceL1() *ReduceL1LayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceL1); ok {
			return x.ReduceL1
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceL2() *ReduceL2LayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceL2); ok {
			return x.ReduceL2
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceMax() *ReduceMaxLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceMax); ok {
			return x.ReduceMax
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceMin() *ReduceMinLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceMin); ok {
			return x.ReduceMin
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceSum() *ReduceSumLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceSum); ok {
			return x.ReduceSum
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceProd() *ReduceProdLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceProd); ok {
			return x.ReduceProd
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceMean() *ReduceMeanLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceMean); ok {
			return x.ReduceMean
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceLogSum() *ReduceLogSumLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceLogSum); ok {
			return x.ReduceLogSum
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceSumSquare() *ReduceSumSquareLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceSumSquare); ok {
			return x.ReduceSumSquare
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetReduceLogSumExp() *ReduceLogSumExpLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ReduceLogSumExp); ok {
			return x.ReduceLogSumExp
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetWhereNonZero() *WhereNonZeroLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_WhereNonZero); ok {
			return x.WhereNonZero
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetMatrixBandPart() *MatrixBandPartLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_MatrixBandPart); ok {
			return x.MatrixBandPart
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLowerTriangular() *LowerTriangularLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LowerTriangular); ok {
			return x.LowerTriangular
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetUpperTriangular() *UpperTriangularLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_UpperTriangular); ok {
			return x.UpperTriangular
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetWhereBroadcastable() *WhereBroadcastableLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_WhereBroadcastable); ok {
			return x.WhereBroadcastable
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetLayerNormalization() *LayerNormalizationLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_LayerNormalization); ok {
			return x.LayerNormalization
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetNonMaximumSuppression() *NonMaximumSuppressionLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_NonMaximumSuppression); ok {
			return x.NonMaximumSuppression
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetOneHot() *OneHotLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_OneHot); ok {
			return x.OneHot
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetCumSum() *CumSumLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_CumSum); ok {
			return x.CumSum
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetClampedReLU() *ClampedReLULayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ClampedReLU); ok {
			return x.ClampedReLU
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetArgSort() *ArgSortLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_ArgSort); ok {
			return x.ArgSort
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetPooling3D() *Pooling3DLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Pooling3D); ok {
			return x.Pooling3D
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetGlobalPooling3D() *GlobalPooling3DLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_GlobalPooling3D); ok {
			return x.GlobalPooling3D
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetSliceBySize() *SliceBySizeLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_SliceBySize); ok {
			return x.SliceBySize
		}
	}
	return nil
}

func (x *NeuralNetworkLayer) GetConvolution3D() *Convolution3DLayerParams {
	if x != nil {
		if x, ok := x.Layer.(*NeuralNetworkLayer_Convolution3D); ok {
			return x.Convolution3D
		}
	}
	return nil
}

type isNeuralNetworkLayer_Layer interface {
	isNeuralNetworkLayer_Layer()
}

type NeuralNetworkLayer_Convolution struct {
	// Start at 100 here
	Convolution *ConvolutionLayerParams `protobuf:"bytes,100,opt,name=convolution,proto3,oneof"`
}

type NeuralNetworkLayer_Pooling struct {
	Pooling *PoolingLayerParams `protobuf:"bytes,120,opt,name=pooling,proto3,oneof"`
}

type NeuralNetworkLayer_Activation struct {
	Activation *ActivationParams `protobuf:"bytes,130,opt,name=activation,proto3,oneof"`
}

type NeuralNetworkLayer_InnerProduct struct {
	InnerProduct *InnerProductLayerParams `protobuf:"bytes,140,opt,name=innerProduct,proto3,oneof"`
}

type NeuralNetworkLayer_Embedding struct {
	Embedding *EmbeddingLayerParams `protobuf:"bytes,150,opt,name=embedding,proto3,oneof"`
}

type NeuralNetworkLayer_Batchnorm struct {
	// Normalization-related Layers
	Batchnorm *BatchnormLayerParams `protobuf:"bytes,160,opt,name=batchnorm,proto3,oneof"`
}

type NeuralNetworkLayer_Mvn struct {
	Mvn *MeanVarianceNormalizeLayerParams `protobuf:"bytes,165,opt,name=mvn,proto3,oneof"`
}

type NeuralNetworkLayer_L2Normalize struct {
	L2Normalize *L2NormalizeLayerParams `protobuf:"bytes,170,opt,name=l2normalize,proto3,oneof"`
}

type NeuralNetworkLayer_Softmax struct {
	Softmax *SoftmaxLayerParams `protobuf:"bytes,175,opt,name=softmax,proto3,oneof"`
}

type NeuralNetworkLayer_Lrn struct {
	Lrn *LRNLayerParams `protobuf:"bytes,180,opt,name=lrn,proto3,oneof"`
}

type NeuralNetworkLayer_Crop struct {
	Crop *CropLayerParams `protobuf:"bytes,190,opt,name=crop,proto3,oneof"`
}

type NeuralNetworkLayer_Padding struct {
	Padding *PaddingLayerParams `protobuf:"bytes,200,opt,name=padding,proto3,oneof"`
}

type NeuralNetworkLayer_Upsample struct {
	Upsample *UpsampleLayerParams `protobuf:"bytes,210,opt,name=upsample,proto3,oneof"`
}

type NeuralNetworkLayer_ResizeBilinear struct {
	ResizeBilinear *ResizeBilinearLayerParams `protobuf:"bytes,211,opt,name=resizeBilinear,proto3,oneof"`
}

type NeuralNetworkLayer_CropResize struct {
	CropResize *CropResizeLayerParams `protobuf:"bytes,212,opt,name=cropResize,proto3,oneof"`
}

type NeuralNetworkLayer_Unary struct {
	Unary *UnaryFunctionLayerParams `protobuf:"bytes,220,opt,name=unary,proto3,oneof"`
}

type NeuralNetworkLayer_Add struct {
	// Element-wise Operations
	Add *AddLayerParams `protobuf:"bytes,230,opt,name=add,proto3,oneof"`
}

type NeuralNetworkLayer_Multiply struct {
	Multiply *MultiplyLayerParams `protobuf:"bytes,231,opt,name=multiply,proto3,oneof"`
}

type NeuralNetworkLayer_Average struct {
	Average *AverageLayerParams `protobuf:"bytes,240,opt,name=average,proto3,oneof"`
}

type NeuralNetworkLayer_Scale struct {
	Scale *ScaleLayerParams `protobuf:"bytes,245,opt,name=scale,proto3,oneof"`
}

type NeuralNetworkLayer_Bias struct {
	Bias *BiasLayerParams `protobuf:"bytes,250,opt,name=bias,proto3,oneof"`
}

type NeuralNetworkLayer_Max struct {
	Max *MaxLayerParams `protobuf:"bytes,260,opt,name=max,proto3,oneof"`
}

type NeuralNetworkLayer_Min struct {
	Min *MinLayerParams `protobuf:"bytes,261,opt,name=min,proto3,oneof"`
}

type NeuralNetworkLayer_Dot struct {
	Dot *DotProductLayerParams `protobuf:"bytes,270,opt,name=dot,proto3,oneof"`
}

type NeuralNetworkLayer_Reduce struct {
	Reduce *ReduceLayerParams `protobuf:"bytes,280,opt,name=reduce,proto3,oneof"`
}

type NeuralNetworkLayer_LoadConstant struct {
	LoadConstant *LoadConstantLayerParams `protobuf:"bytes,290,opt,name=loadConstant,proto3,oneof"`
}

type NeuralNetworkLayer_Reshape struct {
	// Data Reorganization
	Reshape *ReshapeLayerParams `protobuf:"bytes,300,opt,name=reshape,proto3,oneof"`
}

type NeuralNetworkLayer_Flatten struct {
	Flatten *FlattenLayerParams `protobuf:"bytes,301,opt,name=flatten,proto3,oneof"`
}

type NeuralNetworkLayer_Permute struct {
	Permute *PermuteLayerParams `protobuf:"bytes,310,opt,name=permute,proto3,oneof"`
}

type NeuralNetworkLayer_Concat struct {
	Concat *ConcatLayerParams `protobuf:"bytes,320,opt,name=concat,proto3,oneof"`
}

type NeuralNetworkLayer_Split struct {
	Split *SplitLayerParams `protobuf:"bytes,330,opt,name=split,proto3,oneof"`
}

type NeuralNetworkLayer_SequenceRepeat struct {
	SequenceRepeat *SequenceRepeatLayerParams `protobuf:"bytes,340,opt,name=sequenceRepeat,proto3,oneof"`
}

type NeuralNetworkLayer_ReorganizeData struct {
	ReorganizeData *ReorganizeDataLayerParams `protobuf:"bytes,345,opt,name=reorganizeData,proto3,oneof"`
}

type NeuralNetworkLayer_Slice struct {
	Slice *SliceLayerParams `protobuf:"bytes,350,opt,name=slice,proto3,oneof"`
}

type NeuralNetworkLayer_SimpleRecurrent struct {
	// Recurrent Layers
	SimpleRecurrent *SimpleRecurrentLayerParams `protobuf:"bytes,400,opt,name=simpleRecurrent,proto3,oneof"`
}

type NeuralNetworkLayer_Gru struct {
	Gru *GRULayerParams `protobuf:"bytes,410,opt,name=gru,proto3,oneof"`
}

type NeuralNetworkLayer_UniDirectionalLSTM struct {
	UniDirectionalLSTM *UniDirectionalLSTMLayerParams `protobuf:"bytes,420,opt,name=uniDirectionalLSTM,proto3,oneof"`
}

type NeuralNetworkLayer_BiDirectionalLSTM struct {
	BiDirectionalLSTM *BiDirectionalLSTMLayerParams `protobuf:"bytes,430,opt,name=biDirectionalLSTM,proto3,oneof"`
}

type NeuralNetworkLayer_Custom struct {
	// Custom (user-implemented) Layer
	Custom *CustomLayerParams `protobuf:"bytes,500,opt,name=custom,proto3,oneof"`
}

type NeuralNetworkLayer_Copy struct {
	// Control Flow related Layers
	Copy *CopyLayerParams `protobuf:"bytes,600,opt,name=copy,proto3,oneof"`
}

type NeuralNetworkLayer_Branch struct {
	Branch *BranchLayerParams `protobuf:"bytes,605,opt,name=branch,proto3,oneof"`
}

type NeuralNetworkLayer_Loop struct {
	Loop *LoopLayerParams `protobuf:"bytes,615,opt,name=loop,proto3,oneof"`
}

type NeuralNetworkLayer_LoopBreak struct {
	LoopBreak *LoopBreakLayerParams `protobuf:"bytes,620,opt,name=loopBreak,proto3,oneof"`
}

type NeuralNetworkLayer_LoopContinue struct {
	LoopContinue *LoopContinueLayerParams `protobuf:"bytes,625,opt,name=loopContinue,proto3,oneof"`
}

type NeuralNetworkLayer_RangeStatic struct {
	RangeStatic *RangeStaticLayerParams `protobuf:"bytes,635,opt,name=rangeStatic,proto3,oneof"`
}

type NeuralNetworkLayer_RangeDynamic struct {
	RangeDynamic *RangeDynamicLayerParams `protobuf:"bytes,640,opt,name=rangeDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_Clip struct {
	// Element-wise Unary Layers
	Clip *ClipLayerParams `protobuf:"bytes,660,opt,name=clip,proto3,oneof"`
}

type NeuralNetworkLayer_Ceil struct {
	Ceil *CeilLayerParams `protobuf:"bytes,665,opt,name=ceil,proto3,oneof"`
}

type NeuralNetworkLayer_Floor struct {
	Floor *FloorLayerParams `protobuf:"bytes,670,opt,name=floor,proto3,oneof"`
}

type NeuralNetworkLayer_Sign struct {
	Sign *SignLayerParams `protobuf:"bytes,680,opt,name=sign,proto3,oneof"`
}

type NeuralNetworkLayer_Round struct {
	Round *RoundLayerParams `protobuf:"bytes,685,opt,name=round,proto3,oneof"`
}

type NeuralNetworkLayer_Exp2 struct {
	Exp2 *Exp2LayerParams `protobuf:"bytes,700,opt,name=exp2,proto3,oneof"`
}

type NeuralNetworkLayer_Sin struct {
	Sin *SinLayerParams `protobuf:"bytes,710,opt,name=sin,proto3,oneof"`
}

type NeuralNetworkLayer_Cos struct {
	Cos *CosLayerParams `protobuf:"bytes,715,opt,name=cos,proto3,oneof"`
}

type NeuralNetworkLayer_Tan struct {
	Tan *TanLayerParams `protobuf:"bytes,720,opt,name=tan,proto3,oneof"`
}

type NeuralNetworkLayer_Asin struct {
	Asin *AsinLayerParams `protobuf:"bytes,730,opt,name=asin,proto3,oneof"`
}

type NeuralNetworkLayer_Acos struct {
	Acos *AcosLayerParams `protobuf:"bytes,735,opt,name=acos,proto3,oneof"`
}

type NeuralNetworkLayer_Atan struct {
	Atan *AtanLayerParams `protobuf:"bytes,740,opt,name=atan,proto3,oneof"`
}

type NeuralNetworkLayer_Sinh struct {
	Sinh *SinhLayerParams `protobuf:"bytes,750,opt,name=sinh,proto3,oneof"`
}

type NeuralNetworkLayer_Cosh struct {
	Cosh *CoshLayerParams `protobuf:"bytes,755,opt,name=cosh,proto3,oneof"`
}

type NeuralNetworkLayer_Tanh struct {
	Tanh *TanhLayerParams `protobuf:"bytes,760,opt,name=tanh,proto3,oneof"`
}

type NeuralNetworkLayer_Asinh struct {
	Asinh *AsinhLayerParams `protobuf:"bytes,770,opt,name=asinh,proto3,oneof"`
}

type NeuralNetworkLayer_Acosh struct {
	Acosh *AcoshLayerParams `protobuf:"bytes,775,opt,name=acosh,proto3,oneof"`
}

type NeuralNetworkLayer_Atanh struct {
	Atanh *AtanhLayerParams `protobuf:"bytes,780,opt,name=atanh,proto3,oneof"`
}

type NeuralNetworkLayer_Erf struct {
	Erf *ErfLayerParams `protobuf:"bytes,790,opt,name=erf,proto3,oneof"`
}

type NeuralNetworkLayer_Gelu struct {
	Gelu *GeluLayerParams `protobuf:"bytes,795,opt,name=gelu,proto3,oneof"`
}

type NeuralNetworkLayer_Equal struct {
	// Element-wise Binary with Broadcasting Support
	Equal *EqualLayerParams `protobuf:"bytes,815,opt,name=equal,proto3,oneof"`
}

type NeuralNetworkLayer_NotEqual struct {
	NotEqual *NotEqualLayerParams `protobuf:"bytes,820,opt,name=notEqual,proto3,oneof"`
}

type NeuralNetworkLayer_LessThan struct {
	LessThan *LessThanLayerParams `protobuf:"bytes,825,opt,name=lessThan,proto3,oneof"`
}

type NeuralNetworkLayer_LessEqual struct {
	LessEqual *LessEqualLayerParams `protobuf:"bytes,827,opt,name=lessEqual,proto3,oneof"`
}

type NeuralNetworkLayer_GreaterThan struct {
	GreaterThan *GreaterThanLayerParams `protobuf:"bytes,830,opt,name=greaterThan,proto3,oneof"`
}

type NeuralNetworkLayer_GreaterEqual struct {
	GreaterEqual *GreaterEqualLayerParams `protobuf:"bytes,832,opt,name=greaterEqual,proto3,oneof"`
}

type NeuralNetworkLayer_LogicalOr struct {
	LogicalOr *LogicalOrLayerParams `protobuf:"bytes,840,opt,name=logicalOr,proto3,oneof"`
}

type NeuralNetworkLayer_LogicalXor struct {
	LogicalXor *LogicalXorLayerParams `protobuf:"bytes,845,opt,name=logicalXor,proto3,oneof"`
}

type NeuralNetworkLayer_LogicalNot struct {
	LogicalNot *LogicalNotLayerParams `protobuf:"bytes,850,opt,name=logicalNot,proto3,oneof"`
}

type NeuralNetworkLayer_LogicalAnd struct {
	LogicalAnd *LogicalAndLayerParams `protobuf:"bytes,855,opt,name=logicalAnd,proto3,oneof"`
}

type NeuralNetworkLayer_ModBroadcastable struct {
	ModBroadcastable *ModBroadcastableLayerParams `protobuf:"bytes,865,opt,name=modBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_MinBroadcastable struct {
	MinBroadcastable *MinBroadcastableLayerParams `protobuf:"bytes,870,opt,name=minBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_MaxBroadcastable struct {
	MaxBroadcastable *MaxBroadcastableLayerParams `protobuf:"bytes,875,opt,name=maxBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_AddBroadcastable struct {
	AddBroadcastable *AddBroadcastableLayerParams `protobuf:"bytes,880,opt,name=addBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_PowBroadcastable struct {
	PowBroadcastable *PowBroadcastableLayerParams `protobuf:"bytes,885,opt,name=powBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_DivideBroadcastable struct {
	DivideBroadcastable *DivideBroadcastableLayerParams `protobuf:"bytes,890,opt,name=divideBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_FloorDivBroadcastable struct {
	FloorDivBroadcastable *FloorDivBroadcastableLayerParams `protobuf:"bytes,895,opt,name=floorDivBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_MultiplyBroadcastable struct {
	MultiplyBroadcastable *MultiplyBroadcastableLayerParams `protobuf:"bytes,900,opt,name=multiplyBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_SubtractBroadcastable struct {
	SubtractBroadcastable *SubtractBroadcastableLayerParams `protobuf:"bytes,905,opt,name=subtractBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_Tile struct {
	// Tensor Manipulations
	Tile *TileLayerParams `protobuf:"bytes,920,opt,name=tile,proto3,oneof"`
}

type NeuralNetworkLayer_Stack struct {
	Stack *StackLayerParams `protobuf:"bytes,925,opt,name=stack,proto3,oneof"`
}

type NeuralNetworkLayer_Gather struct {
	Gather *GatherLayerParams `protobuf:"bytes,930,opt,name=gather,proto3,oneof"`
}

type NeuralNetworkLayer_Scatter struct {
	Scatter *ScatterLayerParams `protobuf:"bytes,935,opt,name=scatter,proto3,oneof"`
}

type NeuralNetworkLayer_GatherND struct {
	GatherND *GatherNDLayerParams `protobuf:"bytes,940,opt,name=gatherND,proto3,oneof"`
}

type NeuralNetworkLayer_ScatterND struct {
	ScatterND *ScatterNDLayerParams `protobuf:"bytes,945,opt,name=scatterND,proto3,oneof"`
}

type NeuralNetworkLayer_SoftmaxND struct {
	SoftmaxND *SoftmaxNDLayerParams `protobuf:"bytes,950,opt,name=softmaxND,proto3,oneof"`
}

type NeuralNetworkLayer_GatherAlongAxis struct {
	GatherAlongAxis *GatherAlongAxisLayerParams `protobuf:"bytes,952,opt,name=gatherAlongAxis,proto3,oneof"`
}

type NeuralNetworkLayer_ScatterAlongAxis struct {
	ScatterAlongAxis *ScatterAlongAxisLayerParams `protobuf:"bytes,954,opt,name=scatterAlongAxis,proto3,oneof"`
}

type NeuralNetworkLayer_Reverse struct {
	Reverse *ReverseLayerParams `protobuf:"bytes,960,opt,name=reverse,proto3,oneof"`
}

type NeuralNetworkLayer_ReverseSeq struct {
	ReverseSeq *ReverseSeqLayerParams `protobuf:"bytes,965,opt,name=reverseSeq,proto3,oneof"`
}

type NeuralNetworkLayer_SplitND struct {
	SplitND *SplitNDLayerParams `protobuf:"bytes,975,opt,name=splitND,proto3,oneof"`
}

type NeuralNetworkLayer_ConcatND struct {
	ConcatND *ConcatNDLayerParams `protobuf:"bytes,980,opt,name=concatND,proto3,oneof"`
}

type NeuralNetworkLayer_Transpose struct {
	Transpose *TransposeLayerParams `protobuf:"bytes,985,opt,name=transpose,proto3,oneof"`
}

type NeuralNetworkLayer_SliceStatic struct {
	SliceStatic *SliceStaticLayerParams `protobuf:"bytes,995,opt,name=sliceStatic,proto3,oneof"`
}

type NeuralNetworkLayer_SliceDynamic struct {
	SliceDynamic *SliceDynamicLayerParams `protobuf:"bytes,1000,opt,name=sliceDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_SlidingWindows struct {
	SlidingWindows *SlidingWindowsLayerParams `protobuf:"bytes,1005,opt,name=slidingWindows,proto3,oneof"`
}

type NeuralNetworkLayer_TopK struct {
	TopK *TopKLayerParams `protobuf:"bytes,1015,opt,name=topK,proto3,oneof"`
}

type NeuralNetworkLayer_ArgMin struct {
	ArgMin *ArgMinLayerParams `protobuf:"bytes,1020,opt,name=argMin,proto3,oneof"`
}

type NeuralNetworkLayer_ArgMax struct {
	ArgMax *ArgMaxLayerParams `protobuf:"bytes,1025,opt,name=argMax,proto3,oneof"`
}

type NeuralNetworkLayer_EmbeddingND struct {
	EmbeddingND *EmbeddingNDLayerParams `protobuf:"bytes,1040,opt,name=embeddingND,proto3,oneof"`
}

type NeuralNetworkLayer_BatchedMatmul struct {
	BatchedMatmul *BatchedMatMulLayerParams `protobuf:"bytes,1045,opt,name=batchedMatmul,proto3,oneof"`
}

type NeuralNetworkLayer_GetShape struct {
	// Tensor Allocation / Reshape-related Operations
	GetShape *GetShapeLayerParams `protobuf:"bytes,1065,opt,name=getShape,proto3,oneof"`
}

type NeuralNetworkLayer_LoadConstantND struct {
	LoadConstantND *LoadConstantNDLayerParams `protobuf:"bytes,1070,opt,name=loadConstantND,proto3,oneof"`
}

type NeuralNetworkLayer_FillLike struct {
	FillLike *FillLikeLayerParams `protobuf:"bytes,1080,opt,name=fillLike,proto3,oneof"`
}

type NeuralNetworkLayer_FillStatic struct {
	FillStatic *FillStaticLayerParams `protobuf:"bytes,1085,opt,name=fillStatic,proto3,oneof"`
}

type NeuralNetworkLayer_FillDynamic struct {
	FillDynamic *FillDynamicLayerParams `protobuf:"bytes,1090,opt,name=fillDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_BroadcastToLike struct {
	BroadcastToLike *BroadcastToLikeLayerParams `protobuf:"bytes,1100,opt,name=broadcastToLike,proto3,oneof"`
}

type NeuralNetworkLayer_BroadcastToStatic struct {
	BroadcastToStatic *BroadcastToStaticLayerParams `protobuf:"bytes,1105,opt,name=broadcastToStatic,proto3,oneof"`
}

type NeuralNetworkLayer_BroadcastToDynamic struct {
	BroadcastToDynamic *BroadcastToDynamicLayerParams `protobuf:"bytes,1110,opt,name=broadcastToDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_Squeeze struct {
	Squeeze *SqueezeLayerParams `protobuf:"bytes,1120,opt,name=squeeze,proto3,oneof"`
}

type NeuralNetworkLayer_ExpandDims struct {
	ExpandDims *ExpandDimsLayerParams `protobuf:"bytes,1125,opt,name=expandDims,proto3,oneof"`
}

type NeuralNetworkLayer_FlattenTo2D struct {
	FlattenTo2D *FlattenTo2DLayerParams `protobuf:"bytes,1130,opt,name=flattenTo2D,proto3,oneof"`
}

type NeuralNetworkLayer_ReshapeLike struct {
	ReshapeLike *ReshapeLikeLayerParams `protobuf:"bytes,1135,opt,name=reshapeLike,proto3,oneof"`
}

type NeuralNetworkLayer_ReshapeStatic struct {
	ReshapeStatic *ReshapeStaticLayerParams `protobuf:"bytes,1140,opt,name=reshapeStatic,proto3,oneof"`
}

type NeuralNetworkLayer_ReshapeDynamic struct {
	ReshapeDynamic *ReshapeDynamicLayerParams `protobuf:"bytes,1145,opt,name=reshapeDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_RankPreservingReshape struct {
	RankPreservingReshape *RankPreservingReshapeLayerParams `protobuf:"bytes,1150,opt,name=rankPreservingReshape,proto3,oneof"`
}

type NeuralNetworkLayer_ConstantPad struct {
	ConstantPad *ConstantPaddingLayerParams `protobuf:"bytes,1155,opt,name=constantPad,proto3,oneof"`
}

type NeuralNetworkLayer_RandomNormalLike struct {
	// Random Distributions
	RandomNormalLike *RandomNormalLikeLayerParams `protobuf:"bytes,1170,opt,name=randomNormalLike,proto3,oneof"`
}

type NeuralNetworkLayer_RandomNormalStatic struct {
	RandomNormalStatic *RandomNormalStaticLayerParams `protobuf:"bytes,1175,opt,name=randomNormalStatic,proto3,oneof"`
}

type NeuralNetworkLayer_RandomNormalDynamic struct {
	RandomNormalDynamic *RandomNormalDynamicLayerParams `protobuf:"bytes,1180,opt,name=randomNormalDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_RandomUniformLike struct {
	RandomUniformLike *RandomUniformLikeLayerParams `protobuf:"bytes,1190,opt,name=randomUniformLike,proto3,oneof"`
}

type NeuralNetworkLayer_RandomUniformStatic struct {
	RandomUniformStatic *RandomUniformStaticLayerParams `protobuf:"bytes,1195,opt,name=randomUniformStatic,proto3,oneof"`
}

type NeuralNetworkLayer_RandomUniformDynamic struct {
	RandomUniformDynamic *RandomUniformDynamicLayerParams `protobuf:"bytes,1200,opt,name=randomUniformDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_RandomBernoulliLike struct {
	RandomBernoulliLike *RandomBernoulliLikeLayerParams `protobuf:"bytes,1210,opt,name=randomBernoulliLike,proto3,oneof"`
}

type NeuralNetworkLayer_RandomBernoulliStatic struct {
	RandomBernoulliStatic *RandomBernoulliStaticLayerParams `protobuf:"bytes,1215,opt,name=randomBernoulliStatic,proto3,oneof"`
}

type NeuralNetworkLayer_RandomBernoulliDynamic struct {
	RandomBernoulliDynamic *RandomBernoulliDynamicLayerParams `protobuf:"bytes,1220,opt,name=randomBernoulliDynamic,proto3,oneof"`
}

type NeuralNetworkLayer_CategoricalDistribution struct {
	CategoricalDistribution *CategoricalDistributionLayerParams `protobuf:"bytes,1230,opt,name=categoricalDistribution,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceL1 struct {
	// Reduction-related Layers:
	ReduceL1 *ReduceL1LayerParams `protobuf:"bytes,1250,opt,name=reduceL1,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceL2 struct {
	ReduceL2 *ReduceL2LayerParams `protobuf:"bytes,1255,opt,name=reduceL2,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceMax struct {
	ReduceMax *ReduceMaxLayerParams `protobuf:"bytes,1260,opt,name=reduceMax,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceMin struct {
	ReduceMin *ReduceMinLayerParams `protobuf:"bytes,1265,opt,name=reduceMin,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceSum struct {
	ReduceSum *ReduceSumLayerParams `protobuf:"bytes,1270,opt,name=reduceSum,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceProd struct {
	ReduceProd *ReduceProdLayerParams `protobuf:"bytes,1275,opt,name=reduceProd,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceMean struct {
	ReduceMean *ReduceMeanLayerParams `protobuf:"bytes,1280,opt,name=reduceMean,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceLogSum struct {
	ReduceLogSum *ReduceLogSumLayerParams `protobuf:"bytes,1285,opt,name=reduceLogSum,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceSumSquare struct {
	ReduceSumSquare *ReduceSumSquareLayerParams `protobuf:"bytes,1290,opt,name=reduceSumSquare,proto3,oneof"`
}

type NeuralNetworkLayer_ReduceLogSumExp struct {
	ReduceLogSumExp *ReduceLogSumExpLayerParams `protobuf:"bytes,1295,opt,name=reduceLogSumExp,proto3,oneof"`
}

type NeuralNetworkLayer_WhereNonZero struct {
	// Masking / Selection Layers
	WhereNonZero *WhereNonZeroLayerParams `protobuf:"bytes,1313,opt,name=whereNonZero,proto3,oneof"`
}

type NeuralNetworkLayer_MatrixBandPart struct {
	MatrixBandPart *MatrixBandPartLayerParams `protobuf:"bytes,1315,opt,name=matrixBandPart,proto3,oneof"`
}

type NeuralNetworkLayer_LowerTriangular struct {
	LowerTriangular *LowerTriangularLayerParams `protobuf:"bytes,1320,opt,name=lowerTriangular,proto3,oneof"`
}

type NeuralNetworkLayer_UpperTriangular struct {
	UpperTriangular *UpperTriangularLayerParams `protobuf:"bytes,1325,opt,name=upperTriangular,proto3,oneof"`
}

type NeuralNetworkLayer_WhereBroadcastable struct {
	WhereBroadcastable *WhereBroadcastableLayerParams `protobuf:"bytes,1330,opt,name=whereBroadcastable,proto3,oneof"`
}

type NeuralNetworkLayer_LayerNormalization struct {
	// Normalization Layers
	LayerNormalization *LayerNormalizationLayerParams `protobuf:"bytes,1350,opt,name=layerNormalization,proto3,oneof"`
}

type NeuralNetworkLayer_NonMaximumSuppression struct {
	NonMaximumSuppression *NonMaximumSuppressionLayerParams `protobuf:"bytes,1400,opt,name=NonMaximumSuppression,proto3,oneof"`
}

type NeuralNetworkLayer_OneHot struct {
	// Following layers are available only after Core ML Specification
	// version >= 5 (iOS >= 14, macOS >= 11.0)
	OneHot *OneHotLayerParams `protobuf:"bytes,1450,opt,name=oneHot,proto3,oneof"`
}

type NeuralNetworkLayer_CumSum struct {
	CumSum *CumSumLayerParams `protobuf:"bytes,1455,opt,name=cumSum,proto3,oneof"`
}

type NeuralNetworkLayer_ClampedReLU struct {
	ClampedReLU *ClampedReLULayerParams `protobuf:"bytes,1460,opt,name=clampedReLU,proto3,oneof"`
}

type NeuralNetworkLayer_ArgSort struct {
	ArgSort *ArgSortLayerParams `protobuf:"bytes,1461,opt,name=argSort,proto3,oneof"`
}

type NeuralNetworkLayer_Pooling3D struct {
	Pooling3D *Pooling3DLayerParams `protobuf:"bytes,1465,opt,name=pooling3d,proto3,oneof"`
}

type NeuralNetworkLayer_GlobalPooling3D struct {
	GlobalPooling3D *GlobalPooling3DLayerParams `protobuf:"bytes,1466,opt,name=globalPooling3d,proto3,oneof"`
}

type NeuralNetworkLayer_SliceBySize struct {
	SliceBySize *SliceBySizeLayerParams `protobuf:"bytes,1470,opt,name=sliceBySize,proto3,oneof"`
}

type NeuralNetworkLayer_Convolution3D struct {
	Convolution3D *Convolution3DLayerParams `protobuf:"bytes,1471,opt,name=convolution3d,proto3,oneof"`
}

func (*NeuralNetworkLayer_Convolution) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Pooling) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Activation) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_InnerProduct) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Embedding) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Batchnorm) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Mvn) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_L2Normalize) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Softmax) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Lrn) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Crop) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Padding) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Upsample) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ResizeBilinear) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_CropResize) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Unary) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Add) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Multiply) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Average) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Scale) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Bias) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Max) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Min) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Dot) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Reduce) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LoadConstant) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Reshape) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Flatten) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Permute) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Concat) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Split) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SequenceRepeat) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReorganizeData) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Slice) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SimpleRecurrent) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Gru) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_UniDirectionalLSTM) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_BiDirectionalLSTM) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Custom) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Copy) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Branch) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Loop) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LoopBreak) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LoopContinue) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RangeStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RangeDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Clip) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Ceil) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Floor) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Sign) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Round) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Exp2) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Sin) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Cos) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Tan) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Asin) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Acos) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Atan) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Sinh) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Cosh) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Tanh) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Asinh) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Acosh) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Atanh) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Erf) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Gelu) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Equal) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_NotEqual) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LessThan) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LessEqual) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_GreaterThan) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_GreaterEqual) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LogicalOr) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LogicalXor) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LogicalNot) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LogicalAnd) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ModBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_MinBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_MaxBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_AddBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_PowBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_DivideBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_FloorDivBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_MultiplyBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SubtractBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Tile) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Stack) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Gather) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Scatter) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_GatherND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ScatterND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SoftmaxND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_GatherAlongAxis) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ScatterAlongAxis) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Reverse) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReverseSeq) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SplitND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ConcatND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Transpose) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SliceStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SliceDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SlidingWindows) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_TopK) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ArgMin) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ArgMax) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_EmbeddingND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_BatchedMatmul) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_GetShape) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LoadConstantND) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_FillLike) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_FillStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_FillDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_BroadcastToLike) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_BroadcastToStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_BroadcastToDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Squeeze) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ExpandDims) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_FlattenTo2D) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReshapeLike) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReshapeStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReshapeDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RankPreservingReshape) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ConstantPad) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomNormalLike) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomNormalStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomNormalDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomUniformLike) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomUniformStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomUniformDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomBernoulliLike) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomBernoulliStatic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_RandomBernoulliDynamic) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_CategoricalDistribution) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceL1) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceL2) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceMax) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceMin) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceSum) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceProd) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceMean) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceLogSum) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceSumSquare) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ReduceLogSumExp) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_WhereNonZero) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_MatrixBandPart) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LowerTriangular) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_UpperTriangular) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_WhereBroadcastable) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_LayerNormalization) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_NonMaximumSuppression) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_OneHot) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_CumSum) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ClampedReLU) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_ArgSort) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Pooling3D) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_GlobalPooling3D) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_SliceBySize) isNeuralNetworkLayer_Layer() {}

func (*NeuralNetworkLayer_Convolution3D) isNeuralNetworkLayer_Layer() {}

// Branching Layer
//
// A layer that provides the functionality of branching or an If-Else block.
//
// Must have 1 input. There are no outputs as the execution is transferred to either the
// if or the else branch based on the value of the input.
//
// Input is the condition predicate. Must be a scalar (length 1 tensor).
type BranchLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// execute this graph if the absolute value of the input Tensor is greater than 1e-6
	// This must be present.
	IfBranch *NeuralNetwork `protobuf:"bytes,1,opt,name=ifBranch,proto3" json:"ifBranch,omitempty"`
	// execute this graph if the absolute value of the input Tensor is less than 1e-6
	// This is optional.
	ElseBranch    *NeuralNetwork `protobuf:"bytes,2,opt,name=elseBranch,proto3" json:"elseBranch,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BranchLayerParams) Reset() {
	*x = BranchLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BranchLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BranchLayerParams) ProtoMessage() {}

func (x *BranchLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BranchLayerParams.ProtoReflect.Descriptor instead.
func (*BranchLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{20}
}

func (x *BranchLayerParams) GetIfBranch() *NeuralNetwork {
	if x != nil {
		return x.IfBranch
	}
	return nil
}

func (x *BranchLayerParams) GetElseBranch() *NeuralNetwork {
	if x != nil {
		return x.ElseBranch
	}
	return nil
}

// Loop Layer
//
// A layer that provides the functionality of a "for" loop or a "while" loop.
//
// There are either no inputs or 1 input. When an input is present, it corresponds to the maximum loop count,
// in that case the value of the "maxLoopIterations" field is ignored. Input must be a scalar.
// (For description below, maxLoopIterations is assumed to be the value of the input, when its present)
//
// No outputs are produced. Blobs produced by the condition or the body network are visible in the scope of the overall network.
//
// "conditionNetwork" must produce a tensor with the name specified in the "conditionVar" field.
//
// There are 3 possible cases for determining the termination condition:
//
// Case 1:
//
// If there is no "conditionNetwork", in this case the layer corresponds to a pure for loop, which is run "maxLoopIterations" number of times.
// Equivalent pseudo-code:
//
// for loopIterator = 0 : maxLoopIterations
//
//	bodyNetwork()
//
// Case 2:
//
// "conditionNetwork" is present, and "maxLoopIterations" is 0 and there is no input,
// in this case the layer corresponds to a while loop. Equivalent pseudo-code:
//
// conditionVar = conditionNetwork()
// while conditionVar:
//
//	bodyNetwork()
//	conditionVar = conditionNetwork()
//
// Case 3:
//
// "conditionNetwork" is provided, and "maxLoopIterations" is positive or there is an input,
// in this case the layer corresponds to a while loop with a joint condition. Equivalent pseudo-code:
//
// loopIterator = 0
// conditionVar = conditionNetwork()
// while (conditionVar and loopIterator < maxLoopIterations):
//
//	bodyNetwork()
//	loopIterator = loopIterator + 1
//	conditionVar = conditionNetwork()
type LoopLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// maximum number of iterations. Ignored if input is present.
	MaxLoopIterations uint64 `protobuf:"varint,1,opt,name=maxLoopIterations,proto3" json:"maxLoopIterations,omitempty"`
	// This field provides the name of the tensor which is produced by the conditionNetwork
	// and whose value is checked to start/continue/terminate the loop. Value close to 0.0f is treated as False.
	// This field is optional.
	// Must be a non empty string if and only if "conditionNetwork" is present.
	ConditionVar string `protobuf:"bytes,2,opt,name=conditionVar,proto3" json:"conditionVar,omitempty"`
	// Must generate a tensor with the name provided in the "conditionVar" field.
	// This field is optional.
	// Must be present if and only if "conditionVar" field is a non empty string.
	ConditionNetwork *NeuralNetwork `protobuf:"bytes,3,opt,name=conditionNetwork,proto3" json:"conditionNetwork,omitempty"`
	// Body of the loop.
	// This field must be present.
	BodyNetwork   *NeuralNetwork `protobuf:"bytes,4,opt,name=bodyNetwork,proto3" json:"bodyNetwork,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoopLayerParams) Reset() {
	*x = LoopLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoopLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoopLayerParams) ProtoMessage() {}

func (x *LoopLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoopLayerParams.ProtoReflect.Descriptor instead.
func (*LoopLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{21}
}

func (x *LoopLayerParams) GetMaxLoopIterations() uint64 {
	if x != nil {
		return x.MaxLoopIterations
	}
	return 0
}

func (x *LoopLayerParams) GetConditionVar() string {
	if x != nil {
		return x.ConditionVar
	}
	return ""
}

func (x *LoopLayerParams) GetConditionNetwork() *NeuralNetwork {
	if x != nil {
		return x.ConditionNetwork
	}
	return nil
}

func (x *LoopLayerParams) GetBodyNetwork() *NeuralNetwork {
	if x != nil {
		return x.BodyNetwork
	}
	return nil
}

// Loop break Layer
//
// Terminate the loop that has this layer.
// If present, it should always reside in the "bodyNetwork" of the loop layer
//
// No inputs/outputs
type LoopBreakLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoopBreakLayerParams) Reset() {
	*x = LoopBreakLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoopBreakLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoopBreakLayerParams) ProtoMessage() {}

func (x *LoopBreakLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoopBreakLayerParams.ProtoReflect.Descriptor instead.
func (*LoopBreakLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{22}
}

// Loop Continue Layer
//
// Stop the current loop iteration and continue on the next iteration.
// If present, it should always reside in the "bodyNetwork" of the loop layer
//
// No inputs/outputs
type LoopContinueLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoopContinueLayerParams) Reset() {
	*x = LoopContinueLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoopContinueLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoopContinueLayerParams) ProtoMessage() {}

func (x *LoopContinueLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoopContinueLayerParams.ProtoReflect.Descriptor instead.
func (*LoopContinueLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{23}
}

// Copy Layer
//
// A layer that copies its input tensor to the output tensor.
// Must have 1 input and 1 output, with distinct names.
// This is the only layer that is allowed to re-generate an output that is already present in the neural network prior to this layer,
// in which case it will overwrite the output tensor.
type CopyLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CopyLayerParams) Reset() {
	*x = CopyLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CopyLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CopyLayerParams) ProtoMessage() {}

func (x *CopyLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CopyLayerParams.ProtoReflect.Descriptor instead.
func (*CopyLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{24}
}

// GreaterThan Layer
//
// Either 1 or 2 inputs.
// Produces 1 output.
// Perform elementwise greater than operation.
//
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = x1 > x2
//	    or
//	y = x1 > alpha, if only one input is provided
//
// Broadcasting is supported.
type GreaterThanLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compare to the scalar value provided here if there is 1 input
	Alpha         float32 `protobuf:"fixed32,2,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GreaterThanLayerParams) Reset() {
	*x = GreaterThanLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GreaterThanLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GreaterThanLayerParams) ProtoMessage() {}

func (x *GreaterThanLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GreaterThanLayerParams.ProtoReflect.Descriptor instead.
func (*GreaterThanLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{25}
}

func (x *GreaterThanLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// GreaterEqual Layer
//
// Either 1 or 2 inputs.
// Produces 1 output.
// Perform elementwise greater equal operation.
//
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = x1 >= x2
//	    or
//	y = x1 >= alpha, if only one input is provided
//
// Broadcasting is supported.
type GreaterEqualLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compare to the scalar value provided here if there is 1 input
	Alpha         float32 `protobuf:"fixed32,2,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GreaterEqualLayerParams) Reset() {
	*x = GreaterEqualLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GreaterEqualLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GreaterEqualLayerParams) ProtoMessage() {}

func (x *GreaterEqualLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GreaterEqualLayerParams.ProtoReflect.Descriptor instead.
func (*GreaterEqualLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{26}
}

func (x *GreaterEqualLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// LessThan Layer
//
// Either 1 or 2 inputs.
// Produces 1 output.
// Perform elementwise less than operation.
//
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = x1 < x2
//	    or
//	y = x1 < alpha, if only one input is provided
//
// Broadcasting is supported.
type LessThanLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compare to the scalar value provided here if there is 1 input
	Alpha         float32 `protobuf:"fixed32,2,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LessThanLayerParams) Reset() {
	*x = LessThanLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LessThanLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LessThanLayerParams) ProtoMessage() {}

func (x *LessThanLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LessThanLayerParams.ProtoReflect.Descriptor instead.
func (*LessThanLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{27}
}

func (x *LessThanLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// LessEqual Layer
//
// Either 1 or 2 inputs.
// Produces 1 output.
// Perform elementwise less equal operation.
//
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = x1 <= x2
//	    or
//	y = x1 <= alpha, if only one input is provided
//
// Broadcasting is supported.
type LessEqualLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compare to the scalar value provided here if there is 1 input
	Alpha         float32 `protobuf:"fixed32,2,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LessEqualLayerParams) Reset() {
	*x = LessEqualLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LessEqualLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LessEqualLayerParams) ProtoMessage() {}

func (x *LessEqualLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LessEqualLayerParams.ProtoReflect.Descriptor instead.
func (*LessEqualLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{28}
}

func (x *LessEqualLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// Equal Layer
//
// Either 1 or 2 inputs.
// Produces 1 output.
// Perform elementwise equal operation.
//
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = x1 == x2
//	    or
//	y = x1 == alpha, if only one input is provided
//
// Broadcasting is supported.
type EqualLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compare to the scalar value provided here if there is 1 input
	Alpha         float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EqualLayerParams) Reset() {
	*x = EqualLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[29]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EqualLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EqualLayerParams) ProtoMessage() {}

func (x *EqualLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[29]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EqualLayerParams.ProtoReflect.Descriptor instead.
func (*EqualLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{29}
}

func (x *EqualLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// NotEqual Layer
//
// Either 1 or 2 inputs.
// Produces 1 output.
// Perform elementwise not equal operation.
//
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = x1 != x2
//	    or
//	y = x1 != alpha, if only one input is provided
//
// Broadcasting is supported.
type NotEqualLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compare to the scalar value provided here if there is 1 input
	Alpha         float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NotEqualLayerParams) Reset() {
	*x = NotEqualLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[30]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NotEqualLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NotEqualLayerParams) ProtoMessage() {}

func (x *NotEqualLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[30]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NotEqualLayerParams.ProtoReflect.Descriptor instead.
func (*NotEqualLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{30}
}

func (x *NotEqualLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// LogicalAnd Layer
//
// Must have 2 inputs, produces 1 output.
// Perform elementwise logical AND operation.
//
// Input is considered False if equal to 0.0f otherwise True.
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = AND(x1, x2)
//
// Broadcasting is supported.
type LogicalAndLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LogicalAndLayerParams) Reset() {
	*x = LogicalAndLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[31]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LogicalAndLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LogicalAndLayerParams) ProtoMessage() {}

func (x *LogicalAndLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[31]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LogicalAndLayerParams.ProtoReflect.Descriptor instead.
func (*LogicalAndLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{31}
}

// LogicalOr Layer
//
// Must have 2 inputs, produces 1 output.
// Perform elementwise logical OR operation.
//
// Input is considered False if equal to 0.0f otherwise True.
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = OR(x1, x2)
//
// Broadcasting is supported.
type LogicalOrLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LogicalOrLayerParams) Reset() {
	*x = LogicalOrLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[32]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LogicalOrLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LogicalOrLayerParams) ProtoMessage() {}

func (x *LogicalOrLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[32]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LogicalOrLayerParams.ProtoReflect.Descriptor instead.
func (*LogicalOrLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{32}
}

// LogicalXor Layer
//
// Must have 2 inputs, produces 1 output.
// Perform elementwise logical XOR operation.
//
// Input is considered False if equal to 0.0f otherwise True.
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = XOR(x1, x2)
//
// Broadcasting is supported.
type LogicalXorLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LogicalXorLayerParams) Reset() {
	*x = LogicalXorLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[33]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LogicalXorLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LogicalXorLayerParams) ProtoMessage() {}

func (x *LogicalXorLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[33]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LogicalXorLayerParams.ProtoReflect.Descriptor instead.
func (*LogicalXorLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{33}
}

// LogicalNot Layer
//
// Must have 1 input, produces 1 output.
// Perform elementwise logical NOT operation.
//
// Input is considered False if equal to 0.0f otherwise True.
// Output is 1.0f if the condition is true otherwise 0.0f.
//
// .. code::
//
//	y = NOT(x)
type LogicalNotLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LogicalNotLayerParams) Reset() {
	*x = LogicalNotLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[34]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LogicalNotLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LogicalNotLayerParams) ProtoMessage() {}

func (x *LogicalNotLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[34]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LogicalNotLayerParams.ProtoReflect.Descriptor instead.
func (*LogicalNotLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{34}
}

// Specifies the amount of spatial border to be either padded or cropped.
//
// For padding:
//
// .. code::
//
//	H_out = borderAmounts[0].startEdgeSize + H_in + borderAmounts[0].endEdgeSize
//	W_out = borderAmounts[1].startEdgeSize + W_in + borderAmounts[1].endEdgeSize
//
//	topPaddingAmount == Height startEdgeSize
//	bottomPaddingAmount == Height endEdgeSize
//	leftPaddingAmount == Width startEdgeSize
//	rightPaddingAmount == Width endEdgeSize
//
// For cropping:
//
// .. code::
//
//	H_out = (-borderAmounts[0].startEdgeSize) + H_in + (-borderAmounts[0].endEdgeSize)
//	W_out = (-borderAmounts[1].startEdgeSize) + W_in + (-borderAmounts[1].endEdgeSize)
//
//	topCropAmount == Height startEdgeSize
//	bottomCropAmount == Height endEdgeSize
//	leftCropAmount == Width startEdgeSize
//	rightCropAmount == Width endEdgeSize
type BorderAmounts struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The border amounts.
	// This must be length 2 in the order “[H, W]“.
	BorderAmounts []*BorderAmounts_EdgeSizes `protobuf:"bytes,10,rep,name=borderAmounts,proto3" json:"borderAmounts,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BorderAmounts) Reset() {
	*x = BorderAmounts{}
	mi := &file_NeuralNetwork_proto_msgTypes[35]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BorderAmounts) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BorderAmounts) ProtoMessage() {}

func (x *BorderAmounts) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[35]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BorderAmounts.ProtoReflect.Descriptor instead.
func (*BorderAmounts) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{35}
}

func (x *BorderAmounts) GetBorderAmounts() []*BorderAmounts_EdgeSizes {
	if x != nil {
		return x.BorderAmounts
	}
	return nil
}

// Specifies the type of padding to be used with Convolution/Deconvolution and Pooling layers.
// After padding, input spatial shape: “[H_in, W_in]“, gets modified to the
// output spatial shape “[H_out, W_out]“.
//
// .. code::
//
//	topPaddingAmount == Height startEdgeSize == borderAmounts[0].startEdgeSize
//	bottomPaddingAmount == Height endEdgeSize == borderAmounts[0].endEdgeSize
//	leftPaddingAmount == Width startEdgeSize == borderAmounts[1].startEdgeSize
//	rightPaddingAmount == Width endEdgeSize == borderAmounts[1].endEdgeSize
//
// With Convolution or Pooling:
//
// .. code::
//
//	H_out = int_division_round_down((H_in + topPaddingAmount + bottomPaddingAmount - KernelSize[0]),stride[0]) + 1
//
// which is same as:
//
// .. code::
//
//	H_out = int_division_round_up((H_in + topPaddingAmount + bottomPaddingAmount - KernelSize[0] + 1),stride[0])
//
// With Deconvolution:
//
// .. code::
//
//	H_out = (H_in-1) * stride[0] + kernelSize[0] - (topPaddingAmount + bottomPaddingAmount)
//
// The equivalent expressions hold true for “W_out“ as well.
//
// By default, the values of “paddingAmounts“ are set to “0“,
// which results in a "true" valid padding.
// If non-zero values are provided for “paddingAmounts“,
// "valid" convolution/pooling is performed within the spatially expanded input.
type ValidPadding struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	PaddingAmounts *BorderAmounts         `protobuf:"bytes,1,opt,name=paddingAmounts,proto3" json:"paddingAmounts,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ValidPadding) Reset() {
	*x = ValidPadding{}
	mi := &file_NeuralNetwork_proto_msgTypes[36]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ValidPadding) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ValidPadding) ProtoMessage() {}

func (x *ValidPadding) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[36]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ValidPadding.ProtoReflect.Descriptor instead.
func (*ValidPadding) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{36}
}

func (x *ValidPadding) GetPaddingAmounts() *BorderAmounts {
	if x != nil {
		return x.PaddingAmounts
	}
	return nil
}

// Specifies the type of padding to be used with Convolution/Deconvolution and pooling layers.
// After padding, input spatial shape: “[H_in, W_in]“, gets modified to the
// output spatial shape “[H_out, W_out]“.
// With Convolution or pooling:
//
// .. code::
//
//	H_out = int_division_round_up(H_in,stride[0])
//	W_out = int_division_round_up(W_in,stride[1])
//
// This is achieved by using the following padding amounts:
//
// .. code::
//
//	totalPaddingHeight = max(0,(H_out-1) * stride[0] + KernelSize[0] - Hin)
//	totalPaddingWidth = max(0,(W_out-1) * stride[1] + KernelSize[1] - Win)
//
// There are two modes of asymmetry:
// “BOTTOM_RIGHT_HEAVY“, and “TOP_LEFT_HEAVY“.
//
// If the mode is “BOTTOM_RIGHT_HEAVY“:
//
// .. code::
//
//	topPaddingAmount = floor(totalPaddingHeight / 2)
//	bottomPaddingAmount = totalPaddingHeight - topPaddingAmount
//	leftPaddingAmount = floor(totalPaddingWidth / 2)
//	rightPaddingAmount = totalPaddingWidth - leftPaddingAmount
//
// If the mode is “TOP_LEFT_HEAVY“:
//
// .. code::
//
//	bottomPaddingAmount = floor(totalPaddingHeight / 2)
//	topPaddingAmount = totalPaddingHeight - bottomPaddingAmount
//	rightPaddingAmount = floor(totalPaddingWidth / 2)
//	leftPaddingAmount = totalPaddingWidth - rightPaddingAmount
//
// With Deconvolution:
//
// .. code::
//
//	H_out = H_in * stride[0]
//	W_out = W_in * stride[1]
type SamePadding struct {
	state         protoimpl.MessageState      `protogen:"open.v1"`
	AsymmetryMode SamePadding_SamePaddingMode `protobuf:"varint,1,opt,name=asymmetryMode,proto3,enum=CoreML.Specification.SamePadding_SamePaddingMode" json:"asymmetryMode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SamePadding) Reset() {
	*x = SamePadding{}
	mi := &file_NeuralNetwork_proto_msgTypes[37]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SamePadding) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SamePadding) ProtoMessage() {}

func (x *SamePadding) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[37]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SamePadding.ProtoReflect.Descriptor instead.
func (*SamePadding) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{37}
}

func (x *SamePadding) GetAsymmetryMode() SamePadding_SamePaddingMode {
	if x != nil {
		return x.AsymmetryMode
	}
	return SamePadding_BOTTOM_RIGHT_HEAVY
}

// Specifies how grid points are sampled from an interval.
// Without the loss of generality, assume the interval to be [0, X-1] from which N points are to be sampled.
// Here X may correspond to an input image's height or width.
// All the methods can be expressed in terms of numpy's linspace function, along with the constraint that grid points have to lie in the interval [0, X-1].
// Note: numpy.linspace(start = start, end = end, num = N, endpoint = True) corresponds to sampling
// N points uniformly from the interval [start, end], endpoints included.
// The methods vary in how the “start“ and “end“ values are computed.
type SamplingMode struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	SamplingMethod SamplingMode_Method    `protobuf:"varint,1,opt,name=samplingMethod,proto3,enum=CoreML.Specification.SamplingMode_Method" json:"samplingMethod,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *SamplingMode) Reset() {
	*x = SamplingMode{}
	mi := &file_NeuralNetwork_proto_msgTypes[38]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SamplingMode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SamplingMode) ProtoMessage() {}

func (x *SamplingMode) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[38]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SamplingMode.ProtoReflect.Descriptor instead.
func (*SamplingMode) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{38}
}

func (x *SamplingMode) GetSamplingMethod() SamplingMode_Method {
	if x != nil {
		return x.SamplingMethod
	}
	return SamplingMode_STRICT_ALIGN_ENDPOINTS_MODE
}

// Specifies the convention used to specify four bounding box coordinates for an image of size (Height, Width).
// The (0,0) coordinate corresponds to the top-left corner of the image.
type BoxCoordinatesMode struct {
	state         protoimpl.MessageState         `protogen:"open.v1"`
	BoxMode       BoxCoordinatesMode_Coordinates `protobuf:"varint,1,opt,name=boxMode,proto3,enum=CoreML.Specification.BoxCoordinatesMode_Coordinates" json:"boxMode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BoxCoordinatesMode) Reset() {
	*x = BoxCoordinatesMode{}
	mi := &file_NeuralNetwork_proto_msgTypes[39]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BoxCoordinatesMode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BoxCoordinatesMode) ProtoMessage() {}

func (x *BoxCoordinatesMode) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[39]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BoxCoordinatesMode.ProtoReflect.Descriptor instead.
func (*BoxCoordinatesMode) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{39}
}

func (x *BoxCoordinatesMode) GetBoxMode() BoxCoordinatesMode_Coordinates {
	if x != nil {
		return x.BoxMode
	}
	return BoxCoordinatesMode_CORNERS_HEIGHT_FIRST
}

// Weights for layer parameters.
// Weights are stored as repeated floating point numbers
// using row-major ordering
// and can represent 1-, 2-, 3-, or 4-dimensional data.
type WeightParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Values specified in single / float / FP32 precision.
	FloatValue []float32 `protobuf:"fixed32,1,rep,packed,name=floatValue,proto3" json:"floatValue,omitempty"`
	// Values in 16-bit half precision floating point.
	Float16Value []byte `protobuf:"bytes,2,opt,name=float16Value,proto3" json:"float16Value,omitempty"`
	// Raw value specification for quantized lower precisions.
	//
	// This field is interpreted as uintN, where N is the number of bits in quantization.
	// E.g. if n=8, the field is interpreted as an array of UINT8.
	// Use this field for quantized parameters unless specifically noted to use
	// int8RawValue.
	RawValue []byte `protobuf:"bytes,30,opt,name=rawValue,proto3" json:"rawValue,omitempty"`
	// Field to be used if int8DynamicQuantize is set in the parent layer.
	// Cannot be set if rawValue is also set.
	// The values in this field are interpreted as INT8.
	//
	// If this field is set, following conditions must hold true:
	// * QuantizationType == LinearQuantizationParams, such that
	//   - size of the "scale" field is 1 and "bias" field is empty in "LinearQuantizationParams"
	Int8RawValue []byte `protobuf:"bytes,31,opt,name=int8RawValue,proto3" json:"int8RawValue,omitempty"`
	// Quantization related parameters.
	Quantization  *QuantizationParams `protobuf:"bytes,40,opt,name=quantization,proto3" json:"quantization,omitempty"`
	IsUpdatable   bool                `protobuf:"varint,50,opt,name=isUpdatable,proto3" json:"isUpdatable,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WeightParams) Reset() {
	*x = WeightParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[40]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WeightParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WeightParams) ProtoMessage() {}

func (x *WeightParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[40]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WeightParams.ProtoReflect.Descriptor instead.
func (*WeightParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{40}
}

func (x *WeightParams) GetFloatValue() []float32 {
	if x != nil {
		return x.FloatValue
	}
	return nil
}

func (x *WeightParams) GetFloat16Value() []byte {
	if x != nil {
		return x.Float16Value
	}
	return nil
}

func (x *WeightParams) GetRawValue() []byte {
	if x != nil {
		return x.RawValue
	}
	return nil
}

func (x *WeightParams) GetInt8RawValue() []byte {
	if x != nil {
		return x.Int8RawValue
	}
	return nil
}

func (x *WeightParams) GetQuantization() *QuantizationParams {
	if x != nil {
		return x.Quantization
	}
	return nil
}

func (x *WeightParams) GetIsUpdatable() bool {
	if x != nil {
		return x.IsUpdatable
	}
	return false
}

// Quantization parameters.
type QuantizationParams struct {
	state        protoimpl.MessageState `protogen:"open.v1"`
	NumberOfBits uint64                 `protobuf:"varint,1,opt,name=numberOfBits,proto3" json:"numberOfBits,omitempty"`
	// Types that are valid to be assigned to QuantizationType:
	//
	//	*QuantizationParams_LinearQuantization
	//	*QuantizationParams_LookupTableQuantization
	QuantizationType isQuantizationParams_QuantizationType `protobuf_oneof:"QuantizationType"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *QuantizationParams) Reset() {
	*x = QuantizationParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[41]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *QuantizationParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*QuantizationParams) ProtoMessage() {}

func (x *QuantizationParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[41]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use QuantizationParams.ProtoReflect.Descriptor instead.
func (*QuantizationParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{41}
}

func (x *QuantizationParams) GetNumberOfBits() uint64 {
	if x != nil {
		return x.NumberOfBits
	}
	return 0
}

func (x *QuantizationParams) GetQuantizationType() isQuantizationParams_QuantizationType {
	if x != nil {
		return x.QuantizationType
	}
	return nil
}

func (x *QuantizationParams) GetLinearQuantization() *LinearQuantizationParams {
	if x != nil {
		if x, ok := x.QuantizationType.(*QuantizationParams_LinearQuantization); ok {
			return x.LinearQuantization
		}
	}
	return nil
}

func (x *QuantizationParams) GetLookupTableQuantization() *LookUpTableQuantizationParams {
	if x != nil {
		if x, ok := x.QuantizationType.(*QuantizationParams_LookupTableQuantization); ok {
			return x.LookupTableQuantization
		}
	}
	return nil
}

type isQuantizationParams_QuantizationType interface {
	isQuantizationParams_QuantizationType()
}

type QuantizationParams_LinearQuantization struct {
	LinearQuantization *LinearQuantizationParams `protobuf:"bytes,101,opt,name=linearQuantization,proto3,oneof"`
}

type QuantizationParams_LookupTableQuantization struct {
	LookupTableQuantization *LookUpTableQuantizationParams `protobuf:"bytes,102,opt,name=lookupTableQuantization,proto3,oneof"`
}

func (*QuantizationParams_LinearQuantization) isQuantizationParams_QuantizationType() {}

func (*QuantizationParams_LookupTableQuantization) isQuantizationParams_QuantizationType() {}

type LinearQuantizationParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Stores scale and bias values corresponding to the quantized weights.
	// Must be an array of 1 element, or an array of C elements, where C
	// is number of output channels. For recurrent layers it is equal to
	// the output vector size.
	//
	// Relationship between quantized weights, unquantized weights, scale and bias:
	//
	// W_unquantized = W_quantized * scale + bias
	Scale         []float32 `protobuf:"fixed32,1,rep,packed,name=scale,proto3" json:"scale,omitempty"`
	Bias          []float32 `protobuf:"fixed32,2,rep,packed,name=bias,proto3" json:"bias,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LinearQuantizationParams) Reset() {
	*x = LinearQuantizationParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[42]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LinearQuantizationParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LinearQuantizationParams) ProtoMessage() {}

func (x *LinearQuantizationParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[42]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LinearQuantizationParams.ProtoReflect.Descriptor instead.
func (*LinearQuantizationParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{42}
}

func (x *LinearQuantizationParams) GetScale() []float32 {
	if x != nil {
		return x.Scale
	}
	return nil
}

func (x *LinearQuantizationParams) GetBias() []float32 {
	if x != nil {
		return x.Bias
	}
	return nil
}

type LookUpTableQuantizationParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Stores look-up table quantization values. Must be an array of
	// (2^numberOfBits) Elements.
	FloatValue    []float32 `protobuf:"fixed32,1,rep,packed,name=floatValue,proto3" json:"floatValue,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LookUpTableQuantizationParams) Reset() {
	*x = LookUpTableQuantizationParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[43]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LookUpTableQuantizationParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LookUpTableQuantizationParams) ProtoMessage() {}

func (x *LookUpTableQuantizationParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[43]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LookUpTableQuantizationParams.ProtoReflect.Descriptor instead.
func (*LookUpTableQuantizationParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{43}
}

func (x *LookUpTableQuantizationParams) GetFloatValue() []float32 {
	if x != nil {
		return x.FloatValue
	}
	return nil
}

// A layer that performs spatial convolution or deconvolution.
//
// .. code::
//
//	y = ConvolutionLayer(x)
//
// Requires 1 or 2 inputs and produces 1 output.
//
// Input
//
//	First Input:
//	  A blob with rank greater than or equal to 4.
//	  Rank 4 blob represents [Batch, channels, height, width].
//	  For ranks greater than 4, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
//	 From Core ML specification version 4 onwards (iOS >= 13, macOS >= 10.15).
//	 convolution layer can have 2 inputs, in which case the second input is
//	 the blob representing the weights. This is allowed when "isDeconvolution" = False.
//	 The weight blob should have shape
//	 ``[outputChannels, kernelChannels, kernelHeight, kernelWidth]``,
//	 where kernelChannels == inputChannels / nGroups.
//
// Output
//
//	Rank is same as the input. e.g.: for rank 4 input, output shape is [B, C_out, H_out, W_out]
//
// If “dilationFactor“ is not 1, effective kernel size is
// modified as follows:
//
// .. code::
//
//	KernelSize[0] <-- (kernelSize[0]-1) * dilationFactor[0] + 1
//	KernelSize[1] <-- (kernelSize[1]-1) * dilationFactor[1] + 1
//
// Type of padding can be “valid“ or “same“. Output spatial dimensions depend on the
// the type of padding. For details, refer to the descriptions of the messages "ValidPadding"
// and "SamePadding". Padded values are all zeros.
//
// For Deconvolution, “ConvolutionPaddingType“ (“valid“ or “same“) is ignored when “outputShape“ is set.
type ConvolutionLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of kernels.
	// Same as “C_out“ used in the layer description.
	OutputChannels uint64 `protobuf:"varint,1,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"`
	// Channel dimension of the kernels.
	// Must be equal to “inputChannels / nGroups“, if isDeconvolution == False
	// Must be equal to “inputChannels“, if isDeconvolution == True
	KernelChannels uint64 `protobuf:"varint,2,opt,name=kernelChannels,proto3" json:"kernelChannels,omitempty"`
	// Group convolution, i.e. weight reuse along channel axis.
	// Input and kernels are divided into g groups
	// and convolution / deconvolution is applied within the groups independently.
	// If not set or 0, it is set to the default value 1.
	NGroups uint64 `protobuf:"varint,10,opt,name=nGroups,proto3" json:"nGroups,omitempty"`
	// Must be length 2 in the order “[H, W]“.
	// If not set, default value “[3, 3]“ is used.
	KernelSize []uint64 `protobuf:"varint,20,rep,packed,name=kernelSize,proto3" json:"kernelSize,omitempty"`
	// Must be length 2 in the order “[H, W]“.
	// If not set, default value “[1, 1]“ is used.
	Stride []uint64 `protobuf:"varint,30,rep,packed,name=stride,proto3" json:"stride,omitempty"`
	// Must be length 2 in order “[H, W]“.
	// If not set, default value “[1, 1]“ is used.
	// It is ignored if “isDeconvolution == true“.
	DilationFactor []uint64 `protobuf:"varint,40,rep,packed,name=dilationFactor,proto3" json:"dilationFactor,omitempty"`
	// The type of padding.
	//
	// Types that are valid to be assigned to ConvolutionPaddingType:
	//
	//	*ConvolutionLayerParams_Valid
	//	*ConvolutionLayerParams_Same
	ConvolutionPaddingType isConvolutionLayerParams_ConvolutionPaddingType `protobuf_oneof:"ConvolutionPaddingType"`
	// Flag to specify whether it is a deconvolution layer.
	IsDeconvolution bool `protobuf:"varint,60,opt,name=isDeconvolution,proto3" json:"isDeconvolution,omitempty"`
	// Flag to specify whether a bias is to be added or not.
	HasBias bool `protobuf:"varint,70,opt,name=hasBias,proto3" json:"hasBias,omitempty"`
	// Weights associated with this layer.
	// If convolution (“isDeconvolution == false“), weights have the shape
	// “[outputChannels, kernelChannels, kernelHeight, kernelWidth]“, where kernelChannels == inputChannels / nGroups
	// If deconvolution (“isDeconvolution == true“) weights have the shape
	// “[kernelChannels, outputChannels / nGroups, kernelHeight, kernelWidth]“, where kernelChannels == inputChannels
	Weights *WeightParams `protobuf:"bytes,90,opt,name=weights,proto3" json:"weights,omitempty"`
	Bias    *WeightParams `protobuf:"bytes,91,opt,name=bias,proto3" json:"bias,omitempty"` // Must be of size [outputChannels].
	// The output shape, which has length 2 “[H_out, W_out]“.
	// This is used only for deconvolution (“isDeconvolution == true“).
	// If not set, the deconvolution output shape is calculated
	// based on “ConvolutionPaddingType“.
	OutputShape   []uint64 `protobuf:"varint,100,rep,packed,name=outputShape,proto3" json:"outputShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConvolutionLayerParams) Reset() {
	*x = ConvolutionLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[44]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConvolutionLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConvolutionLayerParams) ProtoMessage() {}

func (x *ConvolutionLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[44]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConvolutionLayerParams.ProtoReflect.Descriptor instead.
func (*ConvolutionLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{44}
}

func (x *ConvolutionLayerParams) GetOutputChannels() uint64 {
	if x != nil {
		return x.OutputChannels
	}
	return 0
}

func (x *ConvolutionLayerParams) GetKernelChannels() uint64 {
	if x != nil {
		return x.KernelChannels
	}
	return 0
}

func (x *ConvolutionLayerParams) GetNGroups() uint64 {
	if x != nil {
		return x.NGroups
	}
	return 0
}

func (x *ConvolutionLayerParams) GetKernelSize() []uint64 {
	if x != nil {
		return x.KernelSize
	}
	return nil
}

func (x *ConvolutionLayerParams) GetStride() []uint64 {
	if x != nil {
		return x.Stride
	}
	return nil
}

func (x *ConvolutionLayerParams) GetDilationFactor() []uint64 {
	if x != nil {
		return x.DilationFactor
	}
	return nil
}

func (x *ConvolutionLayerParams) GetConvolutionPaddingType() isConvolutionLayerParams_ConvolutionPaddingType {
	if x != nil {
		return x.ConvolutionPaddingType
	}
	return nil
}

func (x *ConvolutionLayerParams) GetValid() *ValidPadding {
	if x != nil {
		if x, ok := x.ConvolutionPaddingType.(*ConvolutionLayerParams_Valid); ok {
			return x.Valid
		}
	}
	return nil
}

func (x *ConvolutionLayerParams) GetSame() *SamePadding {
	if x != nil {
		if x, ok := x.ConvolutionPaddingType.(*ConvolutionLayerParams_Same); ok {
			return x.Same
		}
	}
	return nil
}

func (x *ConvolutionLayerParams) GetIsDeconvolution() bool {
	if x != nil {
		return x.IsDeconvolution
	}
	return false
}

func (x *ConvolutionLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *ConvolutionLayerParams) GetWeights() *WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *ConvolutionLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

func (x *ConvolutionLayerParams) GetOutputShape() []uint64 {
	if x != nil {
		return x.OutputShape
	}
	return nil
}

type isConvolutionLayerParams_ConvolutionPaddingType interface {
	isConvolutionLayerParams_ConvolutionPaddingType()
}

type ConvolutionLayerParams_Valid struct {
	Valid *ValidPadding `protobuf:"bytes,50,opt,name=valid,proto3,oneof"`
}

type ConvolutionLayerParams_Same struct {
	Same *SamePadding `protobuf:"bytes,51,opt,name=same,proto3,oneof"`
}

func (*ConvolutionLayerParams_Valid) isConvolutionLayerParams_ConvolutionPaddingType() {}

func (*ConvolutionLayerParams_Same) isConvolutionLayerParams_ConvolutionPaddingType() {}

// A layer that performs a 3-dimensional convolution.
//
// .. code::
//
//	y = Convolution3DLayer(x)
//
// Input
//
//	A blob of rank 5.
//	The input blob's shape should be ``[batch, channels, depth, height, width]``.
//
// Fields
//
//	The bias field, if set, should have shape of ``[channelsOut]``.
//
// Output
//
//	A blob of rank 5.
//	The output blob's shape is ``[batch, channelsOut, depthOut, heightOut, widthOut]``.
//
// Type of padding can be “custom“, “valid“, or “same“. Padded values are all zeros.
// Output spatial dimensions depend on the the type of padding. For details, refer to the
// descriptions of the “PaddingType“ field of this “Convolution3DLayerParams“ message.
//
// Example
//
//	For example, given an input of size ``[1, 3, 3, 8, 8]``, a stride of 2 in each dimension,
//	a kernel of 3 in each dimension, 2 output channels, and ``same`` padding, this layer will
//	compute the total padding applied in the depth, height, and width dimensions to be 2, 1, and 1,
//	respectively. The depth padding is even and will be applied equally to both sides of the depth
//	dimension. Since the height and width padding values are odd, they'll be applied to the
//	bottom/right of the height/width dimensions. Thus, the padding applied to the input will be
//	``[1, 1, 0, 1, 0, 1]`` (front, back, top, bottom, left, right). Finally, the output produced
//	will have size ``[1, 2, 2, 4, 4]``.
type Convolution3DLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of channels in the output (channelsOut). Must be a positive integer.
	OutputChannels int32 `protobuf:"varint,1,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"`
	// The number of channels in the input (channels). Must be a positive integer.
	InputChannels int32 `protobuf:"varint,2,opt,name=inputChannels,proto3" json:"inputChannels,omitempty"`
	// Group convolution, i.e., weight reuse along the channel axis.
	// It must evenly divide both the number of input and output channels and be at most the number
	// of input channels (a depthwise convolution).
	// Input and kernels are divided into g groups and convolution is applied within the groups
	// independently.
	NGroups int32 `protobuf:"varint,10,opt,name=nGroups,proto3" json:"nGroups,omitempty"`
	// Depth of the convolution kernel. Must be a positive integer.
	KernelDepth int32 `protobuf:"varint,20,opt,name=kernelDepth,proto3" json:"kernelDepth,omitempty"`
	// Height of the convolution kernel. Must be a positive integer.
	KernelHeight int32 `protobuf:"varint,21,opt,name=kernelHeight,proto3" json:"kernelHeight,omitempty"`
	// Width of the convolution kernel. Must be a positive integer.
	KernelWidth int32 `protobuf:"varint,22,opt,name=kernelWidth,proto3" json:"kernelWidth,omitempty"`
	// Stride along the depth direction. Must be a positive integer.
	StrideDepth int32 `protobuf:"varint,31,opt,name=strideDepth,proto3" json:"strideDepth,omitempty"`
	// Stride along the height direction. Must be a positive integer.
	StrideHeight int32 `protobuf:"varint,32,opt,name=strideHeight,proto3" json:"strideHeight,omitempty"`
	// Stride along the width direction. Must be a positive integer.
	StrideWidth int32 `protobuf:"varint,33,opt,name=strideWidth,proto3" json:"strideWidth,omitempty"`
	// Dilation along the depth direction. Must be a positive integer.
	DilationDepth int32 `protobuf:"varint,40,opt,name=dilationDepth,proto3" json:"dilationDepth,omitempty"`
	// Dilation along the height direction. Must be a positive integer.
	DilationHeight int32 `protobuf:"varint,41,opt,name=dilationHeight,proto3" json:"dilationHeight,omitempty"`
	// Dilation along the width direction. Must be a positive integer.
	DilationWidth int32 `protobuf:"varint,42,opt,name=dilationWidth,proto3" json:"dilationWidth,omitempty"`
	// Flag to specify whether a bias is to be added or not.
	// If false, then no bias is added.
	HasBias bool `protobuf:"varint,50,opt,name=hasBias,proto3" json:"hasBias,omitempty"`
	// Weights associated with this layer.
	// Weights have the shape
	// if deconvolution == False
	// “[outputChannels, kernelChannels, kernelDepth, kernelHeight, kernelWidth]“, where
	// kernelChannels == inputChannels / nGroups
	// else if deconvolution == True
	// “[outputChannels / nGroups, kernelChannels, kernelDepth, kernelHeight, kernelWidth]“, where
	Weights *WeightParams `protobuf:"bytes,60,opt,name=weights,proto3" json:"weights,omitempty"`
	// Must be of size “[outputChannels]“.
	Bias        *WeightParams                        `protobuf:"bytes,61,opt,name=bias,proto3" json:"bias,omitempty"`
	PaddingType Convolution3DLayerParams_PaddingType `protobuf:"varint,70,opt,name=paddingType,proto3,enum=CoreML.Specification.Convolution3DLayerParams_PaddingType" json:"paddingType,omitempty"`
	// Padding before the input in the depth direction. Must be zero or a positive integer.
	// Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
	CustomPaddingFront int32 `protobuf:"varint,80,opt,name=customPaddingFront,proto3" json:"customPaddingFront,omitempty"`
	// Padding after the input in the depth direction. Must be zero or a positive integer.
	// Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
	CustomPaddingBack int32 `protobuf:"varint,81,opt,name=customPaddingBack,proto3" json:"customPaddingBack,omitempty"`
	// Padding before the input in the height direction. Must be zero or a positive integer.
	// Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
	CustomPaddingTop int32 `protobuf:"varint,82,opt,name=customPaddingTop,proto3" json:"customPaddingTop,omitempty"`
	// Padding after the input in the height direction. Must be zero or a positive integer.
	// Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
	CustomPaddingBottom int32 `protobuf:"varint,83,opt,name=customPaddingBottom,proto3" json:"customPaddingBottom,omitempty"`
	// Padding before the input in the width direction. Must be zero or a positive integer.
	// Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
	CustomPaddingLeft int32 `protobuf:"varint,84,opt,name=customPaddingLeft,proto3" json:"customPaddingLeft,omitempty"`
	// Padding after the input in the width direction. Must be zero or a positive integer.
	// Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
	CustomPaddingRight int32 `protobuf:"varint,85,opt,name=customPaddingRight,proto3" json:"customPaddingRight,omitempty"`
	// Flag to specify if this is Convolution Transpose or not.
	IsDeconvolution bool `protobuf:"varint,86,opt,name=isDeconvolution,proto3" json:"isDeconvolution,omitempty"`
	// The output shape, which has length 3 “[D_out, H_out, W_out]“.
	// This is used only for deconvolution (“isDeconvolution == true“).
	// If not set, the deconvolution output shape is calculated
	// based on “PaddingType“.
	OutputShape   []uint64 `protobuf:"varint,87,rep,packed,name=outputShape,proto3" json:"outputShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Convolution3DLayerParams) Reset() {
	*x = Convolution3DLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[45]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Convolution3DLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Convolution3DLayerParams) ProtoMessage() {}

func (x *Convolution3DLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[45]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Convolution3DLayerParams.ProtoReflect.Descriptor instead.
func (*Convolution3DLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{45}
}

func (x *Convolution3DLayerParams) GetOutputChannels() int32 {
	if x != nil {
		return x.OutputChannels
	}
	return 0
}

func (x *Convolution3DLayerParams) GetInputChannels() int32 {
	if x != nil {
		return x.InputChannels
	}
	return 0
}

func (x *Convolution3DLayerParams) GetNGroups() int32 {
	if x != nil {
		return x.NGroups
	}
	return 0
}

func (x *Convolution3DLayerParams) GetKernelDepth() int32 {
	if x != nil {
		return x.KernelDepth
	}
	return 0
}

func (x *Convolution3DLayerParams) GetKernelHeight() int32 {
	if x != nil {
		return x.KernelHeight
	}
	return 0
}

func (x *Convolution3DLayerParams) GetKernelWidth() int32 {
	if x != nil {
		return x.KernelWidth
	}
	return 0
}

func (x *Convolution3DLayerParams) GetStrideDepth() int32 {
	if x != nil {
		return x.StrideDepth
	}
	return 0
}

func (x *Convolution3DLayerParams) GetStrideHeight() int32 {
	if x != nil {
		return x.StrideHeight
	}
	return 0
}

func (x *Convolution3DLayerParams) GetStrideWidth() int32 {
	if x != nil {
		return x.StrideWidth
	}
	return 0
}

func (x *Convolution3DLayerParams) GetDilationDepth() int32 {
	if x != nil {
		return x.DilationDepth
	}
	return 0
}

func (x *Convolution3DLayerParams) GetDilationHeight() int32 {
	if x != nil {
		return x.DilationHeight
	}
	return 0
}

func (x *Convolution3DLayerParams) GetDilationWidth() int32 {
	if x != nil {
		return x.DilationWidth
	}
	return 0
}

func (x *Convolution3DLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *Convolution3DLayerParams) GetWeights() *WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *Convolution3DLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

func (x *Convolution3DLayerParams) GetPaddingType() Convolution3DLayerParams_PaddingType {
	if x != nil {
		return x.PaddingType
	}
	return Convolution3DLayerParams_CUSTOM
}

func (x *Convolution3DLayerParams) GetCustomPaddingFront() int32 {
	if x != nil {
		return x.CustomPaddingFront
	}
	return 0
}

func (x *Convolution3DLayerParams) GetCustomPaddingBack() int32 {
	if x != nil {
		return x.CustomPaddingBack
	}
	return 0
}

func (x *Convolution3DLayerParams) GetCustomPaddingTop() int32 {
	if x != nil {
		return x.CustomPaddingTop
	}
	return 0
}

func (x *Convolution3DLayerParams) GetCustomPaddingBottom() int32 {
	if x != nil {
		return x.CustomPaddingBottom
	}
	return 0
}

func (x *Convolution3DLayerParams) GetCustomPaddingLeft() int32 {
	if x != nil {
		return x.CustomPaddingLeft
	}
	return 0
}

func (x *Convolution3DLayerParams) GetCustomPaddingRight() int32 {
	if x != nil {
		return x.CustomPaddingRight
	}
	return 0
}

func (x *Convolution3DLayerParams) GetIsDeconvolution() bool {
	if x != nil {
		return x.IsDeconvolution
	}
	return false
}

func (x *Convolution3DLayerParams) GetOutputShape() []uint64 {
	if x != nil {
		return x.OutputShape
	}
	return nil
}

// A layer that performs a matrix-vector or matrix-matrix product.
// This is equivalent to a fully-connected, or dense layer.
// The weight parameters correspond to a matrix of dimensions (inputChannels, outputChannels) i.e. (C_in, C_out)
//
// .. code::
//
//	y = InnerProductLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	Input can have rank 1 to rank 5. This is how it is reshaped in to the matrix (for rank > 1):
//	rank 1 (x1) : in this case, the layer corresponds to a matrix-vector product. x1 must be equal to C_in
//	rank 2 (x1, x2): x2 must be equal to C_in
//	rank 3 (x1, x2, x3) --> (x1 * x2, x3). x3 must be equal to C_in
//	rank 4 (x1, x2, x3, x4) ---> (x1, x2 * x3 * x4). x2 * x3 * x4 must be equal to C_in
//	rank 5 (x1, x2, x3, x4, x5) ---> (x1 * x2, x3 * x4 * x5). x3 * x4 * x5 must be equal to C_in
//
// Output
//
//	Output rank is same as the input rank
//	rank 1: (C_out)
//	rank 2: (x1, C_out)
//	rank 3: (x1, x2, C_out)
//	rank 4: (x1, C_out, 1, 1)
//	rank 5: (x1, x2, C_out, 1, 1)
type InnerProductLayerParams struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	InputChannels  uint64                 `protobuf:"varint,1,opt,name=inputChannels,proto3" json:"inputChannels,omitempty"`   // Input size: C_in.
	OutputChannels uint64                 `protobuf:"varint,2,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"` // Output size: C_out.
	HasBias        bool                   `protobuf:"varint,10,opt,name=hasBias,proto3" json:"hasBias,omitempty"`              // Whether a bias is added or not.
	Weights        *WeightParams          `protobuf:"bytes,20,opt,name=weights,proto3" json:"weights,omitempty"`               // Weight matrix [C_out, C_in].
	Bias           *WeightParams          `protobuf:"bytes,21,opt,name=bias,proto3" json:"bias,omitempty"`                     // Bias vector [C_out].
	// If set, this layer, at runtime, quantizes the floating point input blob to int8 before applying an
	// inner product using INT8 weight matrix parameters, as provided in weights->int8RawValue. The
	// result is then dequantized.
	// Requires:
	// * hasBias == false
	// * QuantizationType == LinearQuantizationParams, such that
	//   - size of the "scale" field is 1 and "bias" field is empty in "LinearQuantizationParams"
	//
	// * numberOfBits == 8
	// * weights->rawValue_size to be empty
	Int8DynamicQuantize bool `protobuf:"varint,22,opt,name=int8DynamicQuantize,proto3" json:"int8DynamicQuantize,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *InnerProductLayerParams) Reset() {
	*x = InnerProductLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[46]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InnerProductLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InnerProductLayerParams) ProtoMessage() {}

func (x *InnerProductLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[46]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InnerProductLayerParams.ProtoReflect.Descriptor instead.
func (*InnerProductLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{46}
}

func (x *InnerProductLayerParams) GetInputChannels() uint64 {
	if x != nil {
		return x.InputChannels
	}
	return 0
}

func (x *InnerProductLayerParams) GetOutputChannels() uint64 {
	if x != nil {
		return x.OutputChannels
	}
	return 0
}

func (x *InnerProductLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *InnerProductLayerParams) GetWeights() *WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *InnerProductLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

func (x *InnerProductLayerParams) GetInt8DynamicQuantize() bool {
	if x != nil {
		return x.Int8DynamicQuantize
	}
	return false
}

// A layer that performs a matrix lookup and optionally adds a bias.
// The weights matrix is stored with dimensions [outputChannels, inputDim].
//
// .. code::
//
//	y = EmbeddingLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	Input values must be in the range ``[0, inputDim - 1]``.
//
//	Input must have rank equal to 4 or 5, such that the last 3 dimensions are all 1.
//	rank 4: shape (x1, 1, 1, 1). x1 is effectively the batch/sequence length.
//	rank 5: shape (x1, x2 , 1, 1, 1). x1 * x2 is effectively the combined batch/sequence length.
//
// Output
//
//	Output rank is same as the input rank. Please see input description above.
//	rank 4: shape (x1, outputChannels, 1, 1)
//	rank 5: shape (x1, x2, outputChannels, 1, 1)
type EmbeddingLayerParams struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	InputDim       uint64                 `protobuf:"varint,1,opt,name=inputDim,proto3" json:"inputDim,omitempty"`             // Size of the input dictionary.
	OutputChannels uint64                 `protobuf:"varint,2,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"` // Size of the output vectors.
	HasBias        bool                   `protobuf:"varint,10,opt,name=hasBias,proto3" json:"hasBias,omitempty"`              // Whether a bias is added or not.
	Weights        *WeightParams          `protobuf:"bytes,20,opt,name=weights,proto3" json:"weights,omitempty"`               // 2-D weights of dimensions [outputChannels, inputDim].
	Bias           *WeightParams          `protobuf:"bytes,21,opt,name=bias,proto3" json:"bias,omitempty"`                     // Bias of size [outputChannels].
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *EmbeddingLayerParams) Reset() {
	*x = EmbeddingLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[47]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EmbeddingLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EmbeddingLayerParams) ProtoMessage() {}

func (x *EmbeddingLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[47]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EmbeddingLayerParams.ProtoReflect.Descriptor instead.
func (*EmbeddingLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{47}
}

func (x *EmbeddingLayerParams) GetInputDim() uint64 {
	if x != nil {
		return x.InputDim
	}
	return 0
}

func (x *EmbeddingLayerParams) GetOutputChannels() uint64 {
	if x != nil {
		return x.OutputChannels
	}
	return 0
}

func (x *EmbeddingLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *EmbeddingLayerParams) GetWeights() *WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *EmbeddingLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

// A layer that performs a matrix lookup and optionally adds a bias.
// The weights matrix is stored with dimensions [embeddingSize, vocabSize].
//
// .. code::
//
//	y = EmbeddingNDLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	Input values must be in the range ``[0, vocabSize - 1]``.
//	Input must have rank at least 2. The last dimension must always be 1.
//	rank 2: shape (x1, 1). x1 is the batch/sequence length.
//	rank 3: shape (x1, x2, 1). x1 * x2 is effectively the combined batch/sequence length.
//	rank 4: shape (x1, x2, x3, 1). x1 * x2 * x2 is effectively the combined batch/sequence length.
//	rank 5: shape (x1, x2 , x3, x4, 1). x1 * x2 * x3 * x4 is effectively the combined batch/sequence length.
//
// Output
//
//	Output rank is same as the input rank. Please see input description above.
//	rank 2: shape (x1, embeddingSize)
//	rank 3: shape (x1, x2, embeddingSize)
//	rank 4: shape (x1, x2, x3, embeddingSize)
//	rank 5: shape (x1, x2, x3, x4, embeddingSize)
type EmbeddingNDLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	VocabSize     uint64                 `protobuf:"varint,1,opt,name=vocabSize,proto3" json:"vocabSize,omitempty"`         // Size of the input dictionary.
	EmbeddingSize uint64                 `protobuf:"varint,2,opt,name=embeddingSize,proto3" json:"embeddingSize,omitempty"` // Size of the output vectors.
	HasBias       bool                   `protobuf:"varint,3,opt,name=hasBias,proto3" json:"hasBias,omitempty"`             // Whether a bias is added or not.
	Weights       *WeightParams          `protobuf:"bytes,20,opt,name=weights,proto3" json:"weights,omitempty"`             // 2-D weights of dimensions [embeddingSize, vocabSize].
	Bias          *WeightParams          `protobuf:"bytes,21,opt,name=bias,proto3" json:"bias,omitempty"`                   // Bias of size [embeddingSize].
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EmbeddingNDLayerParams) Reset() {
	*x = EmbeddingNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[48]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EmbeddingNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EmbeddingNDLayerParams) ProtoMessage() {}

func (x *EmbeddingNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[48]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EmbeddingNDLayerParams.ProtoReflect.Descriptor instead.
func (*EmbeddingNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{48}
}

func (x *EmbeddingNDLayerParams) GetVocabSize() uint64 {
	if x != nil {
		return x.VocabSize
	}
	return 0
}

func (x *EmbeddingNDLayerParams) GetEmbeddingSize() uint64 {
	if x != nil {
		return x.EmbeddingSize
	}
	return 0
}

func (x *EmbeddingNDLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *EmbeddingNDLayerParams) GetWeights() *WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *EmbeddingNDLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

// A layer that performs batch normalization,
// which is performed along axis = -3,
// and repeated along the other axes, if present.
//
// .. code::
//
//	y = BatchnormLayer(x)
//
// Requires 1 input and produces 1 output.
//
// This operation is described by the following formula:
//
// .. math::
//
//	y_i = \gamma_i \dfrac{ (x_i - \mu_i)}{\sqrt{\sigma_i^2 + \epsilon}} + \beta_i \;,\;i=1,....,C
//
// Input
//
//	A blob with rank greater than equal to 3.
//	Example: Rank 4 blob represents [Batch, channels, height, width]
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	A blob with the same shape as the input.
type BatchnormLayerParams struct {
	state    protoimpl.MessageState `protogen:"open.v1"`
	Channels uint64                 `protobuf:"varint,1,opt,name=channels,proto3" json:"channels,omitempty"` // Size of the channel dimension in the input.
	// If “computeMeanVar == true“,
	// the mean and variance are calculated from either
	// the single input instance, if “instanceNormalization == true“,
	// or the whole batch, if “instanceNormalization = false“.
	// and the values provided in parameters "mean" and "variance" are ignored.
	ComputeMeanVar        bool `protobuf:"varint,5,opt,name=computeMeanVar,proto3" json:"computeMeanVar,omitempty"`
	InstanceNormalization bool `protobuf:"varint,6,opt,name=instanceNormalization,proto3" json:"instanceNormalization,omitempty"`
	// A small constant to avoid division by 0 while normalizing by variance.
	// Defaults to “1e-5“ if not set or set to “0“.
	Epsilon       float32       `protobuf:"fixed32,10,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	Gamma         *WeightParams `protobuf:"bytes,15,opt,name=gamma,proto3" json:"gamma,omitempty"`       // Parameter of length [channels]
	Beta          *WeightParams `protobuf:"bytes,16,opt,name=beta,proto3" json:"beta,omitempty"`         // Parameter of length [channels]
	Mean          *WeightParams `protobuf:"bytes,17,opt,name=mean,proto3" json:"mean,omitempty"`         // Parameter of length [channels]
	Variance      *WeightParams `protobuf:"bytes,18,opt,name=variance,proto3" json:"variance,omitempty"` // Parameter of length [channels]
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BatchnormLayerParams) Reset() {
	*x = BatchnormLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[49]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchnormLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchnormLayerParams) ProtoMessage() {}

func (x *BatchnormLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[49]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchnormLayerParams.ProtoReflect.Descriptor instead.
func (*BatchnormLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{49}
}

func (x *BatchnormLayerParams) GetChannels() uint64 {
	if x != nil {
		return x.Channels
	}
	return 0
}

func (x *BatchnormLayerParams) GetComputeMeanVar() bool {
	if x != nil {
		return x.ComputeMeanVar
	}
	return false
}

func (x *BatchnormLayerParams) GetInstanceNormalization() bool {
	if x != nil {
		return x.InstanceNormalization
	}
	return false
}

func (x *BatchnormLayerParams) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

func (x *BatchnormLayerParams) GetGamma() *WeightParams {
	if x != nil {
		return x.Gamma
	}
	return nil
}

func (x *BatchnormLayerParams) GetBeta() *WeightParams {
	if x != nil {
		return x.Beta
	}
	return nil
}

func (x *BatchnormLayerParams) GetMean() *WeightParams {
	if x != nil {
		return x.Mean
	}
	return nil
}

func (x *BatchnormLayerParams) GetVariance() *WeightParams {
	if x != nil {
		return x.Variance
	}
	return nil
}

// A spatial pooling layer.
//
// .. code::
//
//	y = PoolingLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank greater than equal to 4.
//	Rank 4 blob represents [Batch, channels, height, width]
//	For ranks greater than 4, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Rank is same as the input. e.g.: for rank 4 input, output shape is [B, C, H_out, W_out]
//
// Padding options are similar to “ConvolutionLayerParams“
// with the additional option of “ValidCompletePadding“ (“includeLastPixel“),
// which ensures that the last application of the kernel
// always includes the last pixel of the input image, if there is padding.
//
// .. code::
//
//	H_out = ceil(float(H_in + 2 * paddingAmounts[0] - kernelSize[0])/float(Stride[0])) + 1
//	if (paddingAmounts[0] > 0 or paddingAmounts[1] > 0)
//	     if ((H_out - 1) * Stride >= H_in + paddingAmounts[0]) {
//	         H_out = H_out - 1
//	     }
//	}
//
// The equivalent expressions hold true for “W_out“ as well.
// Only symmetric padding is supported with this option.
type PoolingLayerParams struct {
	state protoimpl.MessageState         `protogen:"open.v1"`
	Type  PoolingLayerParams_PoolingType `protobuf:"varint,1,opt,name=type,proto3,enum=CoreML.Specification.PoolingLayerParams_PoolingType" json:"type,omitempty"` // Type of pooling operation.
	// Must be length 2 in the order “[H, W]“.
	// If not set, default value “[3, 3]“ is used.
	KernelSize []uint64 `protobuf:"varint,10,rep,packed,name=kernelSize,proto3" json:"kernelSize,omitempty"`
	// Must be length 2 in the order “[H, W]“.
	// If not set, default value “[1, 1]“ is used.
	Stride []uint64 `protobuf:"varint,20,rep,packed,name=stride,proto3" json:"stride,omitempty"`
	// Types that are valid to be assigned to PoolingPaddingType:
	//
	//	*PoolingLayerParams_Valid
	//	*PoolingLayerParams_Same
	//	*PoolingLayerParams_IncludeLastPixel
	PoolingPaddingType isPoolingLayerParams_PoolingPaddingType `protobuf_oneof:"PoolingPaddingType"`
	// If true, padded values are excluded from the count (denominator)
	// when computing average pooling.
	AvgPoolExcludePadding bool `protobuf:"varint,50,opt,name=avgPoolExcludePadding,proto3" json:"avgPoolExcludePadding,omitempty"`
	// If true, global pooling is performed.
	// Kernel size is inferred from the input data spatial dimensions.
	GlobalPooling bool `protobuf:"varint,60,opt,name=globalPooling,proto3" json:"globalPooling,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PoolingLayerParams) Reset() {
	*x = PoolingLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[50]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PoolingLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PoolingLayerParams) ProtoMessage() {}

func (x *PoolingLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[50]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PoolingLayerParams.ProtoReflect.Descriptor instead.
func (*PoolingLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{50}
}

func (x *PoolingLayerParams) GetType() PoolingLayerParams_PoolingType {
	if x != nil {
		return x.Type
	}
	return PoolingLayerParams_MAX
}

func (x *PoolingLayerParams) GetKernelSize() []uint64 {
	if x != nil {
		return x.KernelSize
	}
	return nil
}

func (x *PoolingLayerParams) GetStride() []uint64 {
	if x != nil {
		return x.Stride
	}
	return nil
}

func (x *PoolingLayerParams) GetPoolingPaddingType() isPoolingLayerParams_PoolingPaddingType {
	if x != nil {
		return x.PoolingPaddingType
	}
	return nil
}

func (x *PoolingLayerParams) GetValid() *ValidPadding {
	if x != nil {
		if x, ok := x.PoolingPaddingType.(*PoolingLayerParams_Valid); ok {
			return x.Valid
		}
	}
	return nil
}

func (x *PoolingLayerParams) GetSame() *SamePadding {
	if x != nil {
		if x, ok := x.PoolingPaddingType.(*PoolingLayerParams_Same); ok {
			return x.Same
		}
	}
	return nil
}

func (x *PoolingLayerParams) GetIncludeLastPixel() *PoolingLayerParams_ValidCompletePadding {
	if x != nil {
		if x, ok := x.PoolingPaddingType.(*PoolingLayerParams_IncludeLastPixel); ok {
			return x.IncludeLastPixel
		}
	}
	return nil
}

func (x *PoolingLayerParams) GetAvgPoolExcludePadding() bool {
	if x != nil {
		return x.AvgPoolExcludePadding
	}
	return false
}

func (x *PoolingLayerParams) GetGlobalPooling() bool {
	if x != nil {
		return x.GlobalPooling
	}
	return false
}

type isPoolingLayerParams_PoolingPaddingType interface {
	isPoolingLayerParams_PoolingPaddingType()
}

type PoolingLayerParams_Valid struct {
	Valid *ValidPadding `protobuf:"bytes,30,opt,name=valid,proto3,oneof"`
}

type PoolingLayerParams_Same struct {
	Same *SamePadding `protobuf:"bytes,31,opt,name=same,proto3,oneof"`
}

type PoolingLayerParams_IncludeLastPixel struct {
	IncludeLastPixel *PoolingLayerParams_ValidCompletePadding `protobuf:"bytes,32,opt,name=includeLastPixel,proto3,oneof"`
}

func (*PoolingLayerParams_Valid) isPoolingLayerParams_PoolingPaddingType() {}

func (*PoolingLayerParams_Same) isPoolingLayerParams_PoolingPaddingType() {}

func (*PoolingLayerParams_IncludeLastPixel) isPoolingLayerParams_PoolingPaddingType() {}

// A layer to pool three spatial dimensions
//
// Input
//
//	A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
//
// Output
//
//	Rank is same as the input: A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
//
// Requires 1 input and produces 1 output.
//
// For example, given an input of shape (1,1,2,3,3):
//
//	      +----+----+----+
//	    / | 10 | 11 | 12 |
//	   /  +----+----+----+
//	  /   | 13 | 14 | 15 |
//	 /    +----+----+----+
//	/     | 16 | 17 | 18 |
//
// /      +----+----+----+
// +----+----+----+      /
// |  1 |  2 |  3 |     /
// +----+----+----+    /
// |  4 |  5 |  6 |   /
// +----+----+----+  /
// |  7 |  8 |  9 | /
// +----+----+----+
//
// And applying MAX pooling using:
//
//	Kernel: 2x2x2
//	Stride: 1x1x1
//	Valid Padding
//
// We expect to get an output with shape: (1,1,1,2,2) and value:
// +----+----+
// | 14 | 15 |
// +----+----+
// | 17 | 18 |
// +----+----+
type Pooling3DLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Whether to use Max or Average
	Type Pooling3DLayerParams_PoolingType3D `protobuf:"varint,1,opt,name=type,proto3,enum=CoreML.Specification.Pooling3DLayerParams_PoolingType3D" json:"type,omitempty"`
	// Depth of the pooling region.
	KernelDepth int32 `protobuf:"varint,2,opt,name=kernelDepth,proto3" json:"kernelDepth,omitempty"`
	// Height of the pooling region.
	KernelHeight int32 `protobuf:"varint,3,opt,name=kernelHeight,proto3" json:"kernelHeight,omitempty"`
	// Width of the pooling region.
	KernelWidth int32 `protobuf:"varint,4,opt,name=kernelWidth,proto3" json:"kernelWidth,omitempty"`
	// Stride along the depth direction
	StrideDepth int32 `protobuf:"varint,5,opt,name=strideDepth,proto3" json:"strideDepth,omitempty"`
	// Stride along the height direction
	StrideHeight int32 `protobuf:"varint,6,opt,name=strideHeight,proto3" json:"strideHeight,omitempty"`
	// Stride along the width direction
	StrideWidth int32                                     `protobuf:"varint,7,opt,name=strideWidth,proto3" json:"strideWidth,omitempty"`
	PaddingType Pooling3DLayerParams_Pooling3DPaddingType `protobuf:"varint,15,opt,name=paddingType,proto3,enum=CoreML.Specification.Pooling3DLayerParams_Pooling3DPaddingType" json:"paddingType,omitempty"`
	// Padding before the input in the depth direction.
	CustomPaddingFront int32 `protobuf:"varint,8,opt,name=customPaddingFront,proto3" json:"customPaddingFront,omitempty"`
	// Padding after the input in the depth direction.
	CustomPaddingBack int32 `protobuf:"varint,9,opt,name=customPaddingBack,proto3" json:"customPaddingBack,omitempty"`
	// Padding before the input in the height direction.
	CustomPaddingTop int32 `protobuf:"varint,10,opt,name=customPaddingTop,proto3" json:"customPaddingTop,omitempty"`
	// Padding after the input in the height direction.
	CustomPaddingBottom int32 `protobuf:"varint,11,opt,name=customPaddingBottom,proto3" json:"customPaddingBottom,omitempty"`
	// Padding before the input in the width direction.
	CustomPaddingLeft int32 `protobuf:"varint,12,opt,name=customPaddingLeft,proto3" json:"customPaddingLeft,omitempty"`
	// Padding after the input in the width direction.
	CustomPaddingRight int32 `protobuf:"varint,13,opt,name=customPaddingRight,proto3" json:"customPaddingRight,omitempty"`
	// If true, exclude zeros from padding in Average pooling.  Meaningless in Max Pooling.
	CountExcludePadding bool `protobuf:"varint,14,opt,name=countExcludePadding,proto3" json:"countExcludePadding,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *Pooling3DLayerParams) Reset() {
	*x = Pooling3DLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[51]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Pooling3DLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Pooling3DLayerParams) ProtoMessage() {}

func (x *Pooling3DLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[51]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Pooling3DLayerParams.ProtoReflect.Descriptor instead.
func (*Pooling3DLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{51}
}

func (x *Pooling3DLayerParams) GetType() Pooling3DLayerParams_PoolingType3D {
	if x != nil {
		return x.Type
	}
	return Pooling3DLayerParams_MAX
}

func (x *Pooling3DLayerParams) GetKernelDepth() int32 {
	if x != nil {
		return x.KernelDepth
	}
	return 0
}

func (x *Pooling3DLayerParams) GetKernelHeight() int32 {
	if x != nil {
		return x.KernelHeight
	}
	return 0
}

func (x *Pooling3DLayerParams) GetKernelWidth() int32 {
	if x != nil {
		return x.KernelWidth
	}
	return 0
}

func (x *Pooling3DLayerParams) GetStrideDepth() int32 {
	if x != nil {
		return x.StrideDepth
	}
	return 0
}

func (x *Pooling3DLayerParams) GetStrideHeight() int32 {
	if x != nil {
		return x.StrideHeight
	}
	return 0
}

func (x *Pooling3DLayerParams) GetStrideWidth() int32 {
	if x != nil {
		return x.StrideWidth
	}
	return 0
}

func (x *Pooling3DLayerParams) GetPaddingType() Pooling3DLayerParams_Pooling3DPaddingType {
	if x != nil {
		return x.PaddingType
	}
	return Pooling3DLayerParams_CUSTOM
}

func (x *Pooling3DLayerParams) GetCustomPaddingFront() int32 {
	if x != nil {
		return x.CustomPaddingFront
	}
	return 0
}

func (x *Pooling3DLayerParams) GetCustomPaddingBack() int32 {
	if x != nil {
		return x.CustomPaddingBack
	}
	return 0
}

func (x *Pooling3DLayerParams) GetCustomPaddingTop() int32 {
	if x != nil {
		return x.CustomPaddingTop
	}
	return 0
}

func (x *Pooling3DLayerParams) GetCustomPaddingBottom() int32 {
	if x != nil {
		return x.CustomPaddingBottom
	}
	return 0
}

func (x *Pooling3DLayerParams) GetCustomPaddingLeft() int32 {
	if x != nil {
		return x.CustomPaddingLeft
	}
	return 0
}

func (x *Pooling3DLayerParams) GetCustomPaddingRight() int32 {
	if x != nil {
		return x.CustomPaddingRight
	}
	return 0
}

func (x *Pooling3DLayerParams) GetCountExcludePadding() bool {
	if x != nil {
		return x.CountExcludePadding
	}
	return false
}

// A layer to pool three spatial dimensions down to one value.
// This behaves like a special case of Pooling3DLayerParams in which
// the Kernel is the size of the input and there is no padding.
//
// Input
//
//	A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
//
// Output
//
//	Rank is same as the input: A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
//	Depth, height, and width of the output will always be 1.
//
// Requires 1 input and produces 1 output.
//
// For example, given an input of shape (1,1,2,3,3):
//
//	      +----+----+----+
//	    / | 10 | 11 | 12 |
//	   /  +----+----+----+
//	  /   | 13 | 14 | 15 |
//	 /    +----+----+----+
//	/     | 16 | 17 | 18 |
//
// /      +----+----+----+
// +----+----+----+      /
// |  1 |  2 |  3 |     /
// +----+----+----+    /
// |  4 |  5 |  6 |   /
// +----+----+----+  /
// |  7 |  8 |  9 | /
// +----+----+----+
//
// And applying MAX global 3d pooling, we expect to get an output with shape: (1,1,1,1,1) and value:
// +----+
// | 18 |
// +----+
type GlobalPooling3DLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Whether to use Max or Average
	Type          GlobalPooling3DLayerParams_GlobalPoolingType3D `protobuf:"varint,1,opt,name=type,proto3,enum=CoreML.Specification.GlobalPooling3DLayerParams_GlobalPoolingType3D" json:"type,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GlobalPooling3DLayerParams) Reset() {
	*x = GlobalPooling3DLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[52]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GlobalPooling3DLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GlobalPooling3DLayerParams) ProtoMessage() {}

func (x *GlobalPooling3DLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[52]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GlobalPooling3DLayerParams.ProtoReflect.Descriptor instead.
func (*GlobalPooling3DLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{52}
}

func (x *GlobalPooling3DLayerParams) GetType() GlobalPooling3DLayerParams_GlobalPoolingType3D {
	if x != nil {
		return x.Type
	}
	return GlobalPooling3DLayerParams_MAX
}

// A layer that performs padding along spatial dimensions.
//
// .. code::
//
//	y = PaddingLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 2.
//	e.g.: blob with shape ``[H_in, W_in]``.
//	For ranks greater than 2, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch
//	i.e. Padding is applied on last two dimensions.
//
// Output
//
//	Same rank as the input.
//	e.g.: blob with shape ``[H_out, W_out]``.
//
// Output dimensions are calculated as follows:
//
// .. code::
//
//	H_out = H_in + topPaddingAmount + bottomPaddingAmount
//	W_out = W_in + leftPaddingAmount + rightPaddingAmount
//
//	topPaddingAmount == Height startEdgeSize == borderAmounts[0].startEdgeSize
//	bottomPaddingAmount == Height endEdgeSize == borderAmounts[0].endEdgeSize
//	leftPaddingAmount == Width startEdgeSize == borderAmounts[1].startEdgeSize
//	rightPaddingAmount == Width endEdgeSize == borderAmounts[1].endEdgeSize
//
// There are three types of padding:
//
// - “PaddingConstant“, which fills a constant value at the border.
// - “PaddingReflection“, which reflects the values at the border.
// - “PaddingReplication“, which replicates the values at the border.
//
// Given the following input:
//
// .. code::
//
//	[1, 3, 4]  :  1   2   3   4
//	              5   6   7   8
//	              9   10  11  12
//
// Here is the output of applying the padding
// “(top=2, left=2, bottom=0, right=0)“
// with each of the supported types:
//
//   - “PaddingConstant“ (“value = 0“):
//     .. code::
//
//     [1, 5, 6]  :  0   0   0  0   0   0
//     0   0   0  0   0   0
//     0   0   1  2   3   4
//     0   0   5  6   7   8
//     0   0   9  10  11  12
//
//   - “PaddingReflection“:
//     .. code::
//
//     [1, 5, 6]  :  11  10  9  10  11  12
//     7   6   5  6   7   8
//     3   2   1  2   3   4
//     7   6   5  6   7   8
//     11  10  9  10  11  12
//
//   - “PaddingReplication“:
//     .. code::
//
//     [1, 5, 6]  :  1   1   1  2   3   4
//     1   1   1  2   3   4
//     1   1   1  2   3   4
//     5   5   5  6   7   8
//     9   9   9  10  11  12
type PaddingLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to PaddingType:
	//
	//	*PaddingLayerParams_Constant
	//	*PaddingLayerParams_Reflection
	//	*PaddingLayerParams_Replication
	PaddingType    isPaddingLayerParams_PaddingType `protobuf_oneof:"PaddingType"`
	PaddingAmounts *BorderAmounts                   `protobuf:"bytes,10,opt,name=paddingAmounts,proto3" json:"paddingAmounts,omitempty"` // Amounts to be padded to the input.
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *PaddingLayerParams) Reset() {
	*x = PaddingLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[53]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PaddingLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PaddingLayerParams) ProtoMessage() {}

func (x *PaddingLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[53]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PaddingLayerParams.ProtoReflect.Descriptor instead.
func (*PaddingLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{53}
}

func (x *PaddingLayerParams) GetPaddingType() isPaddingLayerParams_PaddingType {
	if x != nil {
		return x.PaddingType
	}
	return nil
}

func (x *PaddingLayerParams) GetConstant() *PaddingLayerParams_PaddingConstant {
	if x != nil {
		if x, ok := x.PaddingType.(*PaddingLayerParams_Constant); ok {
			return x.Constant
		}
	}
	return nil
}

func (x *PaddingLayerParams) GetReflection() *PaddingLayerParams_PaddingReflection {
	if x != nil {
		if x, ok := x.PaddingType.(*PaddingLayerParams_Reflection); ok {
			return x.Reflection
		}
	}
	return nil
}

func (x *PaddingLayerParams) GetReplication() *PaddingLayerParams_PaddingReplication {
	if x != nil {
		if x, ok := x.PaddingType.(*PaddingLayerParams_Replication); ok {
			return x.Replication
		}
	}
	return nil
}

func (x *PaddingLayerParams) GetPaddingAmounts() *BorderAmounts {
	if x != nil {
		return x.PaddingAmounts
	}
	return nil
}

type isPaddingLayerParams_PaddingType interface {
	isPaddingLayerParams_PaddingType()
}

type PaddingLayerParams_Constant struct {
	Constant *PaddingLayerParams_PaddingConstant `protobuf:"bytes,1,opt,name=constant,proto3,oneof"`
}

type PaddingLayerParams_Reflection struct {
	Reflection *PaddingLayerParams_PaddingReflection `protobuf:"bytes,2,opt,name=reflection,proto3,oneof"`
}

type PaddingLayerParams_Replication struct {
	Replication *PaddingLayerParams_PaddingReplication `protobuf:"bytes,3,opt,name=replication,proto3,oneof"`
}

func (*PaddingLayerParams_Constant) isPaddingLayerParams_PaddingType() {}

func (*PaddingLayerParams_Reflection) isPaddingLayerParams_PaddingType() {}

func (*PaddingLayerParams_Replication) isPaddingLayerParams_PaddingType() {}

// A layer that concatenates along the axis = -3 or -5.
// For general concatenation along any axis, see ConcatNDLayer.
//
// .. code::
//
//	y = ConcatLayer(x1,x2,....)
//
// Requires more than 1 input and produces 1 output.
//
// Input
//
//	All input blobs must have same rank.
//	If "sequenceConcat" = False, rank must be greater than equal to 3. In this case concatenation is along axis = -3
//	If "sequenceConcat" = True, rank must be greater than equal to 5. In this case concatenation is along axis = -5
//
// Output
//
//	Same rank as the input.
type ConcatLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If true, concatenate along the axis = -5 instead of axis = -3.
	SequenceConcat bool `protobuf:"varint,100,opt,name=sequenceConcat,proto3" json:"sequenceConcat,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ConcatLayerParams) Reset() {
	*x = ConcatLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[54]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConcatLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConcatLayerParams) ProtoMessage() {}

func (x *ConcatLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[54]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConcatLayerParams.ProtoReflect.Descriptor instead.
func (*ConcatLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{54}
}

func (x *ConcatLayerParams) GetSequenceConcat() bool {
	if x != nil {
		return x.SequenceConcat
	}
	return false
}

// A layer that performs local response normalization (LRN).
//
// .. code::
//
//	y = LRNLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank greater than equal to 3.
//	Example: Rank 4 blob represents [Batch, channels, height, width]
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	A blob with the same shape as the input.
//
// This layer is described by the following formula:
//
// .. math::
//
//	x_i \leftarrow  \dfrac{x_i}{\left ( k + \dfrac{\alpha}{\text{localSize}} \sum_j x_j^2 \right )^\beta}
//
// where the summation is done over a “(localSize, 1, 1)“ neighborhood ---
// that is, over a window "across" channels in 1x1 spatial neighborhoods.
type LRNLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta          float32                `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
	LocalSize     uint64                 `protobuf:"varint,3,opt,name=localSize,proto3" json:"localSize,omitempty"` // Number of channels in the normalization window.
	K             float32                `protobuf:"fixed32,4,opt,name=k,proto3" json:"k,omitempty"`                // Defaults to 1 if not set or 0. Must be strictly positive.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LRNLayerParams) Reset() {
	*x = LRNLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[55]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LRNLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LRNLayerParams) ProtoMessage() {}

func (x *LRNLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[55]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LRNLayerParams.ProtoReflect.Descriptor instead.
func (*LRNLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{55}
}

func (x *LRNLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

func (x *LRNLayerParams) GetBeta() float32 {
	if x != nil {
		return x.Beta
	}
	return 0
}

func (x *LRNLayerParams) GetLocalSize() uint64 {
	if x != nil {
		return x.LocalSize
	}
	return 0
}

func (x *LRNLayerParams) GetK() float32 {
	if x != nil {
		return x.K
	}
	return 0
}

// Softmax Normalization Layer
//
// A layer that performs softmax normalization.
// Normalization is applied along axis = -3 or N-3 (where N is the rank of the input)
// For softmax layer that can operate on any axis, see SoftmaxNDLayer.
//
// .. code::
//
//	y = SoftmaxLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	Must be a blob with rank >= 3.
//
// Output
//
//	A blob with the same shape as the input.
//
// This layer is described by the following formula:
//
// .. math::
//
//	x_i \leftarrow \dfrac{e^{x_i}}{\sum_i{e^{x_i}}}
type SoftmaxLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SoftmaxLayerParams) Reset() {
	*x = SoftmaxLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[56]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SoftmaxLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SoftmaxLayerParams) ProtoMessage() {}

func (x *SoftmaxLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[56]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SoftmaxLayerParams.ProtoReflect.Descriptor instead.
func (*SoftmaxLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{56}
}

// A layer that uniformly splits across axis = -3 to produce a specified number of outputs.
// For general split operation along any axis, see SplitNDLayer.
//
// .. code::
//
//	(y1,y2,...yN) = SplitLayer(x), where N = nOutputs
//
// Requires 1 input and produces multiple outputs.
//
// Input
//
//	A blob with rank at least 3.
//	e.g.: blob with shape ``[C, H, W]``
//
// Output
//
//	``nOutputs`` blobs each with same rank as the input.
//	e.g.: For input that is of shape ``[C, H, W]``, output shapes will be ``[C/nOutputs, H, W]``
type SplitLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	NOutputs      uint64                 `protobuf:"varint,1,opt,name=nOutputs,proto3" json:"nOutputs,omitempty"` // The number of outputs.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SplitLayerParams) Reset() {
	*x = SplitLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[57]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SplitLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SplitLayerParams) ProtoMessage() {}

func (x *SplitLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[57]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SplitLayerParams.ProtoReflect.Descriptor instead.
func (*SplitLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{57}
}

func (x *SplitLayerParams) GetNOutputs() uint64 {
	if x != nil {
		return x.NOutputs
	}
	return 0
}

// A layer that performs elementwise addition.
// This layer has limited broadcasting support. For general broadcasting see AddBroadcastableLayer.
//
// .. code::
//
//	y = AddLayer(x1,x2,...)
//
// Requires 1 or more than 1 input and produces 1 output.
//
// Input
//
//	In general, there are no rank constraints.
//	However, only certain set of shapes are broadcastable. For example:
//	[B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]
//
// Output
//
//	A blob with shape equal to the input blob.
//
// If only one input is provided, scalar addition is performed:
//
// .. math::
//
//	y = x + \alpha
type AddLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Scalar to be added to the input.
	// Only used if there is a single input.
	Alpha         float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AddLayerParams) Reset() {
	*x = AddLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[58]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AddLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AddLayerParams) ProtoMessage() {}

func (x *AddLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[58]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AddLayerParams.ProtoReflect.Descriptor instead.
func (*AddLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{58}
}

func (x *AddLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// A layer that performs elementwise multiplication.
// This layer has limited broadcasting support. For general broadcasting see MultiplyBroadcastableLayer.
//
// .. code::
//
//	y = MultiplyLayer(x1,x2,...)
//
// Requires 1 or more than 1 input and produces 1 output.
//
// Input
//
//	In general, there are no rank constraints.
//	However, only certain set of shapes are broadcastable. For example:
//	[B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]
//
// Output
//
//	A blob with shape equal to the first input blob.
//
// If only one input is provided, scalar multiplication is performed:
//
// .. math::
//
//	y = \alpha x
type MultiplyLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Scalar to be multiplied with the input.
	// Only used if there is a single input.
	Alpha         float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MultiplyLayerParams) Reset() {
	*x = MultiplyLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[59]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MultiplyLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MultiplyLayerParams) ProtoMessage() {}

func (x *MultiplyLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[59]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MultiplyLayerParams.ProtoReflect.Descriptor instead.
func (*MultiplyLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{59}
}

func (x *MultiplyLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// A layer that applies a unary function.
//
// .. code::
//
//	y = UnaryFunctionLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with no rank constraints.
//
// Output
//
//	A blob with the same shape as the input.
//
// The input is first modified by shifting and scaling:
//
// .. math::
//
//	x \leftarrow \text{scale} \cdot x + \text{shift}
type UnaryFunctionLayerParams struct {
	state protoimpl.MessageState             `protogen:"open.v1"`
	Type  UnaryFunctionLayerParams_Operation `protobuf:"varint,1,opt,name=type,proto3,enum=CoreML.Specification.UnaryFunctionLayerParams_Operation" json:"type,omitempty"` // The type of unary function.
	// A constant used in “POWER“ and “THRESHOLD“ functions.
	Alpha float32 `protobuf:"fixed32,2,opt,name=alpha,proto3" json:"alpha,omitempty"`
	// A small constant to avoid division by 0 while normalizing variance.
	// Defaults to “1e-6“ if not set or set to “0“.
	Epsilon float32 `protobuf:"fixed32,3,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	// Input is shifted by this amount
	// before the unary function is applied.
	// Defaults to “0.0“ if not set.
	Shift float32 `protobuf:"fixed32,4,opt,name=shift,proto3" json:"shift,omitempty"`
	// Input is scaled by this amount
	// before the unary function is applied.
	// Defaults to “1.0“ if not set or set to “0“.
	Scale         float32 `protobuf:"fixed32,5,opt,name=scale,proto3" json:"scale,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UnaryFunctionLayerParams) Reset() {
	*x = UnaryFunctionLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[60]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UnaryFunctionLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UnaryFunctionLayerParams) ProtoMessage() {}

func (x *UnaryFunctionLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[60]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UnaryFunctionLayerParams.ProtoReflect.Descriptor instead.
func (*UnaryFunctionLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{60}
}

func (x *UnaryFunctionLayerParams) GetType() UnaryFunctionLayerParams_Operation {
	if x != nil {
		return x.Type
	}
	return UnaryFunctionLayerParams_SQRT
}

func (x *UnaryFunctionLayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

func (x *UnaryFunctionLayerParams) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

func (x *UnaryFunctionLayerParams) GetShift() float32 {
	if x != nil {
		return x.Shift
	}
	return 0
}

func (x *UnaryFunctionLayerParams) GetScale() float32 {
	if x != nil {
		return x.Scale
	}
	return 0
}

// A layer that scales up spatial dimensions.
// It supports two modes: nearest neighbour (default) and bilinear.
//
// .. code::
//
//	y = UpsampleLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 3.
//	e.g.: blob with shape ``[C, H, W]``.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Same rank as the input.
//	e.g.: blob with shape ``[C, scalingFactor[0] * H, scalingFactor[1] * W]``
type UpsampleLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Scaling Factor. Mutually exclusive with fractionalScalingFactor.
	// Must be length 2 in order “[H, W]“.
	// If not set, default value “[1, 1]“ is used.
	ScalingFactor []uint64 `protobuf:"varint,1,rep,packed,name=scalingFactor,proto3" json:"scalingFactor,omitempty"`
	// Fractional scaling factor. Mutually exclusive with scalingFactor.
	// Must be length 2 in order “[H, W]“.
	// If not set, default value “[1.0, 1.0]“ is used.
	FractionalScalingFactor []float32                              `protobuf:"fixed32,7,rep,packed,name=fractionalScalingFactor,proto3" json:"fractionalScalingFactor,omitempty"`
	Mode                    UpsampleLayerParams_InterpolationMode  `protobuf:"varint,5,opt,name=mode,proto3,enum=CoreML.Specification.UpsampleLayerParams_InterpolationMode" json:"mode,omitempty"`
	LinearUpsampleMode      UpsampleLayerParams_LinearUpsampleMode `protobuf:"varint,6,opt,name=linearUpsampleMode,proto3,enum=CoreML.Specification.UpsampleLayerParams_LinearUpsampleMode" json:"linearUpsampleMode,omitempty"`
	unknownFields           protoimpl.UnknownFields
	sizeCache               protoimpl.SizeCache
}

func (x *UpsampleLayerParams) Reset() {
	*x = UpsampleLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[61]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpsampleLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpsampleLayerParams) ProtoMessage() {}

func (x *UpsampleLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[61]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpsampleLayerParams.ProtoReflect.Descriptor instead.
func (*UpsampleLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{61}
}

func (x *UpsampleLayerParams) GetScalingFactor() []uint64 {
	if x != nil {
		return x.ScalingFactor
	}
	return nil
}

func (x *UpsampleLayerParams) GetFractionalScalingFactor() []float32 {
	if x != nil {
		return x.FractionalScalingFactor
	}
	return nil
}

func (x *UpsampleLayerParams) GetMode() UpsampleLayerParams_InterpolationMode {
	if x != nil {
		return x.Mode
	}
	return UpsampleLayerParams_NN
}

func (x *UpsampleLayerParams) GetLinearUpsampleMode() UpsampleLayerParams_LinearUpsampleMode {
	if x != nil {
		return x.LinearUpsampleMode
	}
	return UpsampleLayerParams_DEFAULT
}

// A layer that resizes the input to a pre-specified spatial size using bilinear interpolation.
//
// .. code::
//
//	y = ResizeBilinearLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 3.
//	e.g.: blob with shape ``[C, H_in, W_in]``.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Same rank as the input.
//	e.g.: blob with shape ``[C, H_out, W_out]``.
type ResizeBilinearLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Target Spatial Size.
	// Must be length 2 in order “[Height, Width]“, i.e. “[H_out, W_out]“.
	// If not set, default value “[1, 1]“ is used.
	TargetSize []uint64 `protobuf:"varint,1,rep,packed,name=targetSize,proto3" json:"targetSize,omitempty"`
	// Mode used to compute the grid on which the spatial output values are evaluated.
	// Same mode is applied to both the height and width axes.
	Mode          *SamplingMode `protobuf:"bytes,2,opt,name=mode,proto3" json:"mode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResizeBilinearLayerParams) Reset() {
	*x = ResizeBilinearLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[62]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResizeBilinearLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResizeBilinearLayerParams) ProtoMessage() {}

func (x *ResizeBilinearLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[62]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResizeBilinearLayerParams.ProtoReflect.Descriptor instead.
func (*ResizeBilinearLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{62}
}

func (x *ResizeBilinearLayerParams) GetTargetSize() []uint64 {
	if x != nil {
		return x.TargetSize
	}
	return nil
}

func (x *ResizeBilinearLayerParams) GetMode() *SamplingMode {
	if x != nil {
		return x.Mode
	}
	return nil
}

// A layer that extracts cropped spatial patches or RoIs (regions of interest) from the input and resizes them to a pre-specified size using
// bilinear interpolation.
// Note that RoI Align layer can be implemented with this layer followed by a pooling layer.
//
// .. code::
//
//	y = CropResizeLayer(x)
//
// Requires 2 inputs and produces 1 output.
//
// Input
//
//	There are two inputs.
//	First input represents an image feature map.
//	Second input represents the bounding box coordinates for N patches or RoIs (region of interest).
//
//	First input is rank 5: [1, Batch, C, H_in, W_in].
//	Second input is rank 5. Its shape can be either [N, 1, 4, 1, 1] or [N, 1, 5, 1, 1].
//
//	N: number of patches/RoIs to be extracted
//
//	If RoI shape = ``[N, 1, 4, 1, 1]``
//	               The axis=-3 corresponds to the four coordinates specifying the bounding box.
//	               All the N RoIs are extracted from all the batches of the input.
//
//	If RoI shape = ``[N, 1, 5, 1, 1]``
//	                The first element of the axis=-3 specifies the input batch id from which to extract the RoI and
//	                          must be in the interval ``[0, Batch - 1]``. That is, n-th RoI is extracted from the RoI[n,0,0,0,0]-th
//	                input batch id. The last four elements of the axis=-3 specify the bounding box coordinates.
//
// Output
//
//	A blob with rank 5.
//	      - Shape is [N, Batch, C, H_out, W_out] if input RoI shape is [N, 1, 4, 1, 1]
//	      - Shape is [N, 1, C, H_out, W_out] if input RoI shape is [N, 1, 5, 1, 1]
type CropResizeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Target Spatial Size.
	// Must be length 2 in order “[Height, Width]“, i.e. “[H_out, W_out]“.
	// If not set, default value “[1, 1]“ is used.
	TargetSize []uint64 `protobuf:"varint,1,rep,packed,name=targetSize,proto3" json:"targetSize,omitempty"`
	// If true the bounding box coordinates must be in the interval [0, 1].
	// They are scaled by (H_in - 1), (W_in - 1), i.e. based on the input spatial dimensions.
	// If false the bounding box coordinates must be in the interval
	// [0, H_in -1] and [0, W_in - 1], respectively for height and width dimensions.
	NormalizedCoordinates bool `protobuf:"varint,2,opt,name=normalizedCoordinates,proto3" json:"normalizedCoordinates,omitempty"`
	// Mode used to compute the grid on which the spatial output values are evaluated.
	// Same mode is applied to both the height and width axes.
	Mode *SamplingMode `protobuf:"bytes,3,opt,name=mode,proto3" json:"mode,omitempty"`
	// Representation used to express the bounding box coordinates.
	// It determines how the values of the second input are interpreted.
	BoxIndicesMode *BoxCoordinatesMode `protobuf:"bytes,4,opt,name=boxIndicesMode,proto3" json:"boxIndicesMode,omitempty"`
	// Additional spatial scale that multiplies the bounding box coordinates.
	// Generally used while implementing the RoI Align layer,
	// which uses unnormalized RoI coordinates along with a spatial scale less than or equal to 1.
	SpatialScale  float32 `protobuf:"fixed32,5,opt,name=spatialScale,proto3" json:"spatialScale,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CropResizeLayerParams) Reset() {
	*x = CropResizeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[63]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CropResizeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CropResizeLayerParams) ProtoMessage() {}

func (x *CropResizeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[63]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CropResizeLayerParams.ProtoReflect.Descriptor instead.
func (*CropResizeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{63}
}

func (x *CropResizeLayerParams) GetTargetSize() []uint64 {
	if x != nil {
		return x.TargetSize
	}
	return nil
}

func (x *CropResizeLayerParams) GetNormalizedCoordinates() bool {
	if x != nil {
		return x.NormalizedCoordinates
	}
	return false
}

func (x *CropResizeLayerParams) GetMode() *SamplingMode {
	if x != nil {
		return x.Mode
	}
	return nil
}

func (x *CropResizeLayerParams) GetBoxIndicesMode() *BoxCoordinatesMode {
	if x != nil {
		return x.BoxIndicesMode
	}
	return nil
}

func (x *CropResizeLayerParams) GetSpatialScale() float32 {
	if x != nil {
		return x.SpatialScale
	}
	return 0
}

// A layer that performs elementwise addition of a bias,
// which is broadcasted to match the input shape.
//
// .. code::
//
//	y = BiasLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 3.
//	e.g.: blob with shape ``[C, H, W]``.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	A blob with the same shape as the input.
type BiasLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The shape of the bias.
	// Must be one of the following:
	// “[1]“, “[C]“, “[1, H, W]“ or “[C, H, W]“.
	Shape []uint64 `protobuf:"varint,1,rep,packed,name=shape,proto3" json:"shape,omitempty"`
	// The bias values.
	// The size must be equal to the product of the “shape“ dimensions.
	Bias          *WeightParams `protobuf:"bytes,2,opt,name=bias,proto3" json:"bias,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BiasLayerParams) Reset() {
	*x = BiasLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[64]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BiasLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BiasLayerParams) ProtoMessage() {}

func (x *BiasLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[64]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BiasLayerParams.ProtoReflect.Descriptor instead.
func (*BiasLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{64}
}

func (x *BiasLayerParams) GetShape() []uint64 {
	if x != nil {
		return x.Shape
	}
	return nil
}

func (x *BiasLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

// A layer that performs elmentwise multiplication by a scale factor
// and optionally adds a bias;
// both the scale and bias are broadcasted to match the input shape.
//
// .. code::
//
//	y = ScaleLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 3.
//	e.g.: blob with shape ``[C, H, W]``.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	A blob with the same shape as the input.
type ScaleLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The shape of the scale.
	// Must be one of the following:
	// “[1]“, “[C]“, “[1, H, W]“ or “[C, H, W]“.
	ShapeScale []uint64 `protobuf:"varint,1,rep,packed,name=shapeScale,proto3" json:"shapeScale,omitempty"`
	// The scale values.
	// The size must be equal to the product of the “shape“ dimensions.
	Scale   *WeightParams `protobuf:"bytes,2,opt,name=scale,proto3" json:"scale,omitempty"`      // Scale values. Size must be equal to the product of dimensions specified in shapeScale.
	HasBias bool          `protobuf:"varint,3,opt,name=hasBias,proto3" json:"hasBias,omitempty"` // If true, a bias is added after scaling.
	// The shape of the bias.
	// Must be one of the following:
	// “[1]“, “[C]“, “[1, H, W]“ or “[C, H, W]“.
	ShapeBias []uint64 `protobuf:"varint,4,rep,packed,name=shapeBias,proto3" json:"shapeBias,omitempty"`
	// The bias values.
	// The size must be equal to the product of the “shape“ dimensions.
	Bias          *WeightParams `protobuf:"bytes,5,opt,name=bias,proto3" json:"bias,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ScaleLayerParams) Reset() {
	*x = ScaleLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[65]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScaleLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScaleLayerParams) ProtoMessage() {}

func (x *ScaleLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[65]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ScaleLayerParams.ProtoReflect.Descriptor instead.
func (*ScaleLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{65}
}

func (x *ScaleLayerParams) GetShapeScale() []uint64 {
	if x != nil {
		return x.ShapeScale
	}
	return nil
}

func (x *ScaleLayerParams) GetScale() *WeightParams {
	if x != nil {
		return x.Scale
	}
	return nil
}

func (x *ScaleLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *ScaleLayerParams) GetShapeBias() []uint64 {
	if x != nil {
		return x.ShapeBias
	}
	return nil
}

func (x *ScaleLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

// A layer that loads data as a parameter and provides it as an output.
// The output is rank 5. For general rank, see LoadConstantNDLayer.
//
// .. code::
//
//	y = LoadConstantLayer()
//
// Requires no input and produces 1 output.
//
// Output:
//
//	A blob with rank 5 and shape ``[1, 1, C, H, W]``
type LoadConstantLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The shape of the constant to be loaded,
	// which must be“[C, H, W]“, that is length 3.
	Shape []uint64 `protobuf:"varint,1,rep,packed,name=shape,proto3" json:"shape,omitempty"`
	// The data values,
	// of size “C * H * W“.
	Data          *WeightParams `protobuf:"bytes,2,opt,name=data,proto3" json:"data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoadConstantLayerParams) Reset() {
	*x = LoadConstantLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[66]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoadConstantLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoadConstantLayerParams) ProtoMessage() {}

func (x *LoadConstantLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[66]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoadConstantLayerParams.ProtoReflect.Descriptor instead.
func (*LoadConstantLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{66}
}

func (x *LoadConstantLayerParams) GetShape() []uint64 {
	if x != nil {
		return x.Shape
	}
	return nil
}

func (x *LoadConstantLayerParams) GetData() *WeightParams {
	if x != nil {
		return x.Data
	}
	return nil
}

// A layer that performs L2 normalization, i.e. divides by the
// the square root of the sum of squares of all elements of input.
//
// .. code::
//
//	y = L2NormalizeLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank greater than equal to 3.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	A blob with the same shape as the input.
//
// This layer is described by the following formula:
//
// .. math::
//
//	x_i \leftarrow \dfrac{x_i}{\sqrt{\sum{x_i^2} + \epsilon}}
type L2NormalizeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A small constant to avoid division by 0 while normalizing variance.
	// Defaults to “1e-6“ if not set or set to “0“.
	Epsilon       float32 `protobuf:"fixed32,1,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *L2NormalizeLayerParams) Reset() {
	*x = L2NormalizeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[67]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *L2NormalizeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*L2NormalizeLayerParams) ProtoMessage() {}

func (x *L2NormalizeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[67]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use L2NormalizeLayerParams.ProtoReflect.Descriptor instead.
func (*L2NormalizeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{67}
}

func (x *L2NormalizeLayerParams) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// A layer that flattens the input.
//
// .. code::
//
//	y = FlattenLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank greater than equal to 3.
//	e.g.: Rank 4 blob represents [Batch, C, H, W]
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Same rank as the input, such that last two dimensions are both 1.
//	e.g.: For rank 4 input, output shape is ``[Batch, C * H * W, 1, 1]``
//
// There are two X orders: “CHANNEL_FIRST“ and “CHANNEL_LAST“.
// “CHANNEL_FIRST“ does not require data to be rearranged,
// because row major ordering is used by internal storage.
// “CHANNEL_LAST“ requires data to be rearranged.
type FlattenLayerParams struct {
	state         protoimpl.MessageState          `protogen:"open.v1"`
	Mode          FlattenLayerParams_FlattenOrder `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.Specification.FlattenLayerParams_FlattenOrder" json:"mode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FlattenLayerParams) Reset() {
	*x = FlattenLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[68]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FlattenLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FlattenLayerParams) ProtoMessage() {}

func (x *FlattenLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[68]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FlattenLayerParams.ProtoReflect.Descriptor instead.
func (*FlattenLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{68}
}

func (x *FlattenLayerParams) GetMode() FlattenLayerParams_FlattenOrder {
	if x != nil {
		return x.Mode
	}
	return FlattenLayerParams_CHANNEL_FIRST
}

// A layer that recasts the input into a new shape.
//
// .. code::
//
//	y = ReshapeLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank 5.
//	e.g.: ``[1, 1, C, H, W]`` or ``[Seq, 1, C, H, W]``.
//
// Output
//
//	A blob with rank 5.
//	e.g.: ``[1, 1, C_out, H_out, W_out]`` or ``[Seq_out, 1, C_out, H_out, W_out]``.
//
// There are two reshape orders: “CHANNEL_FIRST“ and “CHANNEL_LAST“.
// “CHANNEL_FIRST“ is equivalent to
// flattening the input to “[Seq, 1, C * H * W, 1, 1]“ in channel first order
// and then reshaping it to the target shape;
// no data rearrangement is required.
// “CHANNEL_LAST“ is equivalent to
// flattening the input to “[Seq, 1, H * W * C, 1, 1]“ in channel last order,
// reshaping it to “[Seq_out, 1, H_out, W_out, C_out]“ (it is now in "H_out-major"" order),
// and then permuting it to “[C_out, H_out, W_out]“;
// both the flattening and permuting requires the data to be rearranged.
type ReshapeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The shape of the output.
	// Must be of length 3 or 4.
	// If set to 3, “targetShape“ is interpreted as
	// “[1, 1, C_out, H_out, W_out]“, and sequence length of the input is preserved.
	// If set to 4, “targetShape“ is interpreted as
	// “[Seq_out, 1, C_out, H_out, W_out]“,
	// where “Seq_out“ is the new sequence length.
	TargetShape   []int64                         `protobuf:"varint,1,rep,packed,name=targetShape,proto3" json:"targetShape,omitempty"`
	Mode          ReshapeLayerParams_ReshapeOrder `protobuf:"varint,2,opt,name=mode,proto3,enum=CoreML.Specification.ReshapeLayerParams_ReshapeOrder" json:"mode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReshapeLayerParams) Reset() {
	*x = ReshapeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[69]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReshapeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReshapeLayerParams) ProtoMessage() {}

func (x *ReshapeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[69]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReshapeLayerParams.ProtoReflect.Descriptor instead.
func (*ReshapeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{69}
}

func (x *ReshapeLayerParams) GetTargetShape() []int64 {
	if x != nil {
		return x.TargetShape
	}
	return nil
}

func (x *ReshapeLayerParams) GetMode() ReshapeLayerParams_ReshapeOrder {
	if x != nil {
		return x.Mode
	}
	return ReshapeLayerParams_CHANNEL_FIRST
}

// A layer that rearranges the dimensions and data of an input.
// For generic transpose/permute operation see TransposeLayer.
//
// .. code::
//
//	y = PermuteLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	Must be a rank 5 blob.
//	e.g.: shape ``[Seq, B, C, H, W]``.
//
// Output
//
//	Rank 5 blob. Transposed version of the input, such that dimensions at axis=1 or axis=-4 is unchanged.
//
// Examples:
//
//	Assume input shape is [Seq, B, C, H, W]
//
//   - If “axis“ is set to “[0, 3, 1, 2]“,
//     then the output has shape “[Seq, B, W, C, H]“
//
//   - If “axis“ is set to “[3, 1, 2, 0]“,
//     then the output has shape “[W, B, C, H, Seq]“
//
//   - If “axis“ is set to “[0, 3, 2, 1]“,
//     then the output has shape “[Seq, B, W, H, C]“
//
//   - If “axis“ is not set, or is set to “[0, 1, 2, 3]“,
//     the output is the same as the input.
type PermuteLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The order in which to permute the dimensions.
	// Must have length 4 and a permutation of “[0, 1, 2, 3]“.
	Axis          []uint64 `protobuf:"varint,1,rep,packed,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PermuteLayerParams) Reset() {
	*x = PermuteLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[70]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PermuteLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PermuteLayerParams) ProtoMessage() {}

func (x *PermuteLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[70]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PermuteLayerParams.ProtoReflect.Descriptor instead.
func (*PermuteLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{70}
}

func (x *PermuteLayerParams) GetAxis() []uint64 {
	if x != nil {
		return x.Axis
	}
	return nil
}

// A layer that reorganizes data in the input in specific ways.
//
// .. code::
//
//	y = ReorganizeDataLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 3.
//	e.g.: blob with shape ``[C, H, W]``.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Same rank as the input.
//	e.g.: blob with shape ``[C_out, H_out, W_out]``.
//
// mode == SPACE_TO_DEPTH
//
//	``[C_out, H_out, W_out]`` : ``[C * blockSize * blockSize, H/blockSize, W/blockSize]``.
//	blockSize must divide H and W.
//	Data is moved from the spatial dimensions to the channel dimension. Input is spatially divided into
//	non-overlapping blocks of size blockSize X blockSize and data from each block is moved into the
//	channel dimension.
//
// mode == DEPTH_TO_SPACE
//
//	``[C_out, H_out, W_out]`` : ``[C/(blockSize * blockSize), H * blockSize, W * blockSize]``.
//	Square of blockSize must divide C.
//	Reverse of SPACE_TO_DEPTH. Data is moved from the channel dimension to the spatial dimensions.
//
// mode == PIXEL_SHUFFLE
//
//	``[C_out, H_out, W_out]`` : ``[C/(blockSize * blockSize), H * blockSize, W *  blockSize]``.
//	Square of blockSize must divide C.
//	Similar to DEPTH_TO_SPACE, but using the pixel-shuffle semantics for channel order in the output space.
//	In both modes, elements along the channel dimension are collapsed into
//	blocks in the spatial dimensions. The difference is in the arrangement of
//	the input-channels' data in the output space. See below example for more
//	detail.
//	(Only available in Core ML Specification >= 5 (iOS >= 14, macOS >= 11.0)
//
// Examples:
//
// Assume input is the following [C = 8, H = 1, W = 2] tensor:
//
// .. code::
//
//	[[[1 2]] [[3 4]] [[5 6]] [[7 8]] [[9 10]] [[11 12]] [[13 14]] [[15 16]]]
//
// If block_size == 2 and mode == DEPTH_TO_SPACE, output will be the following
// [C = 2, H = 2, W = 4] tensor:
//
// .. code::
//
//	[[[ 1  5  2  6]
//	  [ 9 13 10 14]]
//
//	 [[ 3  7  4  8]
//	  [11 15 12 16]]]
//
// For mode == SPACE_TO_DEPTH, the behavior is the same as mode ==
// DEPTH_TO_SPACE, but with the input and output swapped.
//
// If block_size == 2 and mode == PIXEL_SHUFFLE, output will be the following
// [C = 2, H = 2, W = 4] tensor:
//
// .. code::
//
//	[[[ 1  3  2  4]
//	  [ 5  7  6  8]]
//
//	 [[ 9 11 10 12]
//	  [13 15 14 16]]]
type ReorganizeDataLayerParams struct {
	state         protoimpl.MessageState                       `protogen:"open.v1"`
	Mode          ReorganizeDataLayerParams_ReorganizationType `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.Specification.ReorganizeDataLayerParams_ReorganizationType" json:"mode,omitempty"`
	BlockSize     uint64                                       `protobuf:"varint,2,opt,name=blockSize,proto3" json:"blockSize,omitempty"` // must be greater than 1
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReorganizeDataLayerParams) Reset() {
	*x = ReorganizeDataLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[71]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReorganizeDataLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReorganizeDataLayerParams) ProtoMessage() {}

func (x *ReorganizeDataLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[71]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReorganizeDataLayerParams.ProtoReflect.Descriptor instead.
func (*ReorganizeDataLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{71}
}

func (x *ReorganizeDataLayerParams) GetMode() ReorganizeDataLayerParams_ReorganizationType {
	if x != nil {
		return x.Mode
	}
	return ReorganizeDataLayerParams_SPACE_TO_DEPTH
}

func (x *ReorganizeDataLayerParams) GetBlockSize() uint64 {
	if x != nil {
		return x.BlockSize
	}
	return 0
}

// A layer that slices the input data along axis = -1 or -2 or -3.
// For general slice along any axis, please see SliceStaticLayer/SliceDynamicLayer.
//
// .. code::
//
//	y = SliceLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob that can, in general, have any rank. However, depending on the value of "axis" ,
//	there may be additional rank constraints.
//
// Output
//
//	A blob with the same rank as the input.
//
// Sliced section is taken from the interval “[startIndex, endIndex)“, i.e.
// startIndex is inclusive while endIndex is exclusive.
// stride must be positive and represents the step size for slicing.
// Negative indexing is supported for startIndex and endIndex.
// -1 denotes N-1, -2 denotes N-2 and so on, where N is the length of the dimension to be sliced.
type SliceLayerParams struct {
	state      protoimpl.MessageState `protogen:"open.v1"`
	StartIndex int64                  `protobuf:"varint,1,opt,name=startIndex,proto3" json:"startIndex,omitempty"` // start of the sliced section. Inclusive.
	EndIndex   int64                  `protobuf:"varint,2,opt,name=endIndex,proto3" json:"endIndex,omitempty"`     // end of sliced section. Exclusive.
	Stride     uint64                 `protobuf:"varint,3,opt,name=stride,proto3" json:"stride,omitempty"`         // The step size. Must be positive.
	// The following mapping is used for interpreting this parameter:
	// CHANNEL_AXIS => axis = -3, input must have rank at least 3.
	// HEIGHT_AXIS => axis = -2, input must have rank at least 2.
	// WIDTH_AXIS => axis = -1
	Axis          SliceLayerParams_SliceAxis `protobuf:"varint,4,opt,name=axis,proto3,enum=CoreML.Specification.SliceLayerParams_SliceAxis" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SliceLayerParams) Reset() {
	*x = SliceLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[72]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SliceLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SliceLayerParams) ProtoMessage() {}

func (x *SliceLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[72]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SliceLayerParams.ProtoReflect.Descriptor instead.
func (*SliceLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{72}
}

func (x *SliceLayerParams) GetStartIndex() int64 {
	if x != nil {
		return x.StartIndex
	}
	return 0
}

func (x *SliceLayerParams) GetEndIndex() int64 {
	if x != nil {
		return x.EndIndex
	}
	return 0
}

func (x *SliceLayerParams) GetStride() uint64 {
	if x != nil {
		return x.Stride
	}
	return 0
}

func (x *SliceLayerParams) GetAxis() SliceLayerParams_SliceAxis {
	if x != nil {
		return x.Axis
	}
	return SliceLayerParams_CHANNEL_AXIS
}

// A layer that reduces the input using a specified operation.
//
// .. code::
//
//	y = ReduceLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob that can, in general, have any rank. However, depending on the value of "axis" ,
//	 there may be additional rank constraints.
//
// Output
//
//	A blob with the same rank as the input, which has 1s on the dimensions specified in the parameter "axis"
//
//	Values supported for axis are [-1], [-2], [-3], [-2,-1], [-3,-2,-1]
//	and the equivalent positive values (depending on the rank of the input)
//	For mode == 'ArgMax', axis must be [-1] or [-2] or [-3].
type ReduceLayerParams struct {
	state protoimpl.MessageState            `protogen:"open.v1"`
	Mode  ReduceLayerParams_ReduceOperation `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.Specification.ReduceLayerParams_ReduceOperation" json:"mode,omitempty"` // Specifies function used to reduce.
	// Used if mode is “LOGSUM“.
	// Defaults to “1e-6“ if not set or is set to “0“.
	Epsilon float32 `protobuf:"fixed32,2,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	// The following mapping is used for interpreting this parameter:
	// CHW = axis [-3, -2, -1], input must have rank at least 3.
	// HW = axis [-2, -1], input must have rank at least 2.
	// C = axis [-3]
	// H = axis [-2]
	// W = axis [-1]
	Axis          ReduceLayerParams_ReduceAxis `protobuf:"varint,3,opt,name=axis,proto3,enum=CoreML.Specification.ReduceLayerParams_ReduceAxis" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceLayerParams) Reset() {
	*x = ReduceLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[73]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceLayerParams) ProtoMessage() {}

func (x *ReduceLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[73]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{73}
}

func (x *ReduceLayerParams) GetMode() ReduceLayerParams_ReduceOperation {
	if x != nil {
		return x.Mode
	}
	return ReduceLayerParams_SUM
}

func (x *ReduceLayerParams) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

func (x *ReduceLayerParams) GetAxis() ReduceLayerParams_ReduceAxis {
	if x != nil {
		return x.Axis
	}
	return ReduceLayerParams_CHW
}

// A layer that crops the spatial dimensions of an input.
// If two inputs are provided, the shape of the second input is used as the reference shape.
//
// .. code::
//
//	y = CropLayer(x1) or y = CropLayer(x1,x2)
//
// Requires 1 or 2 inputs and produces 1 output.
//
// Input
//
//	1 or 2 tensors, each with rank at least 3, both inputs must have equal rank.
//	Example:
//	 - 1 input case: A blob with shape ``[C, H_in, W_in]``.
//	 - 2 input case: 1st blob with shape ``[C, H_in, W_in]``, 2nd blob with shape ``[C, H_out, W_out]``.
//
//	 For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Same rank as the inputs.
//	e.g.: A blob with shape ``[C, H_out, W_out]``.
//
// If one input is used, output is computed as follows:
//
// .. code::
//
//	y = x1[:, topCropAmount:H_in - bottomCropAmount, leftCropAmount:W_in - rightCropAmount]
//
//	topCropAmount == Height startEdgeSize == borderAmounts[0].startEdgeSize
//	bottomCropAmount == Height endEdgeSize == borderAmounts[0].endEdgeSize
//	leftCropAmount == Width startEdgeSize == borderAmounts[1].startEdgeSize
//	rightCropAmount == Width endEdgeSize == borderAmounts[1].endEdgeSize
//
//	H_out = H_in - topCropAmount - bottomCropAmount
//	W_out = W_in - leftCropAmount - rightCropAmount
//
// If two inputs are used, output is computed as follows:
//
// .. code::
//
//	y = x1[:, offset[0]:offset[0] + H_out, offset[1]:offset[1] + W_out]
type CropLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The amounts to be cropped from the input.
	// Used only if a single input is provided.
	CropAmounts *BorderAmounts `protobuf:"bytes,1,opt,name=cropAmounts,proto3" json:"cropAmounts,omitempty"`
	// The offset amounts.
	// Used only if two inputs are provided.
	// Must be of length 2, in order “[H, W]“.
	Offset        []uint64 `protobuf:"varint,5,rep,packed,name=offset,proto3" json:"offset,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CropLayerParams) Reset() {
	*x = CropLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[74]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CropLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CropLayerParams) ProtoMessage() {}

func (x *CropLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[74]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CropLayerParams.ProtoReflect.Descriptor instead.
func (*CropLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{74}
}

func (x *CropLayerParams) GetCropAmounts() *BorderAmounts {
	if x != nil {
		return x.CropAmounts
	}
	return nil
}

func (x *CropLayerParams) GetOffset() []uint64 {
	if x != nil {
		return x.Offset
	}
	return nil
}

// A layer that computes the elementwise average of the inputs.
// This layer has limited broadcasting support. For general broadcasting see AddBroadcastableLayer.
//
// .. code::
//
//	y = AverageLayer(x1,x2,...)
//
// Requires multiple inputs and produces 1 output.
//
// Input
//
//	In general, there are no rank constraints.
//	However, only certain set of shapes are broadcastable. For example:
//	[B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]
//
// Output
//
//	A blob with the same shape as each input.
type AverageLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AverageLayerParams) Reset() {
	*x = AverageLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[75]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AverageLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AverageLayerParams) ProtoMessage() {}

func (x *AverageLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[75]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AverageLayerParams.ProtoReflect.Descriptor instead.
func (*AverageLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{75}
}

// A layer that computes the elementwise maximum over the inputs.
//
// .. code::
//
//	y = MaxLayer(x1,x2,...)
//
// Requires multiple inputs and produces 1 output.
//
// Input
//
//	In general, there are no rank constraints.
//	However, only certain set of shapes are broadcastable. For example:
//	[B, C, 1, 1], [B, C, H, W]
//
// Output
//
//	A blob with the same shape as each input.
type MaxLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MaxLayerParams) Reset() {
	*x = MaxLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[76]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MaxLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MaxLayerParams) ProtoMessage() {}

func (x *MaxLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[76]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MaxLayerParams.ProtoReflect.Descriptor instead.
func (*MaxLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{76}
}

// A layer that computes the elementwise minimum over the inputs.
//
// .. code::
//
//	y = MinLayer(x1,x2,...)
//
// Requires multiple inputs and produces 1 output.
//
// Input
//
//	In general, there are no rank constraints.
//	However, only certain set of shapes are broadcastable. For example:
//	[B, C, 1, 1], [B, C, H, W]
//
// Output
//
//	A blob with the same shape as each input.
type MinLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MinLayerParams) Reset() {
	*x = MinLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[77]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MinLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MinLayerParams) ProtoMessage() {}

func (x *MinLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[77]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MinLayerParams.ProtoReflect.Descriptor instead.
func (*MinLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{77}
}

// A layer that computes the dot product of two vectors.
//
// .. code::
//
//	y = DotProductLayer(x1,x2)
//
// Requires 2 inputs and produces 1 output.
//
// Input
//
//	Two blobs with rank at least 3, such that the last two dimensions must be 1.
//	e.g.: blobs with shape ``[B, C, 1, 1]``.
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	Same rank as the input.
//	e.g. for rank 4 inputs, output shape: [B, 1, 1, 1]
type DotProductLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If true, inputs are normalized first,
	// thereby computing the cosine similarity.
	CosineSimilarity bool `protobuf:"varint,1,opt,name=cosineSimilarity,proto3" json:"cosineSimilarity,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *DotProductLayerParams) Reset() {
	*x = DotProductLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[78]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DotProductLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DotProductLayerParams) ProtoMessage() {}

func (x *DotProductLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[78]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DotProductLayerParams.ProtoReflect.Descriptor instead.
func (*DotProductLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{78}
}

func (x *DotProductLayerParams) GetCosineSimilarity() bool {
	if x != nil {
		return x.CosineSimilarity
	}
	return false
}

// A layer that performs mean variance normalization, along axis = -3.
//
// .. code::
//
//	y = MeanVarianceNormalizeLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank greater than equal to 3.
//	Example: Rank 4 blob represents [Batch, channels, height, width]
//	For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
//
// Output
//
//	A blob with the same shape as the input.
//
// If “acrossChannels == true“
// normalization is performed on flattened input, i.e. the input is reshaped to (Batch,C), where "Batch" contains
// all dimensions from 0 to -4 (inclusive), and C contains dimensions -1, -2, -3.
//
// If “acrossChannels == false“
// normalization is performed within a channel,
// across spatial dimensions (i.e. last two dimensions).
type MeanVarianceNormalizeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If true, mean and variance are computed across channels.
	AcrossChannels bool `protobuf:"varint,1,opt,name=acrossChannels,proto3" json:"acrossChannels,omitempty"`
	// If false, only mean is subtracted.
	NormalizeVariance bool `protobuf:"varint,2,opt,name=normalizeVariance,proto3" json:"normalizeVariance,omitempty"`
	// A small constant to avoid division by 0 while normalizing variance.
	// Defaults to “1e-6“ if not set or set to “0“.
	Epsilon       float32 `protobuf:"fixed32,3,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MeanVarianceNormalizeLayerParams) Reset() {
	*x = MeanVarianceNormalizeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[79]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MeanVarianceNormalizeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MeanVarianceNormalizeLayerParams) ProtoMessage() {}

func (x *MeanVarianceNormalizeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[79]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MeanVarianceNormalizeLayerParams.ProtoReflect.Descriptor instead.
func (*MeanVarianceNormalizeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{79}
}

func (x *MeanVarianceNormalizeLayerParams) GetAcrossChannels() bool {
	if x != nil {
		return x.AcrossChannels
	}
	return false
}

func (x *MeanVarianceNormalizeLayerParams) GetNormalizeVariance() bool {
	if x != nil {
		return x.NormalizeVariance
	}
	return false
}

func (x *MeanVarianceNormalizeLayerParams) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// A layer that repeats a sequence or the dimension sitting at axis = -5
//
// .. code::
//
//	y = SequenceRepeatLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	A blob with rank at least 5.
//	e.g: shape ``[Seq, B, C, H, W]``
//
// Output
//
//	A blob with the same rank as the input.
//	e.g.: for input shape ``[Seq, B, C, H, W]``, output shape is ``[nRepetitions * Seq, B, C, H, W]``.
type SequenceRepeatLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Number of repetitions.
	// Defaults to “1“ if not set or set to “0“.
	NRepetitions  uint64 `protobuf:"varint,1,opt,name=nRepetitions,proto3" json:"nRepetitions,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SequenceRepeatLayerParams) Reset() {
	*x = SequenceRepeatLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[80]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SequenceRepeatLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SequenceRepeatLayerParams) ProtoMessage() {}

func (x *SequenceRepeatLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[80]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SequenceRepeatLayerParams.ProtoReflect.Descriptor instead.
func (*SequenceRepeatLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{80}
}

func (x *SequenceRepeatLayerParams) GetNRepetitions() uint64 {
	if x != nil {
		return x.NRepetitions
	}
	return 0
}

// A simple recurrent layer.
//
// .. code::
//
//	y_t = SimpleRecurrentLayer(x_t, y_{t-1})
//
// Input
//
//	A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
//	This represents a sequence of vectors of size ``inputVectorSize``.
//
// Output
//
//	Same rank as the input.
//	Represents a vector of size ``outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
//
// - Output Shape: “[1, Batch, outputVectorSize, 1, 1]“ , if “sequenceOutput == false“
// - Output Shape: “[Seq, Batch, outputVectorSize, 1, 1]“ , if “sequenceOutput == true“
//
// This layer is described by the following equation:
//
// .. math::
//
//	\boldsymbol{y_t} = f(\mathrm{clip}(W \boldsymbol{x_t} + \
//	                                   R \boldsymbol{y_{t-1}} + b))
//
//   - “W“ is a 2-dimensional weight matrix
//     (“[outputVectorSize, inputVectorSize]“, row-major)
//   - “R“ is a 2-dimensional recursion matrix
//     (“[outputVectorSize, outputVectorSize]“, row-major)
//   - “b“ is a 1-dimensional bias vector (“[outputVectorSize]“)
//   - “f()“ is an activation
//   - “clip()“ is a function that constrains values between “[-50.0, 50.0]“
type SimpleRecurrentLayerParams struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	InputVectorSize  uint64                 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`   // The size of the input vectors.
	OutputVectorSize uint64                 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"` // The size of the output vectors.
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	Activation *ActivationParams `protobuf:"bytes,10,opt,name=activation,proto3" json:"activation,omitempty"` // The activation function.
	// If false output is just the result after final state update.
	// If true, output is a sequence, containing outputs at all time steps.
	SequenceOutput  bool          `protobuf:"varint,15,opt,name=sequenceOutput,proto3" json:"sequenceOutput,omitempty"`
	HasBiasVector   bool          `protobuf:"varint,20,opt,name=hasBiasVector,proto3" json:"hasBiasVector,omitempty"`    // If false, no bias is added.
	WeightMatrix    *WeightParams `protobuf:"bytes,30,opt,name=weightMatrix,proto3" json:"weightMatrix,omitempty"`       // Weight matrix W.
	RecursionMatrix *WeightParams `protobuf:"bytes,31,opt,name=recursionMatrix,proto3" json:"recursionMatrix,omitempty"` // Recursion Weight matrix R.
	BiasVector      *WeightParams `protobuf:"bytes,32,opt,name=biasVector,proto3" json:"biasVector,omitempty"`           // Bias vector b.
	ReverseInput    bool          `protobuf:"varint,100,opt,name=reverseInput,proto3" json:"reverseInput,omitempty"`     // If true, then the node processes the input sequence from right to left
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *SimpleRecurrentLayerParams) Reset() {
	*x = SimpleRecurrentLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[81]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SimpleRecurrentLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SimpleRecurrentLayerParams) ProtoMessage() {}

func (x *SimpleRecurrentLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[81]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SimpleRecurrentLayerParams.ProtoReflect.Descriptor instead.
func (*SimpleRecurrentLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{81}
}

func (x *SimpleRecurrentLayerParams) GetInputVectorSize() uint64 {
	if x != nil {
		return x.InputVectorSize
	}
	return 0
}

func (x *SimpleRecurrentLayerParams) GetOutputVectorSize() uint64 {
	if x != nil {
		return x.OutputVectorSize
	}
	return 0
}

func (x *SimpleRecurrentLayerParams) GetActivation() *ActivationParams {
	if x != nil {
		return x.Activation
	}
	return nil
}

func (x *SimpleRecurrentLayerParams) GetSequenceOutput() bool {
	if x != nil {
		return x.SequenceOutput
	}
	return false
}

func (x *SimpleRecurrentLayerParams) GetHasBiasVector() bool {
	if x != nil {
		return x.HasBiasVector
	}
	return false
}

func (x *SimpleRecurrentLayerParams) GetWeightMatrix() *WeightParams {
	if x != nil {
		return x.WeightMatrix
	}
	return nil
}

func (x *SimpleRecurrentLayerParams) GetRecursionMatrix() *WeightParams {
	if x != nil {
		return x.RecursionMatrix
	}
	return nil
}

func (x *SimpleRecurrentLayerParams) GetBiasVector() *WeightParams {
	if x != nil {
		return x.BiasVector
	}
	return nil
}

func (x *SimpleRecurrentLayerParams) GetReverseInput() bool {
	if x != nil {
		return x.ReverseInput
	}
	return false
}

// Gated-Recurrent Unit (GRU) Layer
//
// .. code::
//
//	y_t = GRULayer(x_t, y_{t-1})
//
// Input
//
//	A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
//	This represents a sequence of vectors of size ``inputVectorSize``.
//
// Output
//
//	Same rank as the input.
//	Represents a vector of size ``outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
//
// - Output Shape: “[1, Batch, outputVectorSize, 1, 1]“ , if “sequenceOutput == false“
// - Output Shape: “[Seq, Batch, outputVectorSize, 1, 1]“ , if “sequenceOutput == true“
//
// This layer is described by the following equations:
//
// Update Gate
//
//	.. math::
//	    \boldsymbol{z_t} = \
//	        f(\mathrm{clip}(W_z \boldsymbol{x_t} + \
//	                        R_z \boldsymbol{y_{t-1}} + b_z)
//
// Reset Gate
//
//	.. math::
//	    \boldsymbol{r_t} = \
//	        f(\mathrm{clip}(W_r \boldsymbol{x_t} + \
//	                        R_r \boldsymbol{y_{t-1}} + b_r))
//
// Cell Memory State
//
//	.. math::
//	    \boldsymbol{c_t} = \
//	        \boldsymbol{y_{t-1}} \odot \boldsymbol{r_t}
//
// Output Gate
//
//	.. math::
//	    \boldsymbol{o_t} = \
//	        g(\mathrm{clip}(W_o \boldsymbol{x_t} + \
//	                        R_o \boldsymbol{c_t} + b_o))
//
// Output
//
//	.. math::
//	    \boldsymbol{y_t} = \
//	        (1 - \boldsymbol{z_t}) \odot \boldsymbol{o_t} + \
//	         \boldsymbol{z_t} \odot \boldsymbol{y_{t-1}}
//
//   - “W_z“, “W_r“, “W_o“ are 2-dimensional input weight matrices
//     (“[outputVectorSize, inputVectorSize]“, row-major)
//   - “R_z“, “R_r“, “R_o“ are 2-dimensional recursion matrices
//     (“[outputVectorSize, outputVectorSize]“, row-major)
//   - “b_z“, “b_r“, “b_o“ are 1-dimensional bias vectors
//     (“[outputVectorSize]“)
//   - “f()“, “g()“ are activations
//   - “clip()“ is a function that constrains values between “[-50.0, 50.0]“
//   - “⊙“ denotes the elementwise product of matrices
type GRULayerParams struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	InputVectorSize  uint64                 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`   // Size of the input vectors.
	OutputVectorSize uint64                 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"` // Size of the output vectors.
	// 2 element array representing activations [f(), g()] in that order.
	// Typical values used = [sigmoid, tanh].
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	Activations []*ActivationParams `protobuf:"bytes,10,rep,name=activations,proto3" json:"activations,omitempty"`
	// If false output is just the result after final state update.
	// If true, output is a sequence, containing outputs at all time steps.
	SequenceOutput bool `protobuf:"varint,15,opt,name=sequenceOutput,proto3" json:"sequenceOutput,omitempty"`
	// If false, no biases (“b_z“, “b_r“, “b_o“) are added.
	HasBiasVectors            bool          `protobuf:"varint,20,opt,name=hasBiasVectors,proto3" json:"hasBiasVectors,omitempty"`
	UpdateGateWeightMatrix    *WeightParams `protobuf:"bytes,30,opt,name=updateGateWeightMatrix,proto3" json:"updateGateWeightMatrix,omitempty"`       // Weight Matrix W_z.
	ResetGateWeightMatrix     *WeightParams `protobuf:"bytes,31,opt,name=resetGateWeightMatrix,proto3" json:"resetGateWeightMatrix,omitempty"`         // Weight Matrix W_r.
	OutputGateWeightMatrix    *WeightParams `protobuf:"bytes,32,opt,name=outputGateWeightMatrix,proto3" json:"outputGateWeightMatrix,omitempty"`       // Weight Matrix W_o.
	UpdateGateRecursionMatrix *WeightParams `protobuf:"bytes,50,opt,name=updateGateRecursionMatrix,proto3" json:"updateGateRecursionMatrix,omitempty"` // Recursion Weight Matrix R_z.
	ResetGateRecursionMatrix  *WeightParams `protobuf:"bytes,51,opt,name=resetGateRecursionMatrix,proto3" json:"resetGateRecursionMatrix,omitempty"`   // Recursion Weight Matrix R_r.
	OutputGateRecursionMatrix *WeightParams `protobuf:"bytes,52,opt,name=outputGateRecursionMatrix,proto3" json:"outputGateRecursionMatrix,omitempty"` // Recursion Weight Matrix R_o.
	UpdateGateBiasVector      *WeightParams `protobuf:"bytes,70,opt,name=updateGateBiasVector,proto3" json:"updateGateBiasVector,omitempty"`           // Bias vector b_z.
	ResetGateBiasVector       *WeightParams `protobuf:"bytes,71,opt,name=resetGateBiasVector,proto3" json:"resetGateBiasVector,omitempty"`             // Bias vector b_r.
	OutputGateBiasVector      *WeightParams `protobuf:"bytes,72,opt,name=outputGateBiasVector,proto3" json:"outputGateBiasVector,omitempty"`           // Bias vector b_o.
	// If true, then the node processes the input sequence from right to left
	ReverseInput  bool `protobuf:"varint,100,opt,name=reverseInput,proto3" json:"reverseInput,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GRULayerParams) Reset() {
	*x = GRULayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[82]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GRULayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GRULayerParams) ProtoMessage() {}

func (x *GRULayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[82]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GRULayerParams.ProtoReflect.Descriptor instead.
func (*GRULayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{82}
}

func (x *GRULayerParams) GetInputVectorSize() uint64 {
	if x != nil {
		return x.InputVectorSize
	}
	return 0
}

func (x *GRULayerParams) GetOutputVectorSize() uint64 {
	if x != nil {
		return x.OutputVectorSize
	}
	return 0
}

func (x *GRULayerParams) GetActivations() []*ActivationParams {
	if x != nil {
		return x.Activations
	}
	return nil
}

func (x *GRULayerParams) GetSequenceOutput() bool {
	if x != nil {
		return x.SequenceOutput
	}
	return false
}

func (x *GRULayerParams) GetHasBiasVectors() bool {
	if x != nil {
		return x.HasBiasVectors
	}
	return false
}

func (x *GRULayerParams) GetUpdateGateWeightMatrix() *WeightParams {
	if x != nil {
		return x.UpdateGateWeightMatrix
	}
	return nil
}

func (x *GRULayerParams) GetResetGateWeightMatrix() *WeightParams {
	if x != nil {
		return x.ResetGateWeightMatrix
	}
	return nil
}

func (x *GRULayerParams) GetOutputGateWeightMatrix() *WeightParams {
	if x != nil {
		return x.OutputGateWeightMatrix
	}
	return nil
}

func (x *GRULayerParams) GetUpdateGateRecursionMatrix() *WeightParams {
	if x != nil {
		return x.UpdateGateRecursionMatrix
	}
	return nil
}

func (x *GRULayerParams) GetResetGateRecursionMatrix() *WeightParams {
	if x != nil {
		return x.ResetGateRecursionMatrix
	}
	return nil
}

func (x *GRULayerParams) GetOutputGateRecursionMatrix() *WeightParams {
	if x != nil {
		return x.OutputGateRecursionMatrix
	}
	return nil
}

func (x *GRULayerParams) GetUpdateGateBiasVector() *WeightParams {
	if x != nil {
		return x.UpdateGateBiasVector
	}
	return nil
}

func (x *GRULayerParams) GetResetGateBiasVector() *WeightParams {
	if x != nil {
		return x.ResetGateBiasVector
	}
	return nil
}

func (x *GRULayerParams) GetOutputGateBiasVector() *WeightParams {
	if x != nil {
		return x.OutputGateBiasVector
	}
	return nil
}

func (x *GRULayerParams) GetReverseInput() bool {
	if x != nil {
		return x.ReverseInput
	}
	return false
}

// Long short-term memory (LSTM) parameters.
//
// This is described by the following equations:
//
// Input Gate
//
//	.. math::
//	    \boldsymbol{i_t} = \
//	        f(\mathrm{clip}(W_i \boldsymbol{x_t} + \
//	                        R_i \boldsymbol{y_{t-1}} + \
//	                        p_i \odot c_{t-1} + b_i))
//
// Forget Gate
//
//	.. math::
//	    \boldsymbol{f_t} = \
//	        f(\mathrm{clip}(W_f \boldsymbol{x_t} + \
//	                        R_f \boldsymbol{y_{t-1}} + \
//	                        p_f \odot c_{t-1} + b_f))
//
// Block Input
//
//	.. math::
//	    \boldsymbol{z_t} = \
//	        g(\mathrm{clip}(W_z \boldsymbol{x_t} + \
//	                        R_z \boldsymbol{y_{t-1}} + b_z))
//
// Cell Memory State
//
//	.. math::
//	    \boldsymbol{c_t} = \
//	        \boldsymbol{c_{t-1}} \odot \boldsymbol{f_t} + \
//	        \boldsymbol{i_t} \odot \boldsymbol{z_t}
//
// Output Gate
//
//	.. math::
//	    \boldsymbol{o_t} = \
//	        f(\mathrm{clip}(W_o \boldsymbol{x_t} + \
//	                        R_o \boldsymbol{y_{t-1}} + \
//	                        p_o \odot c_t + b_o))
//
// Output
//
//	.. math::
//	    \boldsymbol{y_t} = \
//	        h(\boldsymbol{c_t}) \odot \boldsymbol{o_t}
//
//   - “W_i“, “W_f“, “W_z“, “W_o“ are 2-dimensional input weight matrices
//     (“[outputVectorSize, inputVectorSize]“, row-major)
//   - “R_i“, “R_f“, “R_z“, “R_o“ are 2-dimensional recursion matrices
//     (“[outputVectorSize, outputVectorSize]“, row-major)
//   - “b_i“, “b_f“, “b_z“, “b_o“ are 1-dimensional bias vectors
//     (“[outputVectorSize]“)
//   - “p_“, “p_f“, “p_o“ are 1-dimensional peephole vectors
//     (“[outputVectorSize]“)
//   - “f()“, “g()“, “h()“ are activations
//   - “clip()“ is a function that constrains values between “[-50.0, 50.0]“
//   - “⊙“ denotes the elementwise product of matrices
type LSTMParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If true, output is a sequence, containing outputs at all time steps.
	// If false, output is just the result after final state update.
	SequenceOutput bool `protobuf:"varint,10,opt,name=sequenceOutput,proto3" json:"sequenceOutput,omitempty"`
	// If false, no biases (“b_i“, “b_f“, “b_z“, “b_o“) are added.
	HasBiasVectors bool `protobuf:"varint,20,opt,name=hasBiasVectors,proto3" json:"hasBiasVectors,omitempty"`
	// If true, a vector of “1“ values is added to “b_f“.
	ForgetBias bool `protobuf:"varint,30,opt,name=forgetBias,proto3" json:"forgetBias,omitempty"`
	// If true, peephole vectors are included.
	HasPeepholeVectors bool `protobuf:"varint,40,opt,name=hasPeepholeVectors,proto3" json:"hasPeepholeVectors,omitempty"`
	// If the coupled Input and Forget flag is on, the behaviour of
	// “c_t“ is changed to the following (i.e. forget gate is not used):
	//
	// .. math::
	//
	//	\boldsymbol{c_t} = \
	//	    \boldsymbol{c_{t-1}} \odot (1 - \boldsymbol{i_t}) + \
	//	    \boldsymbol{i_t} \odot \boldsymbol{z_t}
	CoupledInputAndForgetGate bool `protobuf:"varint,50,opt,name=coupledInputAndForgetGate,proto3" json:"coupledInputAndForgetGate,omitempty"`
	// Places a limit on the maximum and minimum values of “c_t“.
	// c_t = min(c_t, cellClipThreshold)
	// c_t = max(c_t, -cellClipThreshold)
	// If 0, it is set to its default value = 50.0.
	CellClipThreshold float32 `protobuf:"fixed32,60,opt,name=cellClipThreshold,proto3" json:"cellClipThreshold,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *LSTMParams) Reset() {
	*x = LSTMParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[83]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LSTMParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LSTMParams) ProtoMessage() {}

func (x *LSTMParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[83]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LSTMParams.ProtoReflect.Descriptor instead.
func (*LSTMParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{83}
}

func (x *LSTMParams) GetSequenceOutput() bool {
	if x != nil {
		return x.SequenceOutput
	}
	return false
}

func (x *LSTMParams) GetHasBiasVectors() bool {
	if x != nil {
		return x.HasBiasVectors
	}
	return false
}

func (x *LSTMParams) GetForgetBias() bool {
	if x != nil {
		return x.ForgetBias
	}
	return false
}

func (x *LSTMParams) GetHasPeepholeVectors() bool {
	if x != nil {
		return x.HasPeepholeVectors
	}
	return false
}

func (x *LSTMParams) GetCoupledInputAndForgetGate() bool {
	if x != nil {
		return x.CoupledInputAndForgetGate
	}
	return false
}

func (x *LSTMParams) GetCellClipThreshold() float32 {
	if x != nil {
		return x.CellClipThreshold
	}
	return 0
}

// Weights for long short-term memory (LSTM) layers
type LSTMWeightParams struct {
	state                     protoimpl.MessageState `protogen:"open.v1"`
	InputGateWeightMatrix     *WeightParams          `protobuf:"bytes,1,opt,name=inputGateWeightMatrix,proto3" json:"inputGateWeightMatrix,omitempty"`          // Weight Matrix W_i.
	ForgetGateWeightMatrix    *WeightParams          `protobuf:"bytes,2,opt,name=forgetGateWeightMatrix,proto3" json:"forgetGateWeightMatrix,omitempty"`        // Weight Matrix W_f.
	BlockInputWeightMatrix    *WeightParams          `protobuf:"bytes,3,opt,name=blockInputWeightMatrix,proto3" json:"blockInputWeightMatrix,omitempty"`        // Weight Matrix W_z.
	OutputGateWeightMatrix    *WeightParams          `protobuf:"bytes,4,opt,name=outputGateWeightMatrix,proto3" json:"outputGateWeightMatrix,omitempty"`        // Weight Matrix W_o.
	InputGateRecursionMatrix  *WeightParams          `protobuf:"bytes,20,opt,name=inputGateRecursionMatrix,proto3" json:"inputGateRecursionMatrix,omitempty"`   // Recursion Weight Matrix R_i.
	ForgetGateRecursionMatrix *WeightParams          `protobuf:"bytes,21,opt,name=forgetGateRecursionMatrix,proto3" json:"forgetGateRecursionMatrix,omitempty"` // Recursion Weight Matrix R_f.
	BlockInputRecursionMatrix *WeightParams          `protobuf:"bytes,22,opt,name=blockInputRecursionMatrix,proto3" json:"blockInputRecursionMatrix,omitempty"` // Recursion Weight Matrix R_z.
	OutputGateRecursionMatrix *WeightParams          `protobuf:"bytes,23,opt,name=outputGateRecursionMatrix,proto3" json:"outputGateRecursionMatrix,omitempty"` // Recursion Weight Matrix R_o.
	// biases:
	InputGateBiasVector  *WeightParams `protobuf:"bytes,40,opt,name=inputGateBiasVector,proto3" json:"inputGateBiasVector,omitempty"`   // Bias vector b_i.
	ForgetGateBiasVector *WeightParams `protobuf:"bytes,41,opt,name=forgetGateBiasVector,proto3" json:"forgetGateBiasVector,omitempty"` // Bias vector b_f.
	BlockInputBiasVector *WeightParams `protobuf:"bytes,42,opt,name=blockInputBiasVector,proto3" json:"blockInputBiasVector,omitempty"` // Bias vector b_z.
	OutputGateBiasVector *WeightParams `protobuf:"bytes,43,opt,name=outputGateBiasVector,proto3" json:"outputGateBiasVector,omitempty"` // Bias vector b_o.
	// peepholes:
	InputGatePeepholeVector  *WeightParams `protobuf:"bytes,60,opt,name=inputGatePeepholeVector,proto3" json:"inputGatePeepholeVector,omitempty"`   // Peephole vector p_i.
	ForgetGatePeepholeVector *WeightParams `protobuf:"bytes,61,opt,name=forgetGatePeepholeVector,proto3" json:"forgetGatePeepholeVector,omitempty"` // Peephole vector p_f.
	OutputGatePeepholeVector *WeightParams `protobuf:"bytes,62,opt,name=outputGatePeepholeVector,proto3" json:"outputGatePeepholeVector,omitempty"` // Peephole vector p_o.
	unknownFields            protoimpl.UnknownFields
	sizeCache                protoimpl.SizeCache
}

func (x *LSTMWeightParams) Reset() {
	*x = LSTMWeightParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[84]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LSTMWeightParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LSTMWeightParams) ProtoMessage() {}

func (x *LSTMWeightParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[84]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LSTMWeightParams.ProtoReflect.Descriptor instead.
func (*LSTMWeightParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{84}
}

func (x *LSTMWeightParams) GetInputGateWeightMatrix() *WeightParams {
	if x != nil {
		return x.InputGateWeightMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetForgetGateWeightMatrix() *WeightParams {
	if x != nil {
		return x.ForgetGateWeightMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetBlockInputWeightMatrix() *WeightParams {
	if x != nil {
		return x.BlockInputWeightMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetOutputGateWeightMatrix() *WeightParams {
	if x != nil {
		return x.OutputGateWeightMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetInputGateRecursionMatrix() *WeightParams {
	if x != nil {
		return x.InputGateRecursionMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetForgetGateRecursionMatrix() *WeightParams {
	if x != nil {
		return x.ForgetGateRecursionMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetBlockInputRecursionMatrix() *WeightParams {
	if x != nil {
		return x.BlockInputRecursionMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetOutputGateRecursionMatrix() *WeightParams {
	if x != nil {
		return x.OutputGateRecursionMatrix
	}
	return nil
}

func (x *LSTMWeightParams) GetInputGateBiasVector() *WeightParams {
	if x != nil {
		return x.InputGateBiasVector
	}
	return nil
}

func (x *LSTMWeightParams) GetForgetGateBiasVector() *WeightParams {
	if x != nil {
		return x.ForgetGateBiasVector
	}
	return nil
}

func (x *LSTMWeightParams) GetBlockInputBiasVector() *WeightParams {
	if x != nil {
		return x.BlockInputBiasVector
	}
	return nil
}

func (x *LSTMWeightParams) GetOutputGateBiasVector() *WeightParams {
	if x != nil {
		return x.OutputGateBiasVector
	}
	return nil
}

func (x *LSTMWeightParams) GetInputGatePeepholeVector() *WeightParams {
	if x != nil {
		return x.InputGatePeepholeVector
	}
	return nil
}

func (x *LSTMWeightParams) GetForgetGatePeepholeVector() *WeightParams {
	if x != nil {
		return x.ForgetGatePeepholeVector
	}
	return nil
}

func (x *LSTMWeightParams) GetOutputGatePeepholeVector() *WeightParams {
	if x != nil {
		return x.OutputGatePeepholeVector
	}
	return nil
}

// A unidirectional long short-term memory (LSTM) layer.
//
// .. code::
//
//	(y_t, c_t) = UniDirectionalLSTMLayer(x_t, y_{t-1}, c_{t-1})
//
// Input
//
//	A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
//	This represents a sequence of vectors of size ``inputVectorSize``.
//
// Output
//
//	Same rank as the input.
//	Represents a vector of size ``outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
//
// - Output Shape: “[1, Batch, outputVectorSize, 1, 1]“ , if “sequenceOutput == false“
// - Output Shape: “[Seq, Batch, outputVectorSize, 1, 1]“ , if “sequenceOutput == true“
type UniDirectionalLSTMLayerParams struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	InputVectorSize  uint64                 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`   // Size of the input vectors.
	OutputVectorSize uint64                 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"` // Size of the output vectors.
	// 3 element array representing activations [f(),g(),h()] in that order.
	// Typical values used = [sigmoid, tanh, tanh].
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	Activations  []*ActivationParams `protobuf:"bytes,10,rep,name=activations,proto3" json:"activations,omitempty"`
	Params       *LSTMParams         `protobuf:"bytes,15,opt,name=params,proto3" json:"params,omitempty"`
	WeightParams *LSTMWeightParams   `protobuf:"bytes,20,opt,name=weightParams,proto3" json:"weightParams,omitempty"` // Weights, biases and peepholes.
	// If true, then the node processes the input sequence from right to left
	ReverseInput  bool `protobuf:"varint,100,opt,name=reverseInput,proto3" json:"reverseInput,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UniDirectionalLSTMLayerParams) Reset() {
	*x = UniDirectionalLSTMLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[85]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UniDirectionalLSTMLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UniDirectionalLSTMLayerParams) ProtoMessage() {}

func (x *UniDirectionalLSTMLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[85]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UniDirectionalLSTMLayerParams.ProtoReflect.Descriptor instead.
func (*UniDirectionalLSTMLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{85}
}

func (x *UniDirectionalLSTMLayerParams) GetInputVectorSize() uint64 {
	if x != nil {
		return x.InputVectorSize
	}
	return 0
}

func (x *UniDirectionalLSTMLayerParams) GetOutputVectorSize() uint64 {
	if x != nil {
		return x.OutputVectorSize
	}
	return 0
}

func (x *UniDirectionalLSTMLayerParams) GetActivations() []*ActivationParams {
	if x != nil {
		return x.Activations
	}
	return nil
}

func (x *UniDirectionalLSTMLayerParams) GetParams() *LSTMParams {
	if x != nil {
		return x.Params
	}
	return nil
}

func (x *UniDirectionalLSTMLayerParams) GetWeightParams() *LSTMWeightParams {
	if x != nil {
		return x.WeightParams
	}
	return nil
}

func (x *UniDirectionalLSTMLayerParams) GetReverseInput() bool {
	if x != nil {
		return x.ReverseInput
	}
	return false
}

// Bidirectional long short-term memory (LSTM) layer
//
// .. code::
//
//	(y_t, c_t, y_t_reverse, c_t_reverse) = BiDirectionalLSTMLayer(x_t, y_{t-1}, c_{t-1}, y_{t-1}_reverse, c_{t-1}_reverse)
//
// Input
//
//	A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
//	This represents a sequence of vectors of size ``inputVectorSize``.
//
// Output
//
//	Same rank as the input.
//	Represents a vector of size ``2 * outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
//
// - Output Shape: “[1, Batch, 2 * outputVectorSize, 1, 1]“ , if “sequenceOutput == false“
// - Output Shape: “[Seq, Batch, 2 * outputVectorSize, 1, 1]“ , if “sequenceOutput == true“
//
// The first LSTM operates on the input sequence in the forward direction.
// The second LSTM operates on the input sequence in the reverse direction.
//
// Example: given the input sequence “[x_1, x_2, x_3]“,
// where “x_i“ are vectors at time index “i“:
//
// The forward LSTM output is “[yf_1, yf_2, yf_3]“,
//
// where “yf_i“ are vectors of size “outputVectorSize“:
//
// - “yf_1“ is the output at the end of sequence {“x_1“}
// - “yf_2“ is the output at the end of sequence {“x_1“, “x_2“}
// - “yf_3“ is the output at the end of sequence {“x_1“, “x_2“, “x_3“}
//
// The backward LSTM output: “[yb_1, yb_2, yb_3]“,
//
// where “yb_i“ are vectors of size “outputVectorSize“:
//
// - “yb_1“ is the output at the end of sequence {“x_3“}
// - “yb_2“ is the output at the end of sequence {“x_3“, “x_2“}
// - “yb_3“ is the output at the end of sequence {“x_3“, “x_2“, “x_1“}
//
// Output of the bi-dir layer:
//
// - if “sequenceOutput = True“ : { “[yf_1, yb_3]“,  “[yf_2, yb_2]“,  “[yf_3, yb_1]“ }
// - if “sequenceOutput = False“ : { “[yf_3, yb_3]“ }
type BiDirectionalLSTMLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Size of the input vectors.
	InputVectorSize uint64 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`
	// Size of the outputs vectors.
	// It is same for both forward and backward LSTMs.
	OutputVectorSize uint64 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"`
	// 3 element array representing activations [f(),g(),h()] in that order.
	// Typical values used = [sigmoid, tanh, tanh].
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	ActivationsForwardLSTM []*ActivationParams `protobuf:"bytes,10,rep,name=activationsForwardLSTM,proto3" json:"activationsForwardLSTM,omitempty"`
	// Currently, backward LSTM activations
	// must be same as the ones for the forward LSTM.
	ActivationsBackwardLSTM []*ActivationParams `protobuf:"bytes,11,rep,name=activationsBackwardLSTM,proto3" json:"activationsBackwardLSTM,omitempty"`
	// Common parameters shared by the forward and backward LSTMs.
	Params *LSTMParams `protobuf:"bytes,15,opt,name=params,proto3" json:"params,omitempty"`
	// Weights and biases.
	// Must be a length 2 message,
	// for the forward and backward LSTM respectively.
	WeightParams  []*LSTMWeightParams `protobuf:"bytes,20,rep,name=weightParams,proto3" json:"weightParams,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BiDirectionalLSTMLayerParams) Reset() {
	*x = BiDirectionalLSTMLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[86]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BiDirectionalLSTMLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BiDirectionalLSTMLayerParams) ProtoMessage() {}

func (x *BiDirectionalLSTMLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[86]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BiDirectionalLSTMLayerParams.ProtoReflect.Descriptor instead.
func (*BiDirectionalLSTMLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{86}
}

func (x *BiDirectionalLSTMLayerParams) GetInputVectorSize() uint64 {
	if x != nil {
		return x.InputVectorSize
	}
	return 0
}

func (x *BiDirectionalLSTMLayerParams) GetOutputVectorSize() uint64 {
	if x != nil {
		return x.OutputVectorSize
	}
	return 0
}

func (x *BiDirectionalLSTMLayerParams) GetActivationsForwardLSTM() []*ActivationParams {
	if x != nil {
		return x.ActivationsForwardLSTM
	}
	return nil
}

func (x *BiDirectionalLSTMLayerParams) GetActivationsBackwardLSTM() []*ActivationParams {
	if x != nil {
		return x.ActivationsBackwardLSTM
	}
	return nil
}

func (x *BiDirectionalLSTMLayerParams) GetParams() *LSTMParams {
	if x != nil {
		return x.Params
	}
	return nil
}

func (x *BiDirectionalLSTMLayerParams) GetWeightParams() []*LSTMWeightParams {
	if x != nil {
		return x.WeightParams
	}
	return nil
}

type CustomLayerParams struct {
	state         protoimpl.MessageState                              `protogen:"open.v1"`
	ClassName     string                                              `protobuf:"bytes,10,opt,name=className,proto3" json:"className,omitempty"`                                                                             // The name of the class (conforming to MLCustomLayer) corresponding to this layer
	Weights       []*WeightParams                                     `protobuf:"bytes,20,rep,name=weights,proto3" json:"weights,omitempty"`                                                                                 // Any weights -- these are serialized in binary format and memmapped at runtime
	Parameters    map[string]*CustomLayerParams_CustomLayerParamValue `protobuf:"bytes,30,rep,name=parameters,proto3" json:"parameters,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // these may be handled as strings, so this should not be large
	Description   string                                              `protobuf:"bytes,40,opt,name=description,proto3" json:"description,omitempty"`                                                                         // An (optional) description of the layer provided by the model creator. This information is displayed when viewing the model, but does not affect the model's execution on device.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CustomLayerParams) Reset() {
	*x = CustomLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[87]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CustomLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CustomLayerParams) ProtoMessage() {}

func (x *CustomLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[87]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CustomLayerParams.ProtoReflect.Descriptor instead.
func (*CustomLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{87}
}

func (x *CustomLayerParams) GetClassName() string {
	if x != nil {
		return x.ClassName
	}
	return ""
}

func (x *CustomLayerParams) GetWeights() []*WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *CustomLayerParams) GetParameters() map[string]*CustomLayerParams_CustomLayerParamValue {
	if x != nil {
		return x.Parameters
	}
	return nil
}

func (x *CustomLayerParams) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

type TransposeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Length of "axes" should match the rank of input & output tensor
	// "axes" should be a permutation of "[0,1,2,...,N-1]" where N is the rank.
	Axes          []uint64 `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"` //
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TransposeLayerParams) Reset() {
	*x = TransposeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[88]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TransposeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TransposeLayerParams) ProtoMessage() {}

func (x *TransposeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[88]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TransposeLayerParams.ProtoReflect.Descriptor instead.
func (*TransposeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{88}
}

func (x *TransposeLayerParams) GetAxes() []uint64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

// A layer that computes the matrix multiplication of two tensors with numpy-like broadcasting
// where the matrices reside in the last two indices of the tensor.
//
// .. code::
//
//	y = BatchedMatMul(a,b)
//
// Requires 1 or 2 inputs and produces 1 output.
//
// The first tensor, "a", must be provided as an input. The second tensor can either be an input or provided as a weight matrix parameter.
//
// Input
//   - a: First N-Dimensional tensor
//   - b: Second N-Dimensional tensor (either a rank-N input or a matrix, i.e. N=2, provided as a layer parameter)
//
// Output
//
//	A tensor containing the matrix product of two tensors.
//	When there are two inputs: rank is max(2, rank(a), rank(b))
//	When there is one input: rank is same as that of the input.
//
// This operation behaves as following:
//
//	When there are two inputs:
//	    - If N >= 2 for both tensors, it is treated as a batch of matrices residing in the last two indices.
//	      All the indices, except for the last two, are broadcasted using conventional rules.
//	    - If the first tensor is 1-D, it is converted to a 2-D tensor by prepending a 1 to its shape. Eg. (D) -> (1,D)
//	    - If the second tensor is 1-D, it is converted to a 2-D tensor by appending a 1 to its shape. Eg. (D) -> (D,1)
//
//	When there is one input:
//	    - The weight matrix corresponds to a matrix, of shape (X1, X2). Values of X1, X2 must be provided as layer parameters.
//	    - The input, "a", is reshaped into a matrix by combining all the leading dimensions, except the last, into a batch dimension. eg:
//	           - if "a" is rank 1 (X1,) -->  (1, X1). Output shape will be (X2,)
//	           - if "a" is rank 2 (B1, X1) --> no need to reshape. Output shape will be (B1, X2)
//	           - if "a" is rank 3 (B1, B2, X1) --> (B1 * B2, X1). Output shape will be (B1, B2, X2)
//	           - etc
type BatchedMatMulLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If transposeA is true, it transposes the left matrix on the fly before matrix multiplication.
	// (is ignored when there is one input)
	TransposeA bool `protobuf:"varint,1,opt,name=transposeA,proto3" json:"transposeA,omitempty"`
	// If transposeB is true, it transposes the right matrix on the fly before matrix multiplication.
	// (is ignored when there is one input)
	TransposeB                  bool   `protobuf:"varint,2,opt,name=transposeB,proto3" json:"transposeB,omitempty"`
	WeightMatrixFirstDimension  uint64 `protobuf:"varint,5,opt,name=weightMatrixFirstDimension,proto3" json:"weightMatrixFirstDimension,omitempty"`   // X1: same as the last dimension of the input tensor
	WeightMatrixSecondDimension uint64 `protobuf:"varint,6,opt,name=weightMatrixSecondDimension,proto3" json:"weightMatrixSecondDimension,omitempty"` // X2: same as the last dimension of the output tensor
	HasBias                     bool   `protobuf:"varint,7,opt,name=hasBias,proto3" json:"hasBias,omitempty"`                                         // Whether a bias is added or not. Supported only when there is one input.
	// Weight matrix representing shape [X1, X2].
	// Values are however stored in column major order,
	// in the "repeated float" or "bytes" fields of the message "WeightParams"
	Weights *WeightParams `protobuf:"bytes,8,opt,name=weights,proto3" json:"weights,omitempty"`
	Bias    *WeightParams `protobuf:"bytes,9,opt,name=bias,proto3" json:"bias,omitempty"` // Bias vector [X2]. Supported only when there is one input.
	// If set, this layer, at runtime, quantizes the floating point input blob to int8 before applying the
	// matrix multiplication using the INT8 weight parameters provided in weights->int8RawValue. The
	// result is then dequantized.
	// Requires:
	// * number of inputs to be 1
	// * hasBias == false
	// * QuantizationType == LinearQuantizationParams, such that
	//   - size of the "scale" field is 1 and "bias" field is empty in "LinearQuantizationParams"
	//
	// * numberOfBits == 8
	// * weights->rawValue_size to be empty
	Int8DynamicQuantize bool `protobuf:"varint,10,opt,name=int8DynamicQuantize,proto3" json:"int8DynamicQuantize,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *BatchedMatMulLayerParams) Reset() {
	*x = BatchedMatMulLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[89]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchedMatMulLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchedMatMulLayerParams) ProtoMessage() {}

func (x *BatchedMatMulLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[89]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchedMatMulLayerParams.ProtoReflect.Descriptor instead.
func (*BatchedMatMulLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{89}
}

func (x *BatchedMatMulLayerParams) GetTransposeA() bool {
	if x != nil {
		return x.TransposeA
	}
	return false
}

func (x *BatchedMatMulLayerParams) GetTransposeB() bool {
	if x != nil {
		return x.TransposeB
	}
	return false
}

func (x *BatchedMatMulLayerParams) GetWeightMatrixFirstDimension() uint64 {
	if x != nil {
		return x.WeightMatrixFirstDimension
	}
	return 0
}

func (x *BatchedMatMulLayerParams) GetWeightMatrixSecondDimension() uint64 {
	if x != nil {
		return x.WeightMatrixSecondDimension
	}
	return 0
}

func (x *BatchedMatMulLayerParams) GetHasBias() bool {
	if x != nil {
		return x.HasBias
	}
	return false
}

func (x *BatchedMatMulLayerParams) GetWeights() *WeightParams {
	if x != nil {
		return x.Weights
	}
	return nil
}

func (x *BatchedMatMulLayerParams) GetBias() *WeightParams {
	if x != nil {
		return x.Bias
	}
	return nil
}

func (x *BatchedMatMulLayerParams) GetInt8DynamicQuantize() bool {
	if x != nil {
		return x.Int8DynamicQuantize
	}
	return false
}

// A layer that concatenates a list of tensors along a specified axis.
//
// .. code::
//
//	y = ConcatNDLayer(x1,x2,....)
//
// Requires at least 2 input and produces 1 output.
//
// Input
//
//	The rank of the input tensors must match and all dimensions also must match, except for the dimension 'axis'.
//
// Output
//
//	Same rank as the input. The dimension along "axis", is the sum of the dimensions of the inputs.
//
// example:
//
// in1 : shape (3, 2), value = [[1, 2], [3, 4], [5, 6]]
// in2 : shape (3, 2), value = [[7, 8], [9, 10], [11, 12]]
// axis = 0
//
// if interleave = False (default)
// output : shape (6, 2)
// output[0:3, :] = in1
// output[3:6, :] = in2
// value = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]]
//
// if interleave = True
// output : shape (6, 2)
// output[0::2, :] = in1
// output[1::2, :] = in2
// value = [[1, 2], [7, 8], [3, 4], [9, 10], [5, 6], [11, 12]]
type ConcatNDLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Dimension along which to concatenate. Supports negative values of the parameter 'axis'.
	Axis int64 `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	// (Only available in Core ML Specification >= 5 (iOS >= 14, macOS >= 11.0)
	// Interleave option. If True, concatenation is done via interleaving the inputs.
	// This requires all inputs to have the exact same shape.
	Interleave    bool `protobuf:"varint,2,opt,name=interleave,proto3" json:"interleave,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConcatNDLayerParams) Reset() {
	*x = ConcatNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[90]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConcatNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConcatNDLayerParams) ProtoMessage() {}

func (x *ConcatNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[90]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConcatNDLayerParams.ProtoReflect.Descriptor instead.
func (*ConcatNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{90}
}

func (x *ConcatNDLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *ConcatNDLayerParams) GetInterleave() bool {
	if x != nil {
		return x.Interleave
	}
	return false
}

// A layer that performs softmax normalization along a specified axis.
//
// .. code::
//
//	y = SoftmaxNDLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Output shape is same as the input.
type SoftmaxNDLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Dimension on which the softmax would be performed. Supports negative values of the parameter 'axis'.
	Axis          int64 `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SoftmaxNDLayerParams) Reset() {
	*x = SoftmaxNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[91]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SoftmaxNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SoftmaxNDLayerParams) ProtoMessage() {}

func (x *SoftmaxNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[91]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SoftmaxNDLayerParams.ProtoReflect.Descriptor instead.
func (*SoftmaxNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{91}
}

func (x *SoftmaxNDLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

// A layer that reverses specific dimensions of the input tensor.
// It is similar in functionality to the numpy.flip method.
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type ReverseLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Reverses each dimension of the input tensor for which corresponding reverseDim is set to True.
	// Requires len(reverseDim) == rank(inputTensor)
	ReverseDim    []bool `protobuf:"varint,1,rep,packed,name=reverseDim,proto3" json:"reverseDim,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReverseLayerParams) Reset() {
	*x = ReverseLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[92]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReverseLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReverseLayerParams) ProtoMessage() {}

func (x *ReverseLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[92]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReverseLayerParams.ProtoReflect.Descriptor instead.
func (*ReverseLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{92}
}

func (x *ReverseLayerParams) GetReverseDim() []bool {
	if x != nil {
		return x.ReverseDim
	}
	return nil
}

// A layer that reverses variable length slices.
//
// Requires 2 inputs and produces 1 output.
//
// 2 inputs, in order are denoted by "data", "seq_lengths".
// "seq_lenghts" must be a rank 1 tensor, i.e. seq_lengths.shape = (B,)
// which contains the lengths of the amount of sequence to be reversed, for each element of the batch.
// Dimension "batchAxis" in "data" must be equal to B, i.e,
// data.shape[batchAxis] = B.
//
// According to the batch axis, input "data" is first divided into a batch of B inputs,
// each of which is flipped along the dimension "sequenceAxis", by the amount specified in
// "seq_lengths", the second input.
//
// e.g.:
//
// data [shape = (2,4)]:
// [0 1 2 3]
// [4 5 6 7]
// seq_lengths [shape = (2,)]:
// [3, 0]
// batchAxis = 0
// sequenceAxis = 1
//
// output [shape = (2,4)]:
// [2 1 0 3]
// [4 5 6 7]
//
// data [shape = (2,3,2)]:
// [0 1]
// [2 3]
// [4 5] (slice = 0)
// [6 7]
// [8 9]
// [10 11] (slice = 1)
// seq_lengths [shape = (2,)]:
// [2, 3]
// batchAxis = 0
// sequenceAxis = 1
//
// output [shape = (2,3,2)]:
// [2 3]
// [0 1]
// [4 5] (slice = 0)
// [10 11]
// [8 9]
// [6 7] (slice = 1)
//
// Output shape is same as the input.
type ReverseSeqLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	BatchAxis     int64                  `protobuf:"varint,1,opt,name=batchAxis,proto3" json:"batchAxis,omitempty"` // batch axis has to be strictly less than seq_axis
	SequenceAxis  int64                  `protobuf:"varint,2,opt,name=sequenceAxis,proto3" json:"sequenceAxis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReverseSeqLayerParams) Reset() {
	*x = ReverseSeqLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[93]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReverseSeqLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReverseSeqLayerParams) ProtoMessage() {}

func (x *ReverseSeqLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[93]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReverseSeqLayerParams.ProtoReflect.Descriptor instead.
func (*ReverseSeqLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{93}
}

func (x *ReverseSeqLayerParams) GetBatchAxis() int64 {
	if x != nil {
		return x.BatchAxis
	}
	return 0
}

func (x *ReverseSeqLayerParams) GetSequenceAxis() int64 {
	if x != nil {
		return x.SequenceAxis
	}
	return 0
}

// A layer that loads data as a parameter and provides it as an output.
//
// .. code::
//
//	y = LoadConstantNDLayer()
//
// Requires no input and produces 1 output.
//
// Output: A tensor with shape as provided in the parameter "shape"
type LoadConstantNDLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The shape of the constant to be loaded.
	Shape         []uint64      `protobuf:"varint,1,rep,packed,name=shape,proto3" json:"shape,omitempty"`
	Data          *WeightParams `protobuf:"bytes,2,opt,name=data,proto3" json:"data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoadConstantNDLayerParams) Reset() {
	*x = LoadConstantNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[94]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoadConstantNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoadConstantNDLayerParams) ProtoMessage() {}

func (x *LoadConstantNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[94]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoadConstantNDLayerParams.ProtoReflect.Descriptor instead.
func (*LoadConstantNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{94}
}

func (x *LoadConstantNDLayerParams) GetShape() []uint64 {
	if x != nil {
		return x.Shape
	}
	return nil
}

func (x *LoadConstantNDLayerParams) GetData() *WeightParams {
	if x != nil {
		return x.Data
	}
	return nil
}

// A layer that generates an output tensor with a constant value.
// Input is only used to determine the shape of the output.
// This layer is used to allocate a tensor with a dynamic shape (that of the input) and constant value.
//
// Requires 1 input and produces 1 output.
//
// .. code::
//
//	y = FillLikeLayer(x)
//
// Input
//
//	A N-Dimensional tensor, whose values are ignored. Only the shape is used to
//	infer the shape of the output.
//
// Output
//
//	A N-Dimensional tensor with the same shape as the input tensor.
type FillLikeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Value         float32                `protobuf:"fixed32,1,opt,name=value,proto3" json:"value,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FillLikeLayerParams) Reset() {
	*x = FillLikeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[95]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FillLikeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FillLikeLayerParams) ProtoMessage() {}

func (x *FillLikeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[95]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FillLikeLayerParams.ProtoReflect.Descriptor instead.
func (*FillLikeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{95}
}

func (x *FillLikeLayerParams) GetValue() float32 {
	if x != nil {
		return x.Value
	}
	return 0
}

// A layer that generates an output tensor with a constant value.
// This layer is used to allocate a tensor with a static shape and constant value.
//
// Requires no input and produces 1 output.
//
// .. code::
//
//	y = FillStaticLayer(x)
//
// Output
//
//	A N-Dimensional tensor of shape "targetShape".
type FillStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Value         float32                `protobuf:"fixed32,1,opt,name=value,proto3" json:"value,omitempty"`
	TargetShape   []uint64               `protobuf:"varint,2,rep,packed,name=targetShape,proto3" json:"targetShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FillStaticLayerParams) Reset() {
	*x = FillStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[96]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FillStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FillStaticLayerParams) ProtoMessage() {}

func (x *FillStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[96]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FillStaticLayerParams.ProtoReflect.Descriptor instead.
func (*FillStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{96}
}

func (x *FillStaticLayerParams) GetValue() float32 {
	if x != nil {
		return x.Value
	}
	return 0
}

func (x *FillStaticLayerParams) GetTargetShape() []uint64 {
	if x != nil {
		return x.TargetShape
	}
	return nil
}

// A layer that generates an output tensor with a constant value.
// This layer is used to allocate a tensor with a dynamic shape (as specified by the input) and constant value.
//
// Requires 1 input and produces 1 output.
//
// .. code::
//
//	y = FillDynamicLayer(x)
//
// Input
//
//	A rank 1 tensor specifying the shape of the output
//
// Output
//
//	An N-Dimensional tensor with the shape specified by the values in the input tensor.
type FillDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Value         float32                `protobuf:"fixed32,1,opt,name=value,proto3" json:"value,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FillDynamicLayerParams) Reset() {
	*x = FillDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[97]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FillDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FillDynamicLayerParams) ProtoMessage() {}

func (x *FillDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[97]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FillDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*FillDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{97}
}

func (x *FillDynamicLayerParams) GetValue() float32 {
	if x != nil {
		return x.Value
	}
	return 0
}

// A layer that returns the elements either from tensor x or tensor y,
// depending on the value in the condition tensor.
// It is similar in functionality to the numpy.where method with 3 inputs.
//
// Requires 3 inputs and produces 1 output.
// Inputs, in order, are the condition tensor, x and y.
//
// for each vector index (i,...,j):
//
//	output[i,...,j] = x[i,...,j] if condition[i,...,j] = True
//	                  y[i,...,j] if condition[i,...,j] = False
//
// All the 3 inputs are first broadcasted to a common shape.
// (the shapes must be broadcastable)
//
// output.rank = max(input[0].rank, input[1].rank, input[2].rank)
type WhereBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WhereBroadcastableLayerParams) Reset() {
	*x = WhereBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[98]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WhereBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WhereBroadcastableLayerParams) ProtoMessage() {}

func (x *WhereBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[98]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WhereBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*WhereBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{98}
}

// A layer that computes elementwise trigonometric sine function.
//
// .. code::
//
//	y = SinLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type SinLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SinLayerParams) Reset() {
	*x = SinLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[99]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SinLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SinLayerParams) ProtoMessage() {}

func (x *SinLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[99]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SinLayerParams.ProtoReflect.Descriptor instead.
func (*SinLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{99}
}

// A layer that computes elementwise trigonometric cosine function.
//
// .. code::
//
//	y = CosLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type CosLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CosLayerParams) Reset() {
	*x = CosLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[100]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CosLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CosLayerParams) ProtoMessage() {}

func (x *CosLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[100]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CosLayerParams.ProtoReflect.Descriptor instead.
func (*CosLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{100}
}

// A layer that computes elementwise trigonometric tangent function.
//
// .. code::
//
//	y = TanLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type TanLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TanLayerParams) Reset() {
	*x = TanLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[101]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TanLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TanLayerParams) ProtoMessage() {}

func (x *TanLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[101]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TanLayerParams.ProtoReflect.Descriptor instead.
func (*TanLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{101}
}

// A layer that computes elementwise trigonometric arcsine function.
//
// .. code::
//
//	y = AsinLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type AsinLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AsinLayerParams) Reset() {
	*x = AsinLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[102]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AsinLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AsinLayerParams) ProtoMessage() {}

func (x *AsinLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[102]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AsinLayerParams.ProtoReflect.Descriptor instead.
func (*AsinLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{102}
}

// A layer that computes elementwise trigonometric arccosine function.
//
// .. code::
//
//	y = AcosLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type AcosLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AcosLayerParams) Reset() {
	*x = AcosLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[103]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AcosLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AcosLayerParams) ProtoMessage() {}

func (x *AcosLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[103]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AcosLayerParams.ProtoReflect.Descriptor instead.
func (*AcosLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{103}
}

// A layer that computes elementwise trigonometric arctangent function.
//
// .. code::
//
//	y = AtanLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type AtanLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AtanLayerParams) Reset() {
	*x = AtanLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[104]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AtanLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AtanLayerParams) ProtoMessage() {}

func (x *AtanLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[104]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AtanLayerParams.ProtoReflect.Descriptor instead.
func (*AtanLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{104}
}

// A layer that computes elementwise trigonometric hyperbolic sine function.
//
// .. code::
//
//	y = SinhLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type SinhLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SinhLayerParams) Reset() {
	*x = SinhLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[105]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SinhLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SinhLayerParams) ProtoMessage() {}

func (x *SinhLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[105]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SinhLayerParams.ProtoReflect.Descriptor instead.
func (*SinhLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{105}
}

// A layer that computes elementwise trigonometric hyperbolic cosine function.
//
// .. code::
//
//	y = CoshLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type CoshLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CoshLayerParams) Reset() {
	*x = CoshLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[106]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CoshLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CoshLayerParams) ProtoMessage() {}

func (x *CoshLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[106]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CoshLayerParams.ProtoReflect.Descriptor instead.
func (*CoshLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{106}
}

// A layer that computes elementwise trigonometric hyperbolic tangent function.
//
// .. code::
//
//	y = TanhLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type TanhLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TanhLayerParams) Reset() {
	*x = TanhLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[107]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TanhLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TanhLayerParams) ProtoMessage() {}

func (x *TanhLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[107]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TanhLayerParams.ProtoReflect.Descriptor instead.
func (*TanhLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{107}
}

// A layer that computes elementwise trigonometric hyperbolic arcsine function.
//
// .. code::
//
//	y = AsinhLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type AsinhLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AsinhLayerParams) Reset() {
	*x = AsinhLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[108]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AsinhLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AsinhLayerParams) ProtoMessage() {}

func (x *AsinhLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[108]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AsinhLayerParams.ProtoReflect.Descriptor instead.
func (*AsinhLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{108}
}

// A layer that computes elementwise trigonometric hyperbolic arccosine function.
//
// .. code::
//
//	y = AcoshLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type AcoshLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AcoshLayerParams) Reset() {
	*x = AcoshLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[109]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AcoshLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AcoshLayerParams) ProtoMessage() {}

func (x *AcoshLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[109]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AcoshLayerParams.ProtoReflect.Descriptor instead.
func (*AcoshLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{109}
}

// A layer that computes elementwise trigonometric hyperbolic arctangent function.
//
// .. code::
//
//	y = AtanhLayer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type AtanhLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AtanhLayerParams) Reset() {
	*x = AtanhLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[110]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AtanhLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AtanhLayerParams) ProtoMessage() {}

func (x *AtanhLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[110]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AtanhLayerParams.ProtoReflect.Descriptor instead.
func (*AtanhLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{110}
}

// A layer that raises each element in first tensor to the power of
// corresponding element in the second tensor.
// Supports conventional numpy-like broadcasting.
//
// .. code::
//
//	y = PowBroadcastableLayer(x)
//
// Requires 2 inputs and produces 1 output.
//
// Input
//   - First N-Dimensional tensor
//   - Second N-Dimensional tensor
//
// Output
//
//	An N-Dimensional tensor with the broadcast shape.
type PowBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PowBroadcastableLayerParams) Reset() {
	*x = PowBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[111]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PowBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PowBroadcastableLayerParams) ProtoMessage() {}

func (x *PowBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[111]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PowBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*PowBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{111}
}

// A layer that computes the exponential of all elements in the input tensor, with the base 2.
//
// .. code::
//
//	y = Exp2Layer(x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type Exp2LayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Exp2LayerParams) Reset() {
	*x = Exp2LayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[112]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Exp2LayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Exp2LayerParams) ProtoMessage() {}

func (x *Exp2LayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[112]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Exp2LayerParams.ProtoReflect.Descriptor instead.
func (*Exp2LayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{112}
}

// A layer that returns a tensor containing the indices of all non-zero
// elements of input tensor.
// It is similar in functionality to the numpy.where method with 1 input.
//
// Requires 1 input and produces 1 output.
// Output is of rank 2, of shape (N,R),
// where N is the number of non-zero elements in the input and R is the rank of the input.
//
// # Output contains indices represented in the multi-index form
//
// e.g.:
// input {shape = (4,)}:
// [0 1 0 2]
// output {shape = (2,1)}:
// [1]
// [3]
//
// input {shape = (3, 3)}:
// [1 2 1]
// [0 2 2]
// [2 1 0]
// output {shape = (7,1)}:
// [0. 0.]
// [0. 1.]
// [0. 2.]
// [1. 1.]
// [1. 2.]
// [2. 0.]
// [2. 1.]
type WhereNonZeroLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WhereNonZeroLayerParams) Reset() {
	*x = WhereNonZeroLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[113]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WhereNonZeroLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WhereNonZeroLayerParams) ProtoMessage() {}

func (x *WhereNonZeroLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[113]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WhereNonZeroLayerParams.ProtoReflect.Descriptor instead.
func (*WhereNonZeroLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{113}
}

// A layer that copies a tensor setting everything outside a central band in
// each inner-most matrix to zero.
//
// Requires 1 input and produces 1 output.
//
// Parameters for matrix_band_part layer
// band(m, n) = (num_lower < 0 || (m-n) <= num_lower) && (num_upper < 0 || (n-m) <= num_upper).
// output[i, j, k, ..., m, n] = band(m, n) * input[i, j, k, ..., m, n]
//
// Output shape is same as the input shape.
// Rank of the input must be at least 2.
// For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.
type MatrixBandPartLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	NumLower      int64                  `protobuf:"varint,1,opt,name=numLower,proto3" json:"numLower,omitempty"`
	NumUpper      int64                  `protobuf:"varint,2,opt,name=numUpper,proto3" json:"numUpper,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MatrixBandPartLayerParams) Reset() {
	*x = MatrixBandPartLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[114]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MatrixBandPartLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MatrixBandPartLayerParams) ProtoMessage() {}

func (x *MatrixBandPartLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[114]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MatrixBandPartLayerParams.ProtoReflect.Descriptor instead.
func (*MatrixBandPartLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{114}
}

func (x *MatrixBandPartLayerParams) GetNumLower() int64 {
	if x != nil {
		return x.NumLower
	}
	return 0
}

func (x *MatrixBandPartLayerParams) GetNumUpper() int64 {
	if x != nil {
		return x.NumUpper
	}
	return 0
}

// A layer that copies a tensor setting everything outside upper triangular to zero.
//
// Requires 1 input and produces 1 output.
//
// Output shape is same as the input shape.
// Rank of the input must be at least 2.
// For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.
type UpperTriangularLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	K             int64                  `protobuf:"varint,1,opt,name=k,proto3" json:"k,omitempty"` // Diagonal below which to zero elements. k = 0 (the default) is the main diagonal, k < 0 is below it and k > 0 is above
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpperTriangularLayerParams) Reset() {
	*x = UpperTriangularLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[115]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpperTriangularLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpperTriangularLayerParams) ProtoMessage() {}

func (x *UpperTriangularLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[115]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpperTriangularLayerParams.ProtoReflect.Descriptor instead.
func (*UpperTriangularLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{115}
}

func (x *UpperTriangularLayerParams) GetK() int64 {
	if x != nil {
		return x.K
	}
	return 0
}

// A layer that copies a tensor setting everything outside lower triangular to zero.
//
// Requires 1 input and produces 1 output.
//
// Output shape is same as the input shape.
// Rank of the input must be at least 2.
// For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.
type LowerTriangularLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	K             int64                  `protobuf:"varint,1,opt,name=k,proto3" json:"k,omitempty"` // Diagonal above which to zero elements. k = 0 (the default) is the main diagonal, k < 0 is below it and k > 0 is above
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LowerTriangularLayerParams) Reset() {
	*x = LowerTriangularLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[116]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LowerTriangularLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LowerTriangularLayerParams) ProtoMessage() {}

func (x *LowerTriangularLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[116]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LowerTriangularLayerParams.ProtoReflect.Descriptor instead.
func (*LowerTriangularLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{116}
}

func (x *LowerTriangularLayerParams) GetK() int64 {
	if x != nil {
		return x.K
	}
	return 0
}

// A layer that broadcasts a tensor to a new shape.
//
// Requires 2 inputs and produces 1 output.
//
// First input is broadcast to produce the output, while the second input is only
// used to determine the shape of the output. Values of second input are not used.
//
// Output is a tensor with the same shape as the second input.
type BroadcastToLikeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BroadcastToLikeLayerParams) Reset() {
	*x = BroadcastToLikeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[117]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BroadcastToLikeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BroadcastToLikeLayerParams) ProtoMessage() {}

func (x *BroadcastToLikeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[117]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BroadcastToLikeLayerParams.ProtoReflect.Descriptor instead.
func (*BroadcastToLikeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{117}
}

// A layer that broadcasts a tensor to a new shape.
//
// Requires 1 input and produces 1 output.
//
// Output tensor is the broadcasted version of the input and has shape as specified in the
// parameter "targetShape".
type BroadcastToStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TargetShape   []uint64               `protobuf:"varint,1,rep,packed,name=targetShape,proto3" json:"targetShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BroadcastToStaticLayerParams) Reset() {
	*x = BroadcastToStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[118]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BroadcastToStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BroadcastToStaticLayerParams) ProtoMessage() {}

func (x *BroadcastToStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[118]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BroadcastToStaticLayerParams.ProtoReflect.Descriptor instead.
func (*BroadcastToStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{118}
}

func (x *BroadcastToStaticLayerParams) GetTargetShape() []uint64 {
	if x != nil {
		return x.TargetShape
	}
	return nil
}

// A layer that broadcasts a tensor to a new shape.
//
// Requires 2 inputs and produces 1 output.
//
// First input is the one that is broadcasted to produce the output.
// Second input is a rank 1 tensor specifying the shape of the output.
// Output tensor has shape as specified by the values in the 2nd input tensor.
type BroadcastToDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BroadcastToDynamicLayerParams) Reset() {
	*x = BroadcastToDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[119]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BroadcastToDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BroadcastToDynamicLayerParams) ProtoMessage() {}

func (x *BroadcastToDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[119]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BroadcastToDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*BroadcastToDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{119}
}

// A layer that performs element-wise addition operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type AddBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AddBroadcastableLayerParams) Reset() {
	*x = AddBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[120]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AddBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AddBroadcastableLayerParams) ProtoMessage() {}

func (x *AddBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[120]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AddBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*AddBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{120}
}

// A layer that performs element-wise maximum operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type MaxBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MaxBroadcastableLayerParams) Reset() {
	*x = MaxBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[121]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MaxBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MaxBroadcastableLayerParams) ProtoMessage() {}

func (x *MaxBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[121]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MaxBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*MaxBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{121}
}

// A layer that performs element-wise minimum operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type MinBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MinBroadcastableLayerParams) Reset() {
	*x = MinBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[122]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MinBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MinBroadcastableLayerParams) ProtoMessage() {}

func (x *MinBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[122]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MinBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*MinBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{122}
}

// A layer that performs element-wise modular operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type ModBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModBroadcastableLayerParams) Reset() {
	*x = ModBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[123]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModBroadcastableLayerParams) ProtoMessage() {}

func (x *ModBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[123]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*ModBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{123}
}

// A layer that performs element-wise floor division operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type FloorDivBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FloorDivBroadcastableLayerParams) Reset() {
	*x = FloorDivBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[124]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FloorDivBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FloorDivBroadcastableLayerParams) ProtoMessage() {}

func (x *FloorDivBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[124]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FloorDivBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*FloorDivBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{124}
}

// A layer that performs element-wise subtract operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type SubtractBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SubtractBroadcastableLayerParams) Reset() {
	*x = SubtractBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[125]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SubtractBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SubtractBroadcastableLayerParams) ProtoMessage() {}

func (x *SubtractBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[125]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SubtractBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*SubtractBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{125}
}

// A layer that performs element-wise multiply operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type MultiplyBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MultiplyBroadcastableLayerParams) Reset() {
	*x = MultiplyBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[126]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MultiplyBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MultiplyBroadcastableLayerParams) ProtoMessage() {}

func (x *MultiplyBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[126]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MultiplyBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*MultiplyBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{126}
}

// A layer that performs element-wise division operation with broadcast support.
//
// Requires 2 inputs and produces 1 output.
type DivideBroadcastableLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DivideBroadcastableLayerParams) Reset() {
	*x = DivideBroadcastableLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[127]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DivideBroadcastableLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DivideBroadcastableLayerParams) ProtoMessage() {}

func (x *DivideBroadcastableLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[127]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DivideBroadcastableLayerParams.ProtoReflect.Descriptor instead.
func (*DivideBroadcastableLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{127}
}

// Gather layer that gathers elements from the first input, along a specified axis,
// at indices specified in the second input.
// It is similar in functionality to the numpy.take method.
//
// Requires 2 inputs and produces 1 output.
//
// Given two inputs, 'data' and 'indices', gather the slices of 'data'
// and store into output.
// e.g.
// for i in [0, length(indices) - 1]
//
//	output[i] = data[indices[i]]  (1-D case, axis=0)
//
// if axis = 0:
// for each vector index (i,...,j)
//
//	output[i,...,j,:,..,:] = data[indices[i,...,j],:,..,:]
//
// output.rank = (data.rank - 1) + indices.rank
//
// Negative indices and negative axis are supported.
//
// e.g:
//
// data shape = (2, 3)
// indices shape = (6, 8)
// axis = 0
// output shape = (6, 8) + (3,) = (6, 8, 3)
//
// data shape = (2, 3, 5)
// indices shape = (6, 8)
// axis = 1
// output shape = (2,) + (6, 8) + (5,) =  (2, 6, 8, 5)
type GatherLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GatherLayerParams) Reset() {
	*x = GatherLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[128]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GatherLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GatherLayerParams) ProtoMessage() {}

func (x *GatherLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[128]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GatherLayerParams.ProtoReflect.Descriptor instead.
func (*GatherLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{128}
}

func (x *GatherLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

type ScatterLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	Mode          ScatterMode            `protobuf:"varint,2,opt,name=mode,proto3,enum=CoreML.Specification.ScatterMode" json:"mode,omitempty"` // mode of accumulation.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ScatterLayerParams) Reset() {
	*x = ScatterLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[129]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScatterLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScatterLayerParams) ProtoMessage() {}

func (x *ScatterLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[129]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ScatterLayerParams.ProtoReflect.Descriptor instead.
func (*ScatterLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{129}
}

func (x *ScatterLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *ScatterLayerParams) GetMode() ScatterMode {
	if x != nil {
		return x.Mode
	}
	return ScatterMode_SCATTER_UPDATE
}

// A layer that gathers elements from the first input, 'params', at the multi-indices specified
// by the second input, 'indices'.
//
// Requires 2 inputs and produces 1 output.
//
// 'params' = input[0], 'indices' = input[1]
//
// 'indices' is a rank K+1 tensor of shape [I_0, I_1, .., I_(K-1), I_K] which is viewed as a collection of
// indices of (I_0 * I_1 * ... * I_(K-1)) points in the I_K dimensional space. For instance, the multi-index of the first point
// is indices[0,0,...,0,:].
//
// Here is how the output is constructed:
//
// for i = 0,1,...,(I_0-1)
//
//	...
//	  for j = 0,1,....,(I_(K-1)-1)
//	       output[i,....,j,:,:,..,:] = params[indices[i,...,j,:], :,:,..,:]
//
// Hence, output shape is [I_0, I_1,...,I(K-1)] + params.shape[I_K:]
//
// output.rank = indices.rank - 1 + params.rank - indices.shape[-1]
//
// e.g:
//
// input[0] shape = (4, 2, 3, 4)
// input[1] shape = (6, 2)
// output shape = (6,) + (3, 4) = (6, 3, 4)
//
// input[0] shape = (3, 3, 3, 4, 7)
// input[1] shape = (3, 5)
// output shape = (3,) + () = (3,)
//
// input[0] shape = (5, 3, 2, 5)
// input[1] shape = (2, 7, 3, 2)
// output shape = (2, 7, 3) + (2, 5) = (2, 7, 3, 2, 5)
type GatherNDLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GatherNDLayerParams) Reset() {
	*x = GatherNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[130]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GatherNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GatherNDLayerParams) ProtoMessage() {}

func (x *GatherNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[130]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GatherNDLayerParams.ProtoReflect.Descriptor instead.
func (*GatherNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{130}
}

// A layer that scatters data into a new tensor according to multi-indices from the input.
// This is the inverse operation of GatherND.
//
// Requires 3 inputs and produces 1 output.
// 3 inputs, in order are denoted as "container", "indices", "updates".
//
// 'indices' is a rank K+1 tensor of shape [I_0, I_1, .., I_(K-1), I_K] which is viewed as a collection of
// indices of (I_0 * I_1 * ... * I_(K-1)) points in the I_K dimensional space. For instance, the multi-index of the first point
// is indices[0,0,...,0,:].
//
// container.rank >= I_K
// updates.rank = K + (container.rank - I_K)
// shape of 'updates' = [I_0, I_1,...,I(K-1)] + container.shape[I_K:]
//
// output = container
// For each vector index (i,...,j) s.t. 0<=i<I_0,..., 0<=j<I_K
//
//	output[indices[i,...,j,:], :,:,..,:] = updates[i,....,j,:,:,..,:] // if mode == "SCATTER_UPDATE"
//
// The output has the same shape as the first input.
//
// e.g:
//
// container shape = (3, 2)
// indices shape = (4, 2)
// updates shape = (4,)
// output shape = (3, 2)
//
// container shape = (7, 6)
// indices shape = (4, 7, 2, 5, 1)
// updates shape = (4, 7, 2, 5, 6)
// output shape = (7, 6)
type ScatterNDLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Mode          ScatterMode            `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.Specification.ScatterMode" json:"mode,omitempty"` // mode of accumulation.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ScatterNDLayerParams) Reset() {
	*x = ScatterNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[131]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScatterNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScatterNDLayerParams) ProtoMessage() {}

func (x *ScatterNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[131]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ScatterNDLayerParams.ProtoReflect.Descriptor instead.
func (*ScatterNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{131}
}

func (x *ScatterNDLayerParams) GetMode() ScatterMode {
	if x != nil {
		return x.Mode
	}
	return ScatterMode_SCATTER_UPDATE
}

// Gather layer that gathers elements from the first input, along a specified axis,
// at indices specified in the second input.
// It is similar in functionality to the numpy.take_along_axis method.
//
// Requires 2 inputs and produces 1 output.
//
// Given two inputs, 'data' and 'indices', gather the slices of 'data'
// and store into output.
//
// Both inputs and output have the same rank.
// Output shape is same as the shape of 'indices'
// Shapes of 'indices' and 'data' match, except at the 'axis' dimension.
//
// This operation performs the following operation for axis=0:
// for each vector index (i,j,....,k)
//
//	output[i,j,....,k] = data[index[i,j,....,k],j,....,k]
//
// Negative indices and negative axis are supported.
//
// e.g:
//
// data shape = (4, 4, 7)
// indices shape = (4, 5, 7)
// axis = 1
// output shape = (4, 5, 7)
type GatherAlongAxisLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GatherAlongAxisLayerParams) Reset() {
	*x = GatherAlongAxisLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[132]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GatherAlongAxisLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GatherAlongAxisLayerParams) ProtoMessage() {}

func (x *GatherAlongAxisLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[132]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GatherAlongAxisLayerParams.ProtoReflect.Descriptor instead.
func (*GatherAlongAxisLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{132}
}

func (x *GatherAlongAxisLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

// A layer that scatters data into a new tensor according to indices from
// the input along the given axis into the output tensor.
// This is the inverse operation of GatherAlongAxis.
// It is similar in functionality to the numpy.put_along_axis method.
//
// Requires 3 inputs and produces 1 output.
// 3 inputs, in order are denoted as "container", "indices", "updates".
//
// All inputs and output have the same rank.
// Output shape is same as the shape of 'container'
// Shapes of 'indices' and 'updates' match, which is same as the shape of 'container' except at the 'axis' dimension.
//
// Negative indices and negative axis are supported.
//
// This operation performs the following operation for axis=0:
// output = container
// for each vector index (i,j,....,k)
//
//	output[index[i,j,....,k],j,....,k] = updates[i,j,....,k]
//
// e.g.:
//
// container shape = (2, 5, 6)
// indices shape = (2, 2, 6)
// updates shape = (2, 2, 6)
// axis = -2
// output shape = (2, 5, 6)
type ScatterAlongAxisLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	Mode          ScatterMode            `protobuf:"varint,2,opt,name=mode,proto3,enum=CoreML.Specification.ScatterMode" json:"mode,omitempty"` // mode of accumulation.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ScatterAlongAxisLayerParams) Reset() {
	*x = ScatterAlongAxisLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[133]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScatterAlongAxisLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScatterAlongAxisLayerParams) ProtoMessage() {}

func (x *ScatterAlongAxisLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[133]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ScatterAlongAxisLayerParams.ProtoReflect.Descriptor instead.
func (*ScatterAlongAxisLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{133}
}

func (x *ScatterAlongAxisLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *ScatterAlongAxisLayerParams) GetMode() ScatterMode {
	if x != nil {
		return x.Mode
	}
	return ScatterMode_SCATTER_UPDATE
}

// A layer that stacks the input tensors along the given axis.
// It is similar in functionality to the numpy.stack method.
//
// Requires at least 2 inputs and produces 1 output.
// All inputs must have the same shape.
// Rank of the output is 1 greater than the rank of the inputs.
//
// Negative indexing is supported for the "axis" parameter.
//
// e.g.:
//
// input shape = (2, 4, 2)
// number of inputs = 5
// axis = 3
// output shape = (2, 4, 2, 5)
//
// input shape = (2, 4, 2)
// number of inputs = 5
// axis = -2
// output shape = (2, 4, 5, 2)
type StackLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StackLayerParams) Reset() {
	*x = StackLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[134]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StackLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StackLayerParams) ProtoMessage() {}

func (x *StackLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[134]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StackLayerParams.ProtoReflect.Descriptor instead.
func (*StackLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{134}
}

func (x *StackLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

// A layer that reshapes a tensor that does not alter the rank of the input.
// Order of the data is left unchanged.
//
// Requires 1 input and produces 1 output.
//
// e.g:
//
// input shape = (20,10)
// targetShape = (5,-1)
// output shape = (5,40)
//
// input shape = (20,10,5)
// targetShape = (0,2,25)
// output shape = (20,2,25)
//
// input shape = (10,3,5)
// targetShape = (25,0,-1)
// output shape = (25,3,2)
type RankPreservingReshapeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Length of this field must be same as the input/output rank.
	// It can have 0's, in which case the corresponding input dimension is kept intact.
	// At most one element can be -1, in which case the output dimension is calculated from rest of the shape.
	TargetShape   []int64 `protobuf:"varint,1,rep,packed,name=targetShape,proto3" json:"targetShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RankPreservingReshapeLayerParams) Reset() {
	*x = RankPreservingReshapeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[135]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RankPreservingReshapeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RankPreservingReshapeLayerParams) ProtoMessage() {}

func (x *RankPreservingReshapeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[135]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RankPreservingReshapeLayerParams.ProtoReflect.Descriptor instead.
func (*RankPreservingReshapeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{135}
}

func (x *RankPreservingReshapeLayerParams) GetTargetShape() []int64 {
	if x != nil {
		return x.TargetShape
	}
	return nil
}

// Constant padding layer.
// Pad the input array with a constant value, either along a single given axis or along a set of axes.
//
// Requires 1 or 2 inputs and produces 1 output.
// The amount of padding can be either set as a parameter ("padAmounts") or provided as a second input.
//
// Output rank is same as the rank of the first input.
//
// when "padToGivenOutputSizeMode" is False:
//
// output_shape[i] = input_shape[i] + padAmounts[2*i] + padAmounts[2*i+1], i=0,...,rank-1
//
// Examples:
//
// input shape = (20,10)
// padAmounts = [0,1,4,0]
// output shape = (21,14)
//
// input shape = (20,10,5)
// padAmounts = [0,0,3,4,0,9]
// output shape = (20,17,14)
//
// when "padToGivenOutputSizeMode" is True
//
// output_shape[i] = max(input_shape[i], max(padAmounts[2*i] + padAmounts[2*i+1])), i=0,...,rank-1
//
// input shape = (20,10)
// padAmounts = [0,21,14,0]
// output shape = (21,14)
//
// input shape = (20,10,5)
// padAmounts = [0,0,17,0,0,14]
// output shape = (20,17,14)
type ConstantPaddingLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The value to be used for padding.
	Value float32 `protobuf:"fixed32,1,opt,name=value,proto3" json:"value,omitempty"`
	// Length of this repeated field must be twice the rank of the first input.
	// 2*i-th and (2*i+1)-th values represent the amount of padding to be applied to the the i-th input
	// dimension, "before" and "after" the input values, respectively.
	PadAmounts []uint64 `protobuf:"varint,2,rep,packed,name=padAmounts,proto3" json:"padAmounts,omitempty"`
	// When this is True, positive values in "padAmounts" are equivalent to the output shape.
	// In that case only one of padAmounts[2*i] and padAmounts[2*i+1] can be non zero, for i=0,..,rank-1.
	PadToGivenOutputSizeMode bool `protobuf:"varint,3,opt,name=padToGivenOutputSizeMode,proto3" json:"padToGivenOutputSizeMode,omitempty"`
	unknownFields            protoimpl.UnknownFields
	sizeCache                protoimpl.SizeCache
}

func (x *ConstantPaddingLayerParams) Reset() {
	*x = ConstantPaddingLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[136]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConstantPaddingLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConstantPaddingLayerParams) ProtoMessage() {}

func (x *ConstantPaddingLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[136]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConstantPaddingLayerParams.ProtoReflect.Descriptor instead.
func (*ConstantPaddingLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{136}
}

func (x *ConstantPaddingLayerParams) GetValue() float32 {
	if x != nil {
		return x.Value
	}
	return 0
}

func (x *ConstantPaddingLayerParams) GetPadAmounts() []uint64 {
	if x != nil {
		return x.PadAmounts
	}
	return nil
}

func (x *ConstantPaddingLayerParams) GetPadToGivenOutputSizeMode() bool {
	if x != nil {
		return x.PadToGivenOutputSizeMode
	}
	return false
}

// A layer that returns a tensor filled with values from the normal distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameters
//
//	seed: seed used for the normal distribution.
//	mean: mean of the normal distribution.
//	stdDev: standard deviation of the normal distribution.
//
// Input
//
//	An N-Dimensional tensor, whose values are ignored. Only the shape is used to
//	infer the shape of the output.
//
// Output
//
//	An N-Dimensional tensor with the same shape as the input tensor.
type RandomNormalLikeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	Mean          float32                `protobuf:"fixed32,2,opt,name=mean,proto3" json:"mean,omitempty"`
	StdDev        float32                `protobuf:"fixed32,3,opt,name=stdDev,proto3" json:"stdDev,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomNormalLikeLayerParams) Reset() {
	*x = RandomNormalLikeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[137]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomNormalLikeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomNormalLikeLayerParams) ProtoMessage() {}

func (x *RandomNormalLikeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[137]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomNormalLikeLayerParams.ProtoReflect.Descriptor instead.
func (*RandomNormalLikeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{137}
}

func (x *RandomNormalLikeLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomNormalLikeLayerParams) GetMean() float32 {
	if x != nil {
		return x.Mean
	}
	return 0
}

func (x *RandomNormalLikeLayerParams) GetStdDev() float32 {
	if x != nil {
		return x.StdDev
	}
	return 0
}

// A layer that returns a tensor filled with values from the normal distribution.
//
// Requires no input and produces 1 output.
//
// Parameters
//
//	seed: seed used for the normal distribution.
//	mean: mean of the normal distribution.
//	stdDev: standard deviation of the normal distribution.
//	outputShape: shape of the output tensor.
//
// Output
//
//	An N-Dimensional tensor of shape "outputShape".
type RandomNormalStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	Mean          float32                `protobuf:"fixed32,2,opt,name=mean,proto3" json:"mean,omitempty"`
	StdDev        float32                `protobuf:"fixed32,3,opt,name=stdDev,proto3" json:"stdDev,omitempty"`
	OutputShape   []uint64               `protobuf:"varint,4,rep,packed,name=outputShape,proto3" json:"outputShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomNormalStaticLayerParams) Reset() {
	*x = RandomNormalStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[138]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomNormalStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomNormalStaticLayerParams) ProtoMessage() {}

func (x *RandomNormalStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[138]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomNormalStaticLayerParams.ProtoReflect.Descriptor instead.
func (*RandomNormalStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{138}
}

func (x *RandomNormalStaticLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomNormalStaticLayerParams) GetMean() float32 {
	if x != nil {
		return x.Mean
	}
	return 0
}

func (x *RandomNormalStaticLayerParams) GetStdDev() float32 {
	if x != nil {
		return x.StdDev
	}
	return 0
}

func (x *RandomNormalStaticLayerParams) GetOutputShape() []uint64 {
	if x != nil {
		return x.OutputShape
	}
	return nil
}

// A layer that returns a tensor filled with values from the normal distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	seed: seed used for the normal distribution.
//	mean: mean of the normal distribution.
//	stdDev: standard deviation of the normal distribution.
//
// Input
//
//	A rank 1 tensor specifying the shape of the output
//
// Output
//
//	An N-Dimensional tensor with the shape specified by the values in the input tensor.
type RandomNormalDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	Mean          float32                `protobuf:"fixed32,2,opt,name=mean,proto3" json:"mean,omitempty"`
	StdDev        float32                `protobuf:"fixed32,3,opt,name=stdDev,proto3" json:"stdDev,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomNormalDynamicLayerParams) Reset() {
	*x = RandomNormalDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[139]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomNormalDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomNormalDynamicLayerParams) ProtoMessage() {}

func (x *RandomNormalDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[139]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomNormalDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*RandomNormalDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{139}
}

func (x *RandomNormalDynamicLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomNormalDynamicLayerParams) GetMean() float32 {
	if x != nil {
		return x.Mean
	}
	return 0
}

func (x *RandomNormalDynamicLayerParams) GetStdDev() float32 {
	if x != nil {
		return x.StdDev
	}
	return 0
}

// A layer that returns a tensor filled with values from the uniform distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameters
//
//	seed: seed used for the uniform distribution.
//	minVal: lower bound on the range of random values for the uniform distribution.
//	maxVal: upper bound on the range of random values for the uniform distribution.
//
// Input
//
//	An N-Dimensional tensor, whose values are ignored. Only the shape is used to
//	infer the shape of the output.
//
// Output
//
//	An N-Dimensional tensor with the same shape as the input tensor.
type RandomUniformLikeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	MinVal        float32                `protobuf:"fixed32,2,opt,name=minVal,proto3" json:"minVal,omitempty"`
	MaxVal        float32                `protobuf:"fixed32,3,opt,name=maxVal,proto3" json:"maxVal,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomUniformLikeLayerParams) Reset() {
	*x = RandomUniformLikeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[140]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomUniformLikeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomUniformLikeLayerParams) ProtoMessage() {}

func (x *RandomUniformLikeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[140]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomUniformLikeLayerParams.ProtoReflect.Descriptor instead.
func (*RandomUniformLikeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{140}
}

func (x *RandomUniformLikeLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomUniformLikeLayerParams) GetMinVal() float32 {
	if x != nil {
		return x.MinVal
	}
	return 0
}

func (x *RandomUniformLikeLayerParams) GetMaxVal() float32 {
	if x != nil {
		return x.MaxVal
	}
	return 0
}

// A layer that returns a tensor filled with values from the uniform distribution.
//
// Requires no input and produces 1 output.
//
// Parameters
//
//	seed: seed used for the uniform distribution.
//	minVal: lower bound on the range of random values for the uniform distribution.
//	maxVal: upper bound on the range of random values for the uniform distribution.
//	outputShape: shape of the output tensor.
//
// Output
//
//	An N-Dimensional tensor of shape "outputShape".
type RandomUniformStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	MinVal        float32                `protobuf:"fixed32,2,opt,name=minVal,proto3" json:"minVal,omitempty"`
	MaxVal        float32                `protobuf:"fixed32,3,opt,name=maxVal,proto3" json:"maxVal,omitempty"`
	OutputShape   []uint64               `protobuf:"varint,4,rep,packed,name=outputShape,proto3" json:"outputShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomUniformStaticLayerParams) Reset() {
	*x = RandomUniformStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[141]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomUniformStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomUniformStaticLayerParams) ProtoMessage() {}

func (x *RandomUniformStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[141]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomUniformStaticLayerParams.ProtoReflect.Descriptor instead.
func (*RandomUniformStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{141}
}

func (x *RandomUniformStaticLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomUniformStaticLayerParams) GetMinVal() float32 {
	if x != nil {
		return x.MinVal
	}
	return 0
}

func (x *RandomUniformStaticLayerParams) GetMaxVal() float32 {
	if x != nil {
		return x.MaxVal
	}
	return 0
}

func (x *RandomUniformStaticLayerParams) GetOutputShape() []uint64 {
	if x != nil {
		return x.OutputShape
	}
	return nil
}

// A layer that returns a tensor filled with values from the uniform distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	seed: seed used for the uniform distribution.
//	minVal: lower bound on the range of random values for the uniform distribution.
//	maxVal: upper bound on the range of random values for the uniform distribution.
//
// Input
//
//	A rank 1 tensor specifying the shape of the output
//
// Output
//
//	An N-Dimensional tensor with the shape specified by the values in the input tensor.
type RandomUniformDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	MinVal        float32                `protobuf:"fixed32,2,opt,name=minVal,proto3" json:"minVal,omitempty"`
	MaxVal        float32                `protobuf:"fixed32,3,opt,name=maxVal,proto3" json:"maxVal,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomUniformDynamicLayerParams) Reset() {
	*x = RandomUniformDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[142]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomUniformDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomUniformDynamicLayerParams) ProtoMessage() {}

func (x *RandomUniformDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[142]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomUniformDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*RandomUniformDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{142}
}

func (x *RandomUniformDynamicLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomUniformDynamicLayerParams) GetMinVal() float32 {
	if x != nil {
		return x.MinVal
	}
	return 0
}

func (x *RandomUniformDynamicLayerParams) GetMaxVal() float32 {
	if x != nil {
		return x.MaxVal
	}
	return 0
}

// A layer that returns a tensor filled with values from the Bernoulli distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameters
//
//	seed: seed used for the Bernoulli distribution.
//	prob: probability of a 1 event.
//
// Input
//
//	An N-Dimensional tensor, whose values are ignored. Only the shape is used to
//	infer the shape of the output.
//
// Output
//
//	An N-Dimensional tensor with the same shape as the input tensor.
type RandomBernoulliLikeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	Prob          float32                `protobuf:"fixed32,2,opt,name=prob,proto3" json:"prob,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomBernoulliLikeLayerParams) Reset() {
	*x = RandomBernoulliLikeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[143]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomBernoulliLikeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomBernoulliLikeLayerParams) ProtoMessage() {}

func (x *RandomBernoulliLikeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[143]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomBernoulliLikeLayerParams.ProtoReflect.Descriptor instead.
func (*RandomBernoulliLikeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{143}
}

func (x *RandomBernoulliLikeLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomBernoulliLikeLayerParams) GetProb() float32 {
	if x != nil {
		return x.Prob
	}
	return 0
}

// A layer that returns a tensor filled with values from the Bernoulli distribution.
//
// Requires no input and produces 1 output.
//
// Parameters
//
//	seed: seed used for the Bernoulli distribution.
//	prob: probability of a 1 event.
//	outputShape: shape of the output tensor.
//
// Output
//
//	An N-Dimensional tensor of shape "outputShape".
type RandomBernoulliStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	Prob          float32                `protobuf:"fixed32,2,opt,name=prob,proto3" json:"prob,omitempty"`
	OutputShape   []uint64               `protobuf:"varint,3,rep,packed,name=outputShape,proto3" json:"outputShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomBernoulliStaticLayerParams) Reset() {
	*x = RandomBernoulliStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[144]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomBernoulliStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomBernoulliStaticLayerParams) ProtoMessage() {}

func (x *RandomBernoulliStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[144]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomBernoulliStaticLayerParams.ProtoReflect.Descriptor instead.
func (*RandomBernoulliStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{144}
}

func (x *RandomBernoulliStaticLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomBernoulliStaticLayerParams) GetProb() float32 {
	if x != nil {
		return x.Prob
	}
	return 0
}

func (x *RandomBernoulliStaticLayerParams) GetOutputShape() []uint64 {
	if x != nil {
		return x.OutputShape
	}
	return nil
}

// A layer that returns a tensor filled with values from the Bernoulli distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	seed: seed used for the Bernoulli distribution.
//	prob: probability of a 1 event.
//
// Input
//
//	A rank 1 tensor specifying the shape of the output
//
// Output
//
//	An N-Dimensional tensor with the shape specified by the values in the input tensor.
type RandomBernoulliDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	Prob          float32                `protobuf:"fixed32,2,opt,name=prob,proto3" json:"prob,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RandomBernoulliDynamicLayerParams) Reset() {
	*x = RandomBernoulliDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[145]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RandomBernoulliDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RandomBernoulliDynamicLayerParams) ProtoMessage() {}

func (x *RandomBernoulliDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[145]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RandomBernoulliDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*RandomBernoulliDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{145}
}

func (x *RandomBernoulliDynamicLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *RandomBernoulliDynamicLayerParams) GetProb() float32 {
	if x != nil {
		return x.Prob
	}
	return 0
}

// A layer that returns a tensor of the specified shape filled with values from the categorical distribution.
//
// Requires 1 input and produces 1 output.
//
// Parameter:
//
//	seed: seed used for the categorical distribution.
//	numSamples: number of samples to draw.
//	isLogits: true if the inputs are logits, false if the inputs are probabilities.
//	eps: default value is 1e-10.
//	temperature: default value is 1.0.
//
// Input tensor shape = [D_1, D_2, ... , D_(R-1), D_R] (Rank = R)
// Then the shape of the output is [D_1, D_2, ... , D_(R-1), numSamples] (Rank = R)
type CategoricalDistributionLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Seed          int64                  `protobuf:"varint,1,opt,name=seed,proto3" json:"seed,omitempty"`
	NumSamples    int64                  `protobuf:"varint,2,opt,name=numSamples,proto3" json:"numSamples,omitempty"`
	IsLogits      bool                   `protobuf:"varint,3,opt,name=isLogits,proto3" json:"isLogits,omitempty"`
	Eps           float32                `protobuf:"fixed32,4,opt,name=eps,proto3" json:"eps,omitempty"`
	Temperature   float32                `protobuf:"fixed32,5,opt,name=temperature,proto3" json:"temperature,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CategoricalDistributionLayerParams) Reset() {
	*x = CategoricalDistributionLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[146]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CategoricalDistributionLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CategoricalDistributionLayerParams) ProtoMessage() {}

func (x *CategoricalDistributionLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[146]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CategoricalDistributionLayerParams.ProtoReflect.Descriptor instead.
func (*CategoricalDistributionLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{146}
}

func (x *CategoricalDistributionLayerParams) GetSeed() int64 {
	if x != nil {
		return x.Seed
	}
	return 0
}

func (x *CategoricalDistributionLayerParams) GetNumSamples() int64 {
	if x != nil {
		return x.NumSamples
	}
	return 0
}

func (x *CategoricalDistributionLayerParams) GetIsLogits() bool {
	if x != nil {
		return x.IsLogits
	}
	return false
}

func (x *CategoricalDistributionLayerParams) GetEps() float32 {
	if x != nil {
		return x.Eps
	}
	return 0
}

func (x *CategoricalDistributionLayerParams) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

// A layer that performs reduction with L1 normalization operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceL1LayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceL1LayerParams) Reset() {
	*x = ReduceL1LayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[147]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceL1LayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceL1LayerParams) ProtoMessage() {}

func (x *ReduceL1LayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[147]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceL1LayerParams.ProtoReflect.Descriptor instead.
func (*ReduceL1LayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{147}
}

func (x *ReduceL1LayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceL1LayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceL1LayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with L2 normalization operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceL2LayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceL2LayerParams) Reset() {
	*x = ReduceL2LayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[148]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceL2LayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceL2LayerParams) ProtoMessage() {}

func (x *ReduceL2LayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[148]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceL2LayerParams.ProtoReflect.Descriptor instead.
func (*ReduceL2LayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{148}
}

func (x *ReduceL2LayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceL2LayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceL2LayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with max operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceMaxLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceMaxLayerParams) Reset() {
	*x = ReduceMaxLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[149]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceMaxLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceMaxLayerParams) ProtoMessage() {}

func (x *ReduceMaxLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[149]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceMaxLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceMaxLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{149}
}

func (x *ReduceMaxLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceMaxLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceMaxLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with min operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceMinLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceMinLayerParams) Reset() {
	*x = ReduceMinLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[150]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceMinLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceMinLayerParams) ProtoMessage() {}

func (x *ReduceMinLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[150]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceMinLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceMinLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{150}
}

func (x *ReduceMinLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceMinLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceMinLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with sum operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceSumLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceSumLayerParams) Reset() {
	*x = ReduceSumLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[151]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceSumLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceSumLayerParams) ProtoMessage() {}

func (x *ReduceSumLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[151]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceSumLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceSumLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{151}
}

func (x *ReduceSumLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceSumLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceSumLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with prod operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceProdLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceProdLayerParams) Reset() {
	*x = ReduceProdLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[152]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceProdLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceProdLayerParams) ProtoMessage() {}

func (x *ReduceProdLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[152]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceProdLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceProdLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{152}
}

func (x *ReduceProdLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceProdLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceProdLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with mean operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceMeanLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceMeanLayerParams) Reset() {
	*x = ReduceMeanLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[153]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceMeanLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceMeanLayerParams) ProtoMessage() {}

func (x *ReduceMeanLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[153]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceMeanLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceMeanLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{153}
}

func (x *ReduceMeanLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceMeanLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceMeanLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with logSum operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceLogSumLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceLogSumLayerParams) Reset() {
	*x = ReduceLogSumLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[154]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceLogSumLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceLogSumLayerParams) ProtoMessage() {}

func (x *ReduceLogSumLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[154]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceLogSumLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceLogSumLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{154}
}

func (x *ReduceLogSumLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceLogSumLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceLogSumLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with logSumExp operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceSumSquareLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceSumSquareLayerParams) Reset() {
	*x = ReduceSumSquareLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[155]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceSumSquareLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceSumSquareLayerParams) ProtoMessage() {}

func (x *ReduceSumSquareLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[155]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceSumSquareLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceSumSquareLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{155}
}

func (x *ReduceSumSquareLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceSumSquareLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceSumSquareLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that performs reduction with logSumExp operation.
//
// Negative indexing is supported.
// Requires 1 input and produces 1 output.
//
// Parameters:
//
//	axes: dimensions along which to perform reduction
//	keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
//	reduceAll: ignore the "axes" parameter, perform reduction along all axes
type ReduceLogSumExpLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axes          []int64                `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	KeepDims      bool                   `protobuf:"varint,2,opt,name=keepDims,proto3" json:"keepDims,omitempty"`
	ReduceAll     bool                   `protobuf:"varint,3,opt,name=reduceAll,proto3" json:"reduceAll,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReduceLogSumExpLayerParams) Reset() {
	*x = ReduceLogSumExpLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[156]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReduceLogSumExpLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReduceLogSumExpLayerParams) ProtoMessage() {}

func (x *ReduceLogSumExpLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[156]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReduceLogSumExpLayerParams.ProtoReflect.Descriptor instead.
func (*ReduceLogSumExpLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{156}
}

func (x *ReduceLogSumExpLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *ReduceLogSumExpLayerParams) GetKeepDims() bool {
	if x != nil {
		return x.KeepDims
	}
	return false
}

func (x *ReduceLogSumExpLayerParams) GetReduceAll() bool {
	if x != nil {
		return x.ReduceAll
	}
	return false
}

// A layer that increases the rank of the input tensor by adding unit dimensions.
//
// Requires 1 input and produces 1 output.
//
// e.g.:
//
// input shape = (10,5)
// axes = (0,1)
// output shape = (1,1,10,5)
//
// input shape = (10,5)
// axes = (0,2)
// output shape = (1,10,1,5)
//
// input shape = (10,5)
// axes = (-2,-1)
// output shape = (10,5,1,1)
type ExpandDimsLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Axis values provided here get dimension 1 in the output tensor.
	// Negative indexing is supported.
	Axes          []int64 `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExpandDimsLayerParams) Reset() {
	*x = ExpandDimsLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[157]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExpandDimsLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExpandDimsLayerParams) ProtoMessage() {}

func (x *ExpandDimsLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[157]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExpandDimsLayerParams.ProtoReflect.Descriptor instead.
func (*ExpandDimsLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{157}
}

func (x *ExpandDimsLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

// A layer that flattens the input tensor into a 2-dimensional matrix.
//
// Requires 1 input and produces 1 output.
// Output tensor is always rank 2.
//
// First dimension of output is the product of all the dimensions in input[:axis] ("axis" is exclusive)
// Second dimension of output is the product of all the dimensions in input[axis:] ("axis" is inclusive)
//
// e.g.:
// input shape:  (3,)
// axis:  -1
// output shape:  (1, 3)
//
// input shape:  (3,)
// axis:  1
// output shape:  (3, 1)
//
// input shape:  (4, 3)
// axis:  -1
// output shape:  (4, 3)
//
// input shape:  (5, 2)
// axis:  0
// output shape:  (1, 10)
//
// input shape:  (5, 5, 3)
// axis:  -2
// output shape:  (5, 15)
//
// input shape:  (2, 3, 2)
// axis:  -1
// output shape:  (6, 2)
type FlattenTo2DLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FlattenTo2DLayerParams) Reset() {
	*x = FlattenTo2DLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[158]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FlattenTo2DLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FlattenTo2DLayerParams) ProtoMessage() {}

func (x *FlattenTo2DLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[158]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FlattenTo2DLayerParams.ProtoReflect.Descriptor instead.
func (*FlattenTo2DLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{158}
}

func (x *FlattenTo2DLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

// A layer that reshapes a tensor.
//
// Requires 1 input and produces 1 output.
//
// Output tensor is the reshaped version of the input and has shape as specified in the
// parameter "targetShape".
type ReshapeStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TargetShape   []int64                `protobuf:"varint,1,rep,packed,name=targetShape,proto3" json:"targetShape,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReshapeStaticLayerParams) Reset() {
	*x = ReshapeStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[159]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReshapeStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReshapeStaticLayerParams) ProtoMessage() {}

func (x *ReshapeStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[159]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReshapeStaticLayerParams.ProtoReflect.Descriptor instead.
func (*ReshapeStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{159}
}

func (x *ReshapeStaticLayerParams) GetTargetShape() []int64 {
	if x != nil {
		return x.TargetShape
	}
	return nil
}

// A layer that reshapes a tensor.
//
// Requires 2 inputs and produces 1 output.
//
// First input is reshaped to produce the output, while the second input is only
// used to determine the shape of the output. Values of the second input are not used.
//
// Output is a tensor with the same shape as the second input.
type ReshapeLikeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReshapeLikeLayerParams) Reset() {
	*x = ReshapeLikeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[160]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReshapeLikeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReshapeLikeLayerParams) ProtoMessage() {}

func (x *ReshapeLikeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[160]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReshapeLikeLayerParams.ProtoReflect.Descriptor instead.
func (*ReshapeLikeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{160}
}

// A layer that reshapes a tensor.
//
// Requires 2 inputs and produces 1 output.
//
// First input is the one that is reshaped to produce the output.
// Second input is a rank 1 tensor specifying the shape of the output.
// Output tensor has shape as specified by the values in the 2nd input tensor.
type ReshapeDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ReshapeDynamicLayerParams) Reset() {
	*x = ReshapeDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[161]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ReshapeDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ReshapeDynamicLayerParams) ProtoMessage() {}

func (x *ReshapeDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[161]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ReshapeDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*ReshapeDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{161}
}

// A layer that decreases the rank of the input tensor by removing unit dimensions.
//
// Requires 1 input and produces 1 output.
//
// Output rank is one less than input rank, if input rank is more than 1.
// If input rank is 1, output rank is also 1.
//
// e.g.:
//
// input shape = (1,1,10,5)
// axes = (0,1)
// output shape = (10,5)
//
// input shape = (1,10,5,1)
// axes = (0,3)
// output shape = (10,5)
//
// input shape = (10,5,1,1)
// axes = (-2,-1)
// output shape = (10,5)
//
// input shape = (1,)
// axes = (0)
// output shape = (1,)
type SqueezeLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Axis values provided here get removed from the input tensor.
	// Negative indexing is supported.
	Axes          []int64 `protobuf:"varint,1,rep,packed,name=axes,proto3" json:"axes,omitempty"`
	SqueezeAll    bool    `protobuf:"varint,2,opt,name=squeezeAll,proto3" json:"squeezeAll,omitempty"` // if true squeeze all dimensions that are 1.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SqueezeLayerParams) Reset() {
	*x = SqueezeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[162]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SqueezeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SqueezeLayerParams) ProtoMessage() {}

func (x *SqueezeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[162]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SqueezeLayerParams.ProtoReflect.Descriptor instead.
func (*SqueezeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{162}
}

func (x *SqueezeLayerParams) GetAxes() []int64 {
	if x != nil {
		return x.Axes
	}
	return nil
}

func (x *SqueezeLayerParams) GetSqueezeAll() bool {
	if x != nil {
		return x.SqueezeAll
	}
	return false
}

// A layer that returns top K (or bottom K) values and the corresponding indices
// of the input along a given axis.
//
// Requires 1 or 2 inputs and produces 2 outputs.
//
// The second input is the value of the K, and is optional.
// If there is only one input, value of K that is specified in the layer parameter is used.
//
// Both outputs have the same rank as the first input.
// Second input must correspond to a scalar tensor.
//
// e.g.:
//
// first input's shape = (45, 34, 10, 5)
// axis = 1
// output shape, for both outputs = (45, K, 10, 5)
type TopKLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`             //  negative indexing is supported
	K             uint64                 `protobuf:"varint,2,opt,name=K,proto3" json:"K,omitempty"`                   // is ignored if a second input is present.
	UseBottomK    bool                   `protobuf:"varint,3,opt,name=useBottomK,proto3" json:"useBottomK,omitempty"` // if true, bottom K (values, indices) are returned instead
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TopKLayerParams) Reset() {
	*x = TopKLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[163]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TopKLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TopKLayerParams) ProtoMessage() {}

func (x *TopKLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[163]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TopKLayerParams.ProtoReflect.Descriptor instead.
func (*TopKLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{163}
}

func (x *TopKLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *TopKLayerParams) GetK() uint64 {
	if x != nil {
		return x.K
	}
	return 0
}

func (x *TopKLayerParams) GetUseBottomK() bool {
	if x != nil {
		return x.UseBottomK
	}
	return false
}

// A layer that returns the indices of the maximum value along a specified axis in a tensor.
//
// Requires 1 input and produces 1 output. Negative indexing is supported.
//
// Output has the same rank as the input if "removeDim" is False (default).
// Output has rank one less than the input if "removeDim" is True and input rank is more than 1.
//
// e.g.:
//
// input shape = (45, 34, 10, 5)
// axis = -2
// output shape = (45, 1, 10, 5), if removeDim = False (default)
// output shape = (45, 10, 5), if removeDim = True
//
// input shape = (5,)
// axis = 0
// output shape = (1,), if removeDim = False or True
type ArgMaxLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	RemoveDim     bool                   `protobuf:"varint,2,opt,name=removeDim,proto3" json:"removeDim,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ArgMaxLayerParams) Reset() {
	*x = ArgMaxLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[164]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ArgMaxLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ArgMaxLayerParams) ProtoMessage() {}

func (x *ArgMaxLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[164]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ArgMaxLayerParams.ProtoReflect.Descriptor instead.
func (*ArgMaxLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{164}
}

func (x *ArgMaxLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *ArgMaxLayerParams) GetRemoveDim() bool {
	if x != nil {
		return x.RemoveDim
	}
	return false
}

// A layer that returns the indices of the minimum value along a specified axis in a tensor.
//
// Requires 1 input and produces 1 output. Negative indexing is supported.
//
// Output has the same rank as the input if "removeDim" is False (default).
// Output has rank one less than the input if "removeDim" is True and input rank is more than 1.
//
// e.g.:
//
// input shape = (45, 34, 10, 5)
// axis = -2
// output shape = (45, 1, 10, 5), if removeDim = False (default)
// output shape = (45, 10, 5), if removeDim = True
//
// input shape = (5,)
// axis = 0
// output shape = (1,), if removeDim = False or True
type ArgMinLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	RemoveDim     bool                   `protobuf:"varint,2,opt,name=removeDim,proto3" json:"removeDim,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ArgMinLayerParams) Reset() {
	*x = ArgMinLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[165]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ArgMinLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ArgMinLayerParams) ProtoMessage() {}

func (x *ArgMinLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[165]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ArgMinLayerParams.ProtoReflect.Descriptor instead.
func (*ArgMinLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{165}
}

func (x *ArgMinLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *ArgMinLayerParams) GetRemoveDim() bool {
	if x != nil {
		return x.RemoveDim
	}
	return false
}

// A layer layer that splits the input tensor into multiple output tensors,
// along the specified axis.
//
// The layer either uniformly splits the input tensor into “num_splits“ tensors, or
// splits according to the given split sizes in “split_sizes“.
// Supports unequal splits and negative indexing.
//
// Requires 1 input and produces at least 2 outputs.
// Rank of all the outputs is same as that of the input.
//
// If parameter "splitSizes" is provided, value of the parameter "numSplits" is ignored, since in that case
// "numSplits" is automatically inferred to be the length of "splitSizes".
//
// e.g.:
// input shape:  (5, 3, 4)
// axis = -3, split_sizes = [3, 2]
// output shape:  (3, 3, 4)
// output shape:  (2, 3, 4)
type SplitNDLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	NumSplits     uint64                 `protobuf:"varint,2,opt,name=numSplits,proto3" json:"numSplits,omitempty"`
	SplitSizes    []uint64               `protobuf:"varint,3,rep,packed,name=splitSizes,proto3" json:"splitSizes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SplitNDLayerParams) Reset() {
	*x = SplitNDLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[166]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SplitNDLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SplitNDLayerParams) ProtoMessage() {}

func (x *SplitNDLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[166]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SplitNDLayerParams.ProtoReflect.Descriptor instead.
func (*SplitNDLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{166}
}

func (x *SplitNDLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *SplitNDLayerParams) GetNumSplits() uint64 {
	if x != nil {
		return x.NumSplits
	}
	return 0
}

func (x *SplitNDLayerParams) GetSplitSizes() []uint64 {
	if x != nil {
		return x.SplitSizes
	}
	return nil
}

// A layer that performs element-wise ceil operation on the input tensor that
// rounds the value to the smallest integer not less than x.
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type CeilLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CeilLayerParams) Reset() {
	*x = CeilLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[167]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CeilLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CeilLayerParams) ProtoMessage() {}

func (x *CeilLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[167]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CeilLayerParams.ProtoReflect.Descriptor instead.
func (*CeilLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{167}
}

// A layer that performs element-wise round operation on the input tensor
// that rounds the value to the nearest integer.
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type RoundLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RoundLayerParams) Reset() {
	*x = RoundLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[168]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RoundLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RoundLayerParams) ProtoMessage() {}

func (x *RoundLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[168]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RoundLayerParams.ProtoReflect.Descriptor instead.
func (*RoundLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{168}
}

// A layer that performs element-wise floor operation on the input tensor
// that rounds the value to the largest integer not greater than x.
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type FloorLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FloorLayerParams) Reset() {
	*x = FloorLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[169]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FloorLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FloorLayerParams) ProtoMessage() {}

func (x *FloorLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[169]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FloorLayerParams.ProtoReflect.Descriptor instead.
func (*FloorLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{169}
}

// A layer that performs element-wise sign operation (+1 for positive values,
// -1 for negative values, 0 for zeros).
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type SignLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SignLayerParams) Reset() {
	*x = SignLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[170]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SignLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SignLayerParams) ProtoMessage() {}

func (x *SignLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[170]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SignLayerParams.ProtoReflect.Descriptor instead.
func (*SignLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{170}
}

// A layer that performs element-wise clip operation. Clip the values in the
// input tensor to the threshold values [min_value, max_value].
//
// Requires 1 input and produces 1 output.
//
// Parameter minVal: the minimum threshold.
// Parameter maxVal: the maximum threshold.
//
// output =  min(max(input, minVal), maxVal)
//
// Output shape is same as the input.
type ClipLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	MinVal        float32                `protobuf:"fixed32,1,opt,name=minVal,proto3" json:"minVal,omitempty"`
	MaxVal        float32                `protobuf:"fixed32,2,opt,name=maxVal,proto3" json:"maxVal,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ClipLayerParams) Reset() {
	*x = ClipLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[171]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ClipLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClipLayerParams) ProtoMessage() {}

func (x *ClipLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[171]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClipLayerParams.ProtoReflect.Descriptor instead.
func (*ClipLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{171}
}

func (x *ClipLayerParams) GetMinVal() float32 {
	if x != nil {
		return x.MinVal
	}
	return 0
}

func (x *ClipLayerParams) GetMaxVal() float32 {
	if x != nil {
		return x.MaxVal
	}
	return 0
}

// A layer that extracts a slice of size “(end - begin) / stride“
// from the given input tensor.
// Support negative indexing and negative strides.
//
// Requires 1 input and produces 1 output.
// Output rank is same as the input rank.
//
// Value of beginIds, beginMasks, endIds, endMasks, strides are required parameters.
// Lengths of all the parameters must equal the rank of the input.
//
// i-th element of "beginIds" is ignored and assumed to be 0 if the i-th element of
// "beginMasks" is True
//
// i-th element of "endIds" is ignored and assumed to be -1 if the i-th element of
// "endMasks" is True
//
// e.g.:
// if i-th element of "squeezeMasks" is set to True, only beginIds[i] would be sliced
// out, and all other masks and inputs are ignored.
//
// e.g. (without squeezeMasks):
// input shape:  (5, 5, 5)
// beginIds:  [1, 2, 3]
// beginMasks:  [True, False, True]
// endIds:  [3, -3, 2]
// endMasks:  [False, True, True]
// strides:  [2, 2, 2]
// SqueezeMasks:  [False, False, False]
// output shape:  (2, 2, 3)
// This is equivalent to input[:3:2, 2::2, ::2]
//
// e.g. (with squeezeMasks):
// input shape:  (5, 5, 5)
// beginIds:  [1, 2, 3]
// beginMasks:  [True, False, True]
// endIds:  [3, -3, 2]
// endMasks:  [False, True, True]
// strides:  [2, 2, 2]
// SqueezeMasks:  [False, True, False]
// output shape:  (2, 3)
// This is equivalent to input[:3:2, 2, ::2]
type SliceStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	BeginIds      []int64                `protobuf:"varint,1,rep,packed,name=beginIds,proto3" json:"beginIds,omitempty"`
	BeginMasks    []bool                 `protobuf:"varint,2,rep,packed,name=beginMasks,proto3" json:"beginMasks,omitempty"`
	EndIds        []int64                `protobuf:"varint,3,rep,packed,name=endIds,proto3" json:"endIds,omitempty"`
	EndMasks      []bool                 `protobuf:"varint,4,rep,packed,name=endMasks,proto3" json:"endMasks,omitempty"`
	Strides       []int64                `protobuf:"varint,5,rep,packed,name=strides,proto3" json:"strides,omitempty"`
	SqueezeMasks  []bool                 `protobuf:"varint,6,rep,packed,name=squeezeMasks,proto3" json:"squeezeMasks,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SliceStaticLayerParams) Reset() {
	*x = SliceStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[172]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SliceStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SliceStaticLayerParams) ProtoMessage() {}

func (x *SliceStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[172]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SliceStaticLayerParams.ProtoReflect.Descriptor instead.
func (*SliceStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{172}
}

func (x *SliceStaticLayerParams) GetBeginIds() []int64 {
	if x != nil {
		return x.BeginIds
	}
	return nil
}

func (x *SliceStaticLayerParams) GetBeginMasks() []bool {
	if x != nil {
		return x.BeginMasks
	}
	return nil
}

func (x *SliceStaticLayerParams) GetEndIds() []int64 {
	if x != nil {
		return x.EndIds
	}
	return nil
}

func (x *SliceStaticLayerParams) GetEndMasks() []bool {
	if x != nil {
		return x.EndMasks
	}
	return nil
}

func (x *SliceStaticLayerParams) GetStrides() []int64 {
	if x != nil {
		return x.Strides
	}
	return nil
}

func (x *SliceStaticLayerParams) GetSqueezeMasks() []bool {
	if x != nil {
		return x.SqueezeMasks
	}
	return nil
}

// A layer that extracts a slice of size “(end - begin) / stride“
// from the given input tensor.
// Support negative indexing and negative strides.
// See "SliceStaticLayerParams" for the description and an example of the functionality of the layer.
//
// Requires 2 to 7 inputs and produces 1 output.
// Rank of the output is same as the rank of the first input unless squeezeMask is set.
//
// Value of beginIds, beginMasks, endIds, endMasks, strides can be passed in either
// as dynamic inputs or as static parameters.
// Lengths of all the parameters or inputs from 2-6 must equal the rank of the first input.
//
// The 2nd input represents the "beginIds".
// The 3rd input, if present, corresponds to "endIds". In this case the value of the "endIds" parameter is ignored.
// The 4th input, if present, corresponds to "strides". In this case the value of the "strides" parameter is ignored.
// The 5th input, if present, corresponds to "beginMasks". In this case the value of the "beginMasks" parameter is ignored.
// The 6th input, if present, corresponds to "endMasks". In this case the value of the "endMasks" parameter is ignored.
// The 7th input, if present, corresponds to "squeezeMasks". In this case the value of the "squeezeMasks" parameter is ignored.
type SliceDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	BeginMasks    []bool                 `protobuf:"varint,2,rep,packed,name=beginMasks,proto3" json:"beginMasks,omitempty"`
	EndIds        []int64                `protobuf:"varint,3,rep,packed,name=endIds,proto3" json:"endIds,omitempty"`
	EndMasks      []bool                 `protobuf:"varint,4,rep,packed,name=endMasks,proto3" json:"endMasks,omitempty"`
	Strides       []int64                `protobuf:"varint,5,rep,packed,name=strides,proto3" json:"strides,omitempty"`
	SqueezeMasks  []bool                 `protobuf:"varint,6,rep,packed,name=squeezeMasks,proto3" json:"squeezeMasks,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SliceDynamicLayerParams) Reset() {
	*x = SliceDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[173]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SliceDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SliceDynamicLayerParams) ProtoMessage() {}

func (x *SliceDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[173]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SliceDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*SliceDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{173}
}

func (x *SliceDynamicLayerParams) GetBeginMasks() []bool {
	if x != nil {
		return x.BeginMasks
	}
	return nil
}

func (x *SliceDynamicLayerParams) GetEndIds() []int64 {
	if x != nil {
		return x.EndIds
	}
	return nil
}

func (x *SliceDynamicLayerParams) GetEndMasks() []bool {
	if x != nil {
		return x.EndMasks
	}
	return nil
}

func (x *SliceDynamicLayerParams) GetStrides() []int64 {
	if x != nil {
		return x.Strides
	}
	return nil
}

func (x *SliceDynamicLayerParams) GetSqueezeMasks() []bool {
	if x != nil {
		return x.SqueezeMasks
	}
	return nil
}

// A layer that constructs a tensor by repeating the input tensor multiple
// number of times.
//
// Requires 1 or 2 inputs and produces 1 output.
// Output rank is same as the input rank.
//
// If two inputs are provided, second input is used as "reps"
// and "reps" parameter is ignored.
//
// If only one input is provided,
// length of the "reps" parameter must be at least 1 and
// not greater than the rank of the input.
// If it is less than the input rank, it is made equal to the input rank by prepending 1's to it.
//
// e.g.:
//
// input shape = (2, 4, 2)
// reps = (1, 2, 6)
// output shape = (2, 8, 12)
//
// input shape = (2, 4, 2)
// reps = (6)
// reps after prepending ones = (1, 1, 6)
// output shape = (2, 4, 12)
//
// input shape = (2, 4, 2)
// second input = [1, 2, 6] -> shape: (3,)
// reps = N/A [Ignored]
// output shape = (2, 8, 12)
type TileLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Reps          []uint64               `protobuf:"varint,1,rep,packed,name=reps,proto3" json:"reps,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TileLayerParams) Reset() {
	*x = TileLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[174]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TileLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TileLayerParams) ProtoMessage() {}

func (x *TileLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[174]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TileLayerParams.ProtoReflect.Descriptor instead.
func (*TileLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{174}
}

func (x *TileLayerParams) GetReps() []uint64 {
	if x != nil {
		return x.Reps
	}
	return nil
}

// A layer that returns the shape of an input tensor.
//
// Requires 1 input and produces 1 output.
//
// Input: a tensor.
// Output: a vector of length R, where R is the rank of the input tensor
// Output is always a rank 1 tensor.
type GetShapeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetShapeLayerParams) Reset() {
	*x = GetShapeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[175]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetShapeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetShapeLayerParams) ProtoMessage() {}

func (x *GetShapeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[175]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetShapeLayerParams.ProtoReflect.Descriptor instead.
func (*GetShapeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{175}
}

// A layer that computes the Gauss error function,
// which is defined as:
//
// .. math::
//
//	f(x) = \dfrac{1}{\sqrt{\pi}}\int_{-x}^{x}{e^{-t^2}dt}
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type ErfLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ErfLayerParams) Reset() {
	*x = ErfLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[176]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ErfLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ErfLayerParams) ProtoMessage() {}

func (x *ErfLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[176]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ErfLayerParams.ProtoReflect.Descriptor instead.
func (*ErfLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{176}
}

// A layer that evaluates the Gaussian Error Linear Unit (GELU) activation.
// Following equations are used to compute the activation based on the value of the "mode" parameter:
//
// mode == 'EXACT':
// .. math::
//
//	f(x) = 0.5x\left ( 1+\rm{erf}\left ( \frac{x}{\sqrt{2}} \right ) \right )
//
// mode == 'TANH_APPROXIMATION':
// .. math::
//
//	f(x) = 0.5x\left ( 1+\rm{tanh}\left ( \sqrt{2/\pi}\left ( x + 0.044715x^3 \right ) \right ) \right )
//
// mode == 'SIGMOID_APPROXIMATION':
// .. math::
//
//	f(x) = x*\rm{sigmoid}(1.702x)
//
// Requires 1 input and produces 1 output.
// Output shape is same as the input.
type GeluLayerParams struct {
	state         protoimpl.MessageState   `protogen:"open.v1"`
	Mode          GeluLayerParams_GeluMode `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.Specification.GeluLayerParams_GeluMode" json:"mode,omitempty"` // mode of GELU operation.
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GeluLayerParams) Reset() {
	*x = GeluLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[177]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GeluLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GeluLayerParams) ProtoMessage() {}

func (x *GeluLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[177]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GeluLayerParams.ProtoReflect.Descriptor instead.
func (*GeluLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{177}
}

func (x *GeluLayerParams) GetMode() GeluLayerParams_GeluMode {
	if x != nil {
		return x.Mode
	}
	return GeluLayerParams_EXACT
}

// RangeStatic layer that returns a tensor that contains evenly spaced values.
// It is similar in functionality to the numpy.arange method.
//
// Requires no input and produces 1 output.
// Output is a rank 1 tensor.
type RangeStaticLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	EndValue      float32                `protobuf:"fixed32,1,opt,name=endValue,proto3" json:"endValue,omitempty"`
	StartValue    float32                `protobuf:"fixed32,2,opt,name=startValue,proto3" json:"startValue,omitempty"`
	StepSizeValue float32                `protobuf:"fixed32,3,opt,name=stepSizeValue,proto3" json:"stepSizeValue,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RangeStaticLayerParams) Reset() {
	*x = RangeStaticLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[178]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RangeStaticLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RangeStaticLayerParams) ProtoMessage() {}

func (x *RangeStaticLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[178]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RangeStaticLayerParams.ProtoReflect.Descriptor instead.
func (*RangeStaticLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{178}
}

func (x *RangeStaticLayerParams) GetEndValue() float32 {
	if x != nil {
		return x.EndValue
	}
	return 0
}

func (x *RangeStaticLayerParams) GetStartValue() float32 {
	if x != nil {
		return x.StartValue
	}
	return 0
}

func (x *RangeStaticLayerParams) GetStepSizeValue() float32 {
	if x != nil {
		return x.StepSizeValue
	}
	return 0
}

// A layer that returns a tensor that contains evenly spaced values.
// Its functionality is similar to the numpy.arange method.
//
// Requires at least 1 input, up to a maximum of 3 inputs.
// Produces 1 output, which is a rank 1 tensor.
//
// Each input must be a scalar, or rank 1 and shape (1,).
//
// The first input represents the "endValue".
// The second input, if present, corresponds to "startValue". In this case the value of the "startValue" parameter is ignored.
// The third input, if present, corresponds to "stepSizeValue". In this case the value of the "stepSizeValue" parameter is ignored.
type RangeDynamicLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	StartValue    float32                `protobuf:"fixed32,2,opt,name=startValue,proto3" json:"startValue,omitempty"`
	StepSizeValue float32                `protobuf:"fixed32,3,opt,name=stepSizeValue,proto3" json:"stepSizeValue,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RangeDynamicLayerParams) Reset() {
	*x = RangeDynamicLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[179]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RangeDynamicLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RangeDynamicLayerParams) ProtoMessage() {}

func (x *RangeDynamicLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[179]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RangeDynamicLayerParams.ProtoReflect.Descriptor instead.
func (*RangeDynamicLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{179}
}

func (x *RangeDynamicLayerParams) GetStartValue() float32 {
	if x != nil {
		return x.StartValue
	}
	return 0
}

func (x *RangeDynamicLayerParams) GetStepSizeValue() float32 {
	if x != nil {
		return x.StepSizeValue
	}
	return 0
}

// A layer that returns a tensor containing all windows of size “windowSize“
// separated by “step“ along the dimension “axis“.
//
// .. code::
//
//	y = SlidingWindows(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//
//	An N-Dimensional tensor.
//
// Output
//
//	An (N+1)-Dimensional tensor.
//
// This operation behaves as following:
//   - if axis = 0 & input is rank 1 (L,). Output shape will be (M, W).
//   - if axis = 1 & input is rank 3 (B1, L, C1). Output shape will be (B1, M, W, C1)
//   - if axis = 2 & input is rank 5 (B1, B2, L, C1, C2) --> (B1 * B2, L, C1 * C2) --> (B1 * B2, M, W, C1 * C2). Output shape will be (B1, B2, M, W, C1, C2)
//   - etc.
//
// where
//   - L, C, B refer to input length, feature dimension length & batch size respectively
//   - W is the window size.
//   - M is the number of windows/slices calculated as M = (L - W) / step + 1
type SlidingWindowsLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"`
	WindowSize    uint64                 `protobuf:"varint,2,opt,name=windowSize,proto3" json:"windowSize,omitempty"`
	Step          uint64                 `protobuf:"varint,3,opt,name=step,proto3" json:"step,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SlidingWindowsLayerParams) Reset() {
	*x = SlidingWindowsLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[180]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SlidingWindowsLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SlidingWindowsLayerParams) ProtoMessage() {}

func (x *SlidingWindowsLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[180]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SlidingWindowsLayerParams.ProtoReflect.Descriptor instead.
func (*SlidingWindowsLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{180}
}

func (x *SlidingWindowsLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *SlidingWindowsLayerParams) GetWindowSize() uint64 {
	if x != nil {
		return x.WindowSize
	}
	return 0
}

func (x *SlidingWindowsLayerParams) GetStep() uint64 {
	if x != nil {
		return x.Step
	}
	return 0
}

// A layer that applies layer normalization over the input tensor.
//
// Requires 1 input and produces 1 output.
//
// output = gamma * (input - computed_mean) / (sqrt(computed_variance + eps)) + beta
//
// Parameters
//
//	normalizedShape: subset of the input shape, along with layer norm is performed, rest of the input shape is treated as the batch dimension. The mean and variance are computed for the input, over the last few dimensions as specified by the normalizedShape parameter.
//	gamma: must have shape = "normalizedShape"
//	beta: must have shape = "normalizedShape"
//	eps: small constant to avoid division by 0
//
// Output shape is same as the input.
//
// e.g.:
// input shape = (10,5)
// normalized shape = (5,) or (10,5)
//
// input shape = (10,5,6,7)
// normalized shape = (7,) or (6,7) or (5,6,7) or (10,5,6,7)
type LayerNormalizationLayerParams struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	NormalizedShape []int64                `protobuf:"varint,1,rep,packed,name=normalizedShape,proto3" json:"normalizedShape,omitempty"`
	Eps             float32                `protobuf:"fixed32,2,opt,name=eps,proto3" json:"eps,omitempty"`
	Gamma           *WeightParams          `protobuf:"bytes,3,opt,name=gamma,proto3" json:"gamma,omitempty"`
	Beta            *WeightParams          `protobuf:"bytes,4,opt,name=beta,proto3" json:"beta,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *LayerNormalizationLayerParams) Reset() {
	*x = LayerNormalizationLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[181]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LayerNormalizationLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LayerNormalizationLayerParams) ProtoMessage() {}

func (x *LayerNormalizationLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[181]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LayerNormalizationLayerParams.ProtoReflect.Descriptor instead.
func (*LayerNormalizationLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{181}
}

func (x *LayerNormalizationLayerParams) GetNormalizedShape() []int64 {
	if x != nil {
		return x.NormalizedShape
	}
	return nil
}

func (x *LayerNormalizationLayerParams) GetEps() float32 {
	if x != nil {
		return x.Eps
	}
	return 0
}

func (x *LayerNormalizationLayerParams) GetGamma() *WeightParams {
	if x != nil {
		return x.Gamma
	}
	return nil
}

func (x *LayerNormalizationLayerParams) GetBeta() *WeightParams {
	if x != nil {
		return x.Beta
	}
	return nil
}

// Non maximum suppression (NMS) layer.
// Applies the non maximum suppression algorithm to input bounding box coordinates.
// The effect of this layer is similar to the functionality of the "NonMaximumSuppression"
// model type (for details please see NonMaximumSuppression.proto) with a couple of differences.
// One, this is a layer in a neural network model, whereas that is a different model type. Second,
// this layer supports a batch of bounding boxes.
//
// The NMS layer requires at least 2 inputs, and up to a maximum of 5 inputs. It produces 4 outputs.
// Following is the description of inputs and outputs:
//
// input 1, shape (B,N,4): coordinates of N boxes, for a batch size B.
// input 2, shape (B,N,C): class scores for each box. C can be 1 when there is only 1 score per box, i.e., no class specific score.
//
// input 3, optional, shape (1,): IoU threshold. When present, it overwrites the value provided in layer parameter "iouThreshold".
// input 4, optional, shape (1,): Score threshold. When present, it overwrites the value provided in layer parameter "scoreThreshold".
// input 5, optional, shape (1,): Maximum number of boxes. When present, it overwrites the value provided in layer parameter "maxBoxes".
//
// output 1, shape (B,maxBoxes,4): box coordinates, corresponding to the surviving boxes.
// output 2, shape (B,maxBoxes,C): box scores, corresponding to the surviving boxes.
// output 3, shape (B,maxBoxes): indices of the surviving boxes. Hence it will have values in the range [0,N-1], except for padding.
// output 4, shape (B,): number of boxes selected after the NMS algorithm, for each batch.
//
// When surviving boxes are less than "maxBoxes", the first 3 outputs are padded.
// For the first two outputs, the padding is done using values 0, whereas for the third output the
// padding value used is -1, since the output values represent indices.
//
// If no box survives, that is, all the scores are below the "scoreThreshold",
// then for that batch, number of boxes (value of the fourth output) will be 1. The first 3 outputs will
// correspond to the box with the highest score. This is to avoid generating an "empty" output.
//
// The four values that describe the box dimensions are (in order):
//
//   - x (center location of the box along the horizontal axis)
//   - y (center location of the box along the vertical axis)
//   - width (size of box along the horizontal axis)
//   - height (size of box on along the vertical axis)
//
// In each batch,
// the N scores for N boxes, used for suppression, are generated by taking the max of the matrix (N,C)
// along the columns.
// If "perClassSuppression" flag is false, suppression happens across all classes.
// If "perClassSuppression" flag is true, each box is assigned to the class with the highest
// score and then the suppression happens separately for boxes within the same class.
//
// Note that the 4th output can be used to dynamically slice the first 3 outputs, in case
// the padded outputs are not required.
type NonMaximumSuppressionLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The intersection over union (IoU) threshold over which boxes are suppressed.
	IouThreshold float32 `protobuf:"fixed32,1,opt,name=iouThreshold,proto3" json:"iouThreshold,omitempty"`
	// Before IoU suppression is performed, boxes with class scores below this threshold are rejected.
	ScoreThreshold float32 `protobuf:"fixed32,2,opt,name=scoreThreshold,proto3" json:"scoreThreshold,omitempty"`
	// The maximum number of boxes to be given out as output.
	// If the number of surviving boxes are less, output is padded up to this number.
	MaxBoxes uint64 `protobuf:"varint,3,opt,name=maxBoxes,proto3" json:"maxBoxes,omitempty"`
	// If true, suppression is performed independently within boxes of each class.
	PerClassSuppression bool `protobuf:"varint,4,opt,name=perClassSuppression,proto3" json:"perClassSuppression,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *NonMaximumSuppressionLayerParams) Reset() {
	*x = NonMaximumSuppressionLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[182]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NonMaximumSuppressionLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NonMaximumSuppressionLayerParams) ProtoMessage() {}

func (x *NonMaximumSuppressionLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[182]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NonMaximumSuppressionLayerParams.ProtoReflect.Descriptor instead.
func (*NonMaximumSuppressionLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{182}
}

func (x *NonMaximumSuppressionLayerParams) GetIouThreshold() float32 {
	if x != nil {
		return x.IouThreshold
	}
	return 0
}

func (x *NonMaximumSuppressionLayerParams) GetScoreThreshold() float32 {
	if x != nil {
		return x.ScoreThreshold
	}
	return 0
}

func (x *NonMaximumSuppressionLayerParams) GetMaxBoxes() uint64 {
	if x != nil {
		return x.MaxBoxes
	}
	return 0
}

func (x *NonMaximumSuppressionLayerParams) GetPerClassSuppression() bool {
	if x != nil {
		return x.PerClassSuppression
	}
	return false
}

// A layer that performs element-wise clamped ReLU operation.
//
// Requires 1 input and produces 1 output.
//
// This function has the following formula:
//
// .. math::
//
//	f(x) = \begin{cases}
//	          \text{min}(\text{beta},x) \;\; \text{if} \;\; x \geq 0\\
//	          \text{min}(\text{beta} ,\text{alpha}\cdot x) \;\; \text{if} \;\; x<0
//	       \end{cases}
//
// Output shape is same as the input.
//
// Available (iOS >= 14, macOS >= 11.0, watchOS >= 7)
type ClampedReLULayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Alpha         float32                `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta          float32                `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ClampedReLULayerParams) Reset() {
	*x = ClampedReLULayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[183]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ClampedReLULayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClampedReLULayerParams) ProtoMessage() {}

func (x *ClampedReLULayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[183]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClampedReLULayerParams.ProtoReflect.Descriptor instead.
func (*ClampedReLULayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{183}
}

func (x *ClampedReLULayerParams) GetAlpha() float32 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

func (x *ClampedReLULayerParams) GetBeta() float32 {
	if x != nil {
		return x.Beta
	}
	return 0
}

// A layer that returns the indices that would sort the input tensor, along a specified axis.
//
// Requires 1 input and produces 1 output.
//
// Output has the same rank and shape as the input.
//
// Value of "axis" must be positive and less than the rank of the input.
//
// e.g.:
//
// input shape = (5,)
// axis = 0
// input values = [3.1, 5.4, 32.9, 3.2, 77.0]
// output shape = (5,)
// output values = [0, 3, 1, 2, 4], descending = False
// output values = [4, 2, 1, 3, 0], descending = True
//
// input shape = (2,3)
// axis = 1
// input values = [[3, 5, 32], [3, 77, 6]]
// output shape = (2,3)
// output values = [[0, 1, 2], [0, 2, 1]], descending = False
// output values = [[2, 1, 0], [1, 2, 0]], descending = True
type ArgSortLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Axis          int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"` // must be between [0, input_rank - 1]
	Descending    bool                   `protobuf:"varint,2,opt,name=descending,proto3" json:"descending,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ArgSortLayerParams) Reset() {
	*x = ArgSortLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[184]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ArgSortLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ArgSortLayerParams) ProtoMessage() {}

func (x *ArgSortLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[184]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ArgSortLayerParams.ProtoReflect.Descriptor instead.
func (*ArgSortLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{184}
}

func (x *ArgSortLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *ArgSortLayerParams) GetDescending() bool {
	if x != nil {
		return x.Descending
	}
	return false
}

// A layer that does slice operation by providing size to be extracted
// from the given input tensor.
//
// Requires 2 inputs and produces 1 output.
// Rank of the output is same as the rank of the first input.
//
// The 1st input represents the tensor to be sliced.
// The 2nd input represents the beginning index to be sliced from.
//
// Example:
// Input 1: x (x.shape = (2, 3, 4))
// Input 2: begin
// size: 2
// axis: 1
//
// Output: x[:, begin:begin+2, :]
type SliceBySizeLayerParams struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Size          int64                  `protobuf:"varint,2,opt,name=size,proto3" json:"size,omitempty"`
	Axis          int64                  `protobuf:"varint,3,opt,name=axis,proto3" json:"axis,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SliceBySizeLayerParams) Reset() {
	*x = SliceBySizeLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[185]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SliceBySizeLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SliceBySizeLayerParams) ProtoMessage() {}

func (x *SliceBySizeLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[185]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SliceBySizeLayerParams.ProtoReflect.Descriptor instead.
func (*SliceBySizeLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{185}
}

func (x *SliceBySizeLayerParams) GetSize() int64 {
	if x != nil {
		return x.Size
	}
	return 0
}

func (x *SliceBySizeLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

// A neural network specialized as a classifier.
type NeuralNetworkClassifier struct {
	state         protoimpl.MessageState        `protogen:"open.v1"`
	Layers        []*NeuralNetworkLayer         `protobuf:"bytes,1,rep,name=layers,proto3" json:"layers,omitempty"`
	Preprocessing []*NeuralNetworkPreprocessing `protobuf:"bytes,2,rep,name=preprocessing,proto3" json:"preprocessing,omitempty"`
	// use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs
	ArrayInputShapeMapping NeuralNetworkMultiArrayShapeMapping `protobuf:"varint,5,opt,name=arrayInputShapeMapping,proto3,enum=CoreML.Specification.NeuralNetworkMultiArrayShapeMapping" json:"arrayInputShapeMapping,omitempty"`
	// use this enum value to determine the input tensor shapes to the neural network, for image inputs
	ImageInputShapeMapping NeuralNetworkImageShapeMapping `protobuf:"varint,6,opt,name=imageInputShapeMapping,proto3,enum=CoreML.Specification.NeuralNetworkImageShapeMapping" json:"imageInputShapeMapping,omitempty"`
	UpdateParams           *NetworkUpdateParameters       `protobuf:"bytes,10,opt,name=updateParams,proto3" json:"updateParams,omitempty"`
	// The set of labels for every possible class.
	//
	// Types that are valid to be assigned to ClassLabels:
	//
	//	*NeuralNetworkClassifier_StringClassLabels
	//	*NeuralNetworkClassifier_Int64ClassLabels
	ClassLabels isNeuralNetworkClassifier_ClassLabels `protobuf_oneof:"ClassLabels"`
	// The name of the output blob containing the probability of each class.
	// In other words, the score vector. Must be a 1-D tensor with the same
	// number and order of elements as ClassLabels.
	LabelProbabilityLayerName string `protobuf:"bytes,200,opt,name=labelProbabilityLayerName,proto3" json:"labelProbabilityLayerName,omitempty"`
	unknownFields             protoimpl.UnknownFields
	sizeCache                 protoimpl.SizeCache
}

func (x *NeuralNetworkClassifier) Reset() {
	*x = NeuralNetworkClassifier{}
	mi := &file_NeuralNetwork_proto_msgTypes[186]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetworkClassifier) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetworkClassifier) ProtoMessage() {}

func (x *NeuralNetworkClassifier) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[186]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetworkClassifier.ProtoReflect.Descriptor instead.
func (*NeuralNetworkClassifier) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{186}
}

func (x *NeuralNetworkClassifier) GetLayers() []*NeuralNetworkLayer {
	if x != nil {
		return x.Layers
	}
	return nil
}

func (x *NeuralNetworkClassifier) GetPreprocessing() []*NeuralNetworkPreprocessing {
	if x != nil {
		return x.Preprocessing
	}
	return nil
}

func (x *NeuralNetworkClassifier) GetArrayInputShapeMapping() NeuralNetworkMultiArrayShapeMapping {
	if x != nil {
		return x.ArrayInputShapeMapping
	}
	return NeuralNetworkMultiArrayShapeMapping_RANK5_ARRAY_MAPPING
}

func (x *NeuralNetworkClassifier) GetImageInputShapeMapping() NeuralNetworkImageShapeMapping {
	if x != nil {
		return x.ImageInputShapeMapping
	}
	return NeuralNetworkImageShapeMapping_RANK5_IMAGE_MAPPING
}

func (x *NeuralNetworkClassifier) GetUpdateParams() *NetworkUpdateParameters {
	if x != nil {
		return x.UpdateParams
	}
	return nil
}

func (x *NeuralNetworkClassifier) GetClassLabels() isNeuralNetworkClassifier_ClassLabels {
	if x != nil {
		return x.ClassLabels
	}
	return nil
}

func (x *NeuralNetworkClassifier) GetStringClassLabels() *StringVector {
	if x != nil {
		if x, ok := x.ClassLabels.(*NeuralNetworkClassifier_StringClassLabels); ok {
			return x.StringClassLabels
		}
	}
	return nil
}

func (x *NeuralNetworkClassifier) GetInt64ClassLabels() *Int64Vector {
	if x != nil {
		if x, ok := x.ClassLabels.(*NeuralNetworkClassifier_Int64ClassLabels); ok {
			return x.Int64ClassLabels
		}
	}
	return nil
}

func (x *NeuralNetworkClassifier) GetLabelProbabilityLayerName() string {
	if x != nil {
		return x.LabelProbabilityLayerName
	}
	return ""
}

type isNeuralNetworkClassifier_ClassLabels interface {
	isNeuralNetworkClassifier_ClassLabels()
}

type NeuralNetworkClassifier_StringClassLabels struct {
	StringClassLabels *StringVector `protobuf:"bytes,100,opt,name=stringClassLabels,proto3,oneof"`
}

type NeuralNetworkClassifier_Int64ClassLabels struct {
	Int64ClassLabels *Int64Vector `protobuf:"bytes,101,opt,name=int64ClassLabels,proto3,oneof"`
}

func (*NeuralNetworkClassifier_StringClassLabels) isNeuralNetworkClassifier_ClassLabels() {}

func (*NeuralNetworkClassifier_Int64ClassLabels) isNeuralNetworkClassifier_ClassLabels() {}

type OneHotLayerParams struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	OneHotVectorSize uint64                 `protobuf:"varint,1,opt,name=oneHotVectorSize,proto3" json:"oneHotVectorSize,omitempty"` // size of the one hot vector
	Axis             int64                  `protobuf:"varint,2,opt,name=axis,proto3" json:"axis,omitempty"`                         //  negative indexing is supported. It refers to the axis in the output tensor.
	OnValue          float32                `protobuf:"fixed32,3,opt,name=onValue,proto3" json:"onValue,omitempty"`
	OffValue         float32                `protobuf:"fixed32,4,opt,name=offValue,proto3" json:"offValue,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *OneHotLayerParams) Reset() {
	*x = OneHotLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[187]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *OneHotLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OneHotLayerParams) ProtoMessage() {}

func (x *OneHotLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[187]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OneHotLayerParams.ProtoReflect.Descriptor instead.
func (*OneHotLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{187}
}

func (x *OneHotLayerParams) GetOneHotVectorSize() uint64 {
	if x != nil {
		return x.OneHotVectorSize
	}
	return 0
}

func (x *OneHotLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *OneHotLayerParams) GetOnValue() float32 {
	if x != nil {
		return x.OnValue
	}
	return 0
}

func (x *OneHotLayerParams) GetOffValue() float32 {
	if x != nil {
		return x.OffValue
	}
	return 0
}

type CumSumLayerParams struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Axis  int64                  `protobuf:"varint,1,opt,name=axis,proto3" json:"axis,omitempty"` //  negative indexing is supported
	// if true, the first element of the output is 0, and the last element contains the sum of the input up to the penultimate value
	// if false, the first element of the output is same as the input and the last element is the sum of all the input values
	// (this behavior is reversed when "reverse" flag is True)
	ExcludeFinalSum bool `protobuf:"varint,2,opt,name=excludeFinalSum,proto3" json:"excludeFinalSum,omitempty"`
	Reverse         bool `protobuf:"varint,3,opt,name=reverse,proto3" json:"reverse,omitempty"` // if true, cumsum is performed in the opposite direction
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *CumSumLayerParams) Reset() {
	*x = CumSumLayerParams{}
	mi := &file_NeuralNetwork_proto_msgTypes[188]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CumSumLayerParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CumSumLayerParams) ProtoMessage() {}

func (x *CumSumLayerParams) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[188]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CumSumLayerParams.ProtoReflect.Descriptor instead.
func (*CumSumLayerParams) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{188}
}

func (x *CumSumLayerParams) GetAxis() int64 {
	if x != nil {
		return x.Axis
	}
	return 0
}

func (x *CumSumLayerParams) GetExcludeFinalSum() bool {
	if x != nil {
		return x.ExcludeFinalSum
	}
	return false
}

func (x *CumSumLayerParams) GetReverse() bool {
	if x != nil {
		return x.Reverse
	}
	return false
}

// A neural network specialized as a regressor.
type NeuralNetworkRegressor struct {
	state         protoimpl.MessageState        `protogen:"open.v1"`
	Layers        []*NeuralNetworkLayer         `protobuf:"bytes,1,rep,name=layers,proto3" json:"layers,omitempty"`
	Preprocessing []*NeuralNetworkPreprocessing `protobuf:"bytes,2,rep,name=preprocessing,proto3" json:"preprocessing,omitempty"`
	// use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs
	ArrayInputShapeMapping NeuralNetworkMultiArrayShapeMapping `protobuf:"varint,5,opt,name=arrayInputShapeMapping,proto3,enum=CoreML.Specification.NeuralNetworkMultiArrayShapeMapping" json:"arrayInputShapeMapping,omitempty"`
	// use this enum value to determine the input tensor shapes to the neural network, for image inputs
	ImageInputShapeMapping NeuralNetworkImageShapeMapping `protobuf:"varint,6,opt,name=imageInputShapeMapping,proto3,enum=CoreML.Specification.NeuralNetworkImageShapeMapping" json:"imageInputShapeMapping,omitempty"`
	UpdateParams           *NetworkUpdateParameters       `protobuf:"bytes,10,opt,name=updateParams,proto3" json:"updateParams,omitempty"`
	unknownFields          protoimpl.UnknownFields
	sizeCache              protoimpl.SizeCache
}

func (x *NeuralNetworkRegressor) Reset() {
	*x = NeuralNetworkRegressor{}
	mi := &file_NeuralNetwork_proto_msgTypes[189]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NeuralNetworkRegressor) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NeuralNetworkRegressor) ProtoMessage() {}

func (x *NeuralNetworkRegressor) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[189]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NeuralNetworkRegressor.ProtoReflect.Descriptor instead.
func (*NeuralNetworkRegressor) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{189}
}

func (x *NeuralNetworkRegressor) GetLayers() []*NeuralNetworkLayer {
	if x != nil {
		return x.Layers
	}
	return nil
}

func (x *NeuralNetworkRegressor) GetPreprocessing() []*NeuralNetworkPreprocessing {
	if x != nil {
		return x.Preprocessing
	}
	return nil
}

func (x *NeuralNetworkRegressor) GetArrayInputShapeMapping() NeuralNetworkMultiArrayShapeMapping {
	if x != nil {
		return x.ArrayInputShapeMapping
	}
	return NeuralNetworkMultiArrayShapeMapping_RANK5_ARRAY_MAPPING
}

func (x *NeuralNetworkRegressor) GetImageInputShapeMapping() NeuralNetworkImageShapeMapping {
	if x != nil {
		return x.ImageInputShapeMapping
	}
	return NeuralNetworkImageShapeMapping_RANK5_IMAGE_MAPPING
}

func (x *NeuralNetworkRegressor) GetUpdateParams() *NetworkUpdateParameters {
	if x != nil {
		return x.UpdateParams
	}
	return nil
}

// Details on how the network will be updated
type NetworkUpdateParameters struct {
	state      protoimpl.MessageState `protogen:"open.v1"`
	LossLayers []*LossLayer           `protobuf:"bytes,1,rep,name=lossLayers,proto3" json:"lossLayers,omitempty"`
	Optimizer  *Optimizer             `protobuf:"bytes,2,opt,name=optimizer,proto3" json:"optimizer,omitempty"`
	Epochs     *Int64Parameter        `protobuf:"bytes,3,opt,name=epochs,proto3" json:"epochs,omitempty"`
	// Describes whether to shuffle the batch of data between epochs.
	Shuffle *BoolParameter `protobuf:"bytes,10,opt,name=shuffle,proto3" json:"shuffle,omitempty"`
	// The seed to be used in an associated random number generator.
	Seed          *Int64Parameter `protobuf:"bytes,20,opt,name=seed,proto3" json:"seed,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NetworkUpdateParameters) Reset() {
	*x = NetworkUpdateParameters{}
	mi := &file_NeuralNetwork_proto_msgTypes[190]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NetworkUpdateParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NetworkUpdateParameters) ProtoMessage() {}

func (x *NetworkUpdateParameters) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[190]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NetworkUpdateParameters.ProtoReflect.Descriptor instead.
func (*NetworkUpdateParameters) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{190}
}

func (x *NetworkUpdateParameters) GetLossLayers() []*LossLayer {
	if x != nil {
		return x.LossLayers
	}
	return nil
}

func (x *NetworkUpdateParameters) GetOptimizer() *Optimizer {
	if x != nil {
		return x.Optimizer
	}
	return nil
}

func (x *NetworkUpdateParameters) GetEpochs() *Int64Parameter {
	if x != nil {
		return x.Epochs
	}
	return nil
}

func (x *NetworkUpdateParameters) GetShuffle() *BoolParameter {
	if x != nil {
		return x.Shuffle
	}
	return nil
}

func (x *NetworkUpdateParameters) GetSeed() *Int64Parameter {
	if x != nil {
		return x.Seed
	}
	return nil
}

// Loss layer - categorical cross entropy and mean squared error are the only supported loss functions currently
type LossLayer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	Name  string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Types that are valid to be assigned to LossLayerType:
	//
	//	*LossLayer_CategoricalCrossEntropyLossLayer
	//	*LossLayer_MeanSquaredErrorLossLayer
	LossLayerType isLossLayer_LossLayerType `protobuf_oneof:"LossLayerType"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LossLayer) Reset() {
	*x = LossLayer{}
	mi := &file_NeuralNetwork_proto_msgTypes[191]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LossLayer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LossLayer) ProtoMessage() {}

func (x *LossLayer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[191]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LossLayer.ProtoReflect.Descriptor instead.
func (*LossLayer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{191}
}

func (x *LossLayer) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *LossLayer) GetLossLayerType() isLossLayer_LossLayerType {
	if x != nil {
		return x.LossLayerType
	}
	return nil
}

func (x *LossLayer) GetCategoricalCrossEntropyLossLayer() *CategoricalCrossEntropyLossLayer {
	if x != nil {
		if x, ok := x.LossLayerType.(*LossLayer_CategoricalCrossEntropyLossLayer); ok {
			return x.CategoricalCrossEntropyLossLayer
		}
	}
	return nil
}

func (x *LossLayer) GetMeanSquaredErrorLossLayer() *MeanSquaredErrorLossLayer {
	if x != nil {
		if x, ok := x.LossLayerType.(*LossLayer_MeanSquaredErrorLossLayer); ok {
			return x.MeanSquaredErrorLossLayer
		}
	}
	return nil
}

type isLossLayer_LossLayerType interface {
	isLossLayer_LossLayerType()
}

type LossLayer_CategoricalCrossEntropyLossLayer struct {
	CategoricalCrossEntropyLossLayer *CategoricalCrossEntropyLossLayer `protobuf:"bytes,10,opt,name=categoricalCrossEntropyLossLayer,proto3,oneof"`
}

type LossLayer_MeanSquaredErrorLossLayer struct {
	MeanSquaredErrorLossLayer *MeanSquaredErrorLossLayer `protobuf:"bytes,11,opt,name=meanSquaredErrorLossLayer,proto3,oneof"`
}

func (*LossLayer_CategoricalCrossEntropyLossLayer) isLossLayer_LossLayerType() {}

func (*LossLayer_MeanSquaredErrorLossLayer) isLossLayer_LossLayerType() {}

// Categorical cross entropy loss layer
// Categorical cross entropy is used for single label categorization (only one category is applicable for each data point).
//
// The input is a vector of length N representing the distribution over N categories.  It must be the output of a softmax.
//
// The target is a single value representing the true category or class label. If the target is the predictedFeatureName of a neural network classifier it will be inverse mapped to the corresponding categorical index for you.
//
// math:
// Loss_{CCE}(input, target) = -\sum_{i=1}^{N} (target == i) log( input[i] ) = - log (input[target])
type CategoricalCrossEntropyLossLayer struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Input         string                 `protobuf:"bytes,1,opt,name=input,proto3" json:"input,omitempty"`
	Target        string                 `protobuf:"bytes,2,opt,name=target,proto3" json:"target,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CategoricalCrossEntropyLossLayer) Reset() {
	*x = CategoricalCrossEntropyLossLayer{}
	mi := &file_NeuralNetwork_proto_msgTypes[192]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CategoricalCrossEntropyLossLayer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CategoricalCrossEntropyLossLayer) ProtoMessage() {}

func (x *CategoricalCrossEntropyLossLayer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[192]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CategoricalCrossEntropyLossLayer.ProtoReflect.Descriptor instead.
func (*CategoricalCrossEntropyLossLayer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{192}
}

func (x *CategoricalCrossEntropyLossLayer) GetInput() string {
	if x != nil {
		return x.Input
	}
	return ""
}

func (x *CategoricalCrossEntropyLossLayer) GetTarget() string {
	if x != nil {
		return x.Target
	}
	return ""
}

// Mean squared error loss layer,
// specifying input and target
type MeanSquaredErrorLossLayer struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Input         string                 `protobuf:"bytes,1,opt,name=input,proto3" json:"input,omitempty"`
	Target        string                 `protobuf:"bytes,2,opt,name=target,proto3" json:"target,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MeanSquaredErrorLossLayer) Reset() {
	*x = MeanSquaredErrorLossLayer{}
	mi := &file_NeuralNetwork_proto_msgTypes[193]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MeanSquaredErrorLossLayer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MeanSquaredErrorLossLayer) ProtoMessage() {}

func (x *MeanSquaredErrorLossLayer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[193]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MeanSquaredErrorLossLayer.ProtoReflect.Descriptor instead.
func (*MeanSquaredErrorLossLayer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{193}
}

func (x *MeanSquaredErrorLossLayer) GetInput() string {
	if x != nil {
		return x.Input
	}
	return ""
}

func (x *MeanSquaredErrorLossLayer) GetTarget() string {
	if x != nil {
		return x.Target
	}
	return ""
}

// Optimizer - stochastic gradient descent and adam are the only supported optimizers currently
type Optimizer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to OptimizerType:
	//
	//	*Optimizer_SgdOptimizer
	//	*Optimizer_AdamOptimizer
	OptimizerType isOptimizer_OptimizerType `protobuf_oneof:"OptimizerType"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Optimizer) Reset() {
	*x = Optimizer{}
	mi := &file_NeuralNetwork_proto_msgTypes[194]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Optimizer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Optimizer) ProtoMessage() {}

func (x *Optimizer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[194]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Optimizer.ProtoReflect.Descriptor instead.
func (*Optimizer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{194}
}

func (x *Optimizer) GetOptimizerType() isOptimizer_OptimizerType {
	if x != nil {
		return x.OptimizerType
	}
	return nil
}

func (x *Optimizer) GetSgdOptimizer() *SGDOptimizer {
	if x != nil {
		if x, ok := x.OptimizerType.(*Optimizer_SgdOptimizer); ok {
			return x.SgdOptimizer
		}
	}
	return nil
}

func (x *Optimizer) GetAdamOptimizer() *AdamOptimizer {
	if x != nil {
		if x, ok := x.OptimizerType.(*Optimizer_AdamOptimizer); ok {
			return x.AdamOptimizer
		}
	}
	return nil
}

type isOptimizer_OptimizerType interface {
	isOptimizer_OptimizerType()
}

type Optimizer_SgdOptimizer struct {
	SgdOptimizer *SGDOptimizer `protobuf:"bytes,10,opt,name=sgdOptimizer,proto3,oneof"`
}

type Optimizer_AdamOptimizer struct {
	AdamOptimizer *AdamOptimizer `protobuf:"bytes,11,opt,name=adamOptimizer,proto3,oneof"`
}

func (*Optimizer_SgdOptimizer) isOptimizer_OptimizerType() {}

func (*Optimizer_AdamOptimizer) isOptimizer_OptimizerType() {}

// Stochastic gradient descent optimizer,
// specifying configurable learning rate, mini batch size, and momentum
type SGDOptimizer struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	LearningRate  *DoubleParameter       `protobuf:"bytes,1,opt,name=learningRate,proto3" json:"learningRate,omitempty"`
	MiniBatchSize *Int64Parameter        `protobuf:"bytes,2,opt,name=miniBatchSize,proto3" json:"miniBatchSize,omitempty"`
	Momentum      *DoubleParameter       `protobuf:"bytes,3,opt,name=momentum,proto3" json:"momentum,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SGDOptimizer) Reset() {
	*x = SGDOptimizer{}
	mi := &file_NeuralNetwork_proto_msgTypes[195]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SGDOptimizer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SGDOptimizer) ProtoMessage() {}

func (x *SGDOptimizer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[195]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SGDOptimizer.ProtoReflect.Descriptor instead.
func (*SGDOptimizer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{195}
}

func (x *SGDOptimizer) GetLearningRate() *DoubleParameter {
	if x != nil {
		return x.LearningRate
	}
	return nil
}

func (x *SGDOptimizer) GetMiniBatchSize() *Int64Parameter {
	if x != nil {
		return x.MiniBatchSize
	}
	return nil
}

func (x *SGDOptimizer) GetMomentum() *DoubleParameter {
	if x != nil {
		return x.Momentum
	}
	return nil
}

// Adam optimizer,
// specifying configurable learning rate, mini batch size, betas, and eps
type AdamOptimizer struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	LearningRate  *DoubleParameter       `protobuf:"bytes,1,opt,name=learningRate,proto3" json:"learningRate,omitempty"`
	MiniBatchSize *Int64Parameter        `protobuf:"bytes,2,opt,name=miniBatchSize,proto3" json:"miniBatchSize,omitempty"`
	Beta1         *DoubleParameter       `protobuf:"bytes,3,opt,name=beta1,proto3" json:"beta1,omitempty"`
	Beta2         *DoubleParameter       `protobuf:"bytes,4,opt,name=beta2,proto3" json:"beta2,omitempty"`
	Eps           *DoubleParameter       `protobuf:"bytes,5,opt,name=eps,proto3" json:"eps,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AdamOptimizer) Reset() {
	*x = AdamOptimizer{}
	mi := &file_NeuralNetwork_proto_msgTypes[196]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AdamOptimizer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AdamOptimizer) ProtoMessage() {}

func (x *AdamOptimizer) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[196]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AdamOptimizer.ProtoReflect.Descriptor instead.
func (*AdamOptimizer) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{196}
}

func (x *AdamOptimizer) GetLearningRate() *DoubleParameter {
	if x != nil {
		return x.LearningRate
	}
	return nil
}

func (x *AdamOptimizer) GetMiniBatchSize() *Int64Parameter {
	if x != nil {
		return x.MiniBatchSize
	}
	return nil
}

func (x *AdamOptimizer) GetBeta1() *DoubleParameter {
	if x != nil {
		return x.Beta1
	}
	return nil
}

func (x *AdamOptimizer) GetBeta2() *DoubleParameter {
	if x != nil {
		return x.Beta2
	}
	return nil
}

func (x *AdamOptimizer) GetEps() *DoubleParameter {
	if x != nil {
		return x.Eps
	}
	return nil
}

type BorderAmounts_EdgeSizes struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The amount to be padded or cropped from the beginning.
	StartEdgeSize uint64 `protobuf:"varint,1,opt,name=startEdgeSize,proto3" json:"startEdgeSize,omitempty"`
	// The amount to be padded or cropped from the end.
	EndEdgeSize   uint64 `protobuf:"varint,2,opt,name=endEdgeSize,proto3" json:"endEdgeSize,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BorderAmounts_EdgeSizes) Reset() {
	*x = BorderAmounts_EdgeSizes{}
	mi := &file_NeuralNetwork_proto_msgTypes[197]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BorderAmounts_EdgeSizes) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BorderAmounts_EdgeSizes) ProtoMessage() {}

func (x *BorderAmounts_EdgeSizes) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[197]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BorderAmounts_EdgeSizes.ProtoReflect.Descriptor instead.
func (*BorderAmounts_EdgeSizes) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{35, 0}
}

func (x *BorderAmounts_EdgeSizes) GetStartEdgeSize() uint64 {
	if x != nil {
		return x.StartEdgeSize
	}
	return 0
}

func (x *BorderAmounts_EdgeSizes) GetEndEdgeSize() uint64 {
	if x != nil {
		return x.EndEdgeSize
	}
	return 0
}

type PoolingLayerParams_ValidCompletePadding struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Must be length 2 in order “[H, W]“.
	// If not set, value “[0, 0]“ is used.
	PaddingAmounts []uint64 `protobuf:"varint,10,rep,packed,name=paddingAmounts,proto3" json:"paddingAmounts,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *PoolingLayerParams_ValidCompletePadding) Reset() {
	*x = PoolingLayerParams_ValidCompletePadding{}
	mi := &file_NeuralNetwork_proto_msgTypes[198]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PoolingLayerParams_ValidCompletePadding) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PoolingLayerParams_ValidCompletePadding) ProtoMessage() {}

func (x *PoolingLayerParams_ValidCompletePadding) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[198]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PoolingLayerParams_ValidCompletePadding.ProtoReflect.Descriptor instead.
func (*PoolingLayerParams_ValidCompletePadding) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{50, 0}
}

func (x *PoolingLayerParams_ValidCompletePadding) GetPaddingAmounts() []uint64 {
	if x != nil {
		return x.PaddingAmounts
	}
	return nil
}

// Fill a constant value in the padded region.
type PaddingLayerParams_PaddingConstant struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Value         float32                `protobuf:"fixed32,1,opt,name=value,proto3" json:"value,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PaddingLayerParams_PaddingConstant) Reset() {
	*x = PaddingLayerParams_PaddingConstant{}
	mi := &file_NeuralNetwork_proto_msgTypes[199]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PaddingLayerParams_PaddingConstant) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PaddingLayerParams_PaddingConstant) ProtoMessage() {}

func (x *PaddingLayerParams_PaddingConstant) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[199]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PaddingLayerParams_PaddingConstant.ProtoReflect.Descriptor instead.
func (*PaddingLayerParams_PaddingConstant) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{53, 0}
}

func (x *PaddingLayerParams_PaddingConstant) GetValue() float32 {
	if x != nil {
		return x.Value
	}
	return 0
}

// Reflect the values at the border for padding.
type PaddingLayerParams_PaddingReflection struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PaddingLayerParams_PaddingReflection) Reset() {
	*x = PaddingLayerParams_PaddingReflection{}
	mi := &file_NeuralNetwork_proto_msgTypes[200]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PaddingLayerParams_PaddingReflection) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PaddingLayerParams_PaddingReflection) ProtoMessage() {}

func (x *PaddingLayerParams_PaddingReflection) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[200]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PaddingLayerParams_PaddingReflection.ProtoReflect.Descriptor instead.
func (*PaddingLayerParams_PaddingReflection) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{53, 1}
}

// Replicate the values at the border for padding.
type PaddingLayerParams_PaddingReplication struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PaddingLayerParams_PaddingReplication) Reset() {
	*x = PaddingLayerParams_PaddingReplication{}
	mi := &file_NeuralNetwork_proto_msgTypes[201]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PaddingLayerParams_PaddingReplication) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PaddingLayerParams_PaddingReplication) ProtoMessage() {}

func (x *PaddingLayerParams_PaddingReplication) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[201]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PaddingLayerParams_PaddingReplication.ProtoReflect.Descriptor instead.
func (*PaddingLayerParams_PaddingReplication) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{53, 2}
}

type CustomLayerParams_CustomLayerParamValue struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Value:
	//
	//	*CustomLayerParams_CustomLayerParamValue_DoubleValue
	//	*CustomLayerParams_CustomLayerParamValue_StringValue
	//	*CustomLayerParams_CustomLayerParamValue_IntValue
	//	*CustomLayerParams_CustomLayerParamValue_LongValue
	//	*CustomLayerParams_CustomLayerParamValue_BoolValue
	Value         isCustomLayerParams_CustomLayerParamValue_Value `protobuf_oneof:"value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CustomLayerParams_CustomLayerParamValue) Reset() {
	*x = CustomLayerParams_CustomLayerParamValue{}
	mi := &file_NeuralNetwork_proto_msgTypes[202]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CustomLayerParams_CustomLayerParamValue) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CustomLayerParams_CustomLayerParamValue) ProtoMessage() {}

func (x *CustomLayerParams_CustomLayerParamValue) ProtoReflect() protoreflect.Message {
	mi := &file_NeuralNetwork_proto_msgTypes[202]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CustomLayerParams_CustomLayerParamValue.ProtoReflect.Descriptor instead.
func (*CustomLayerParams_CustomLayerParamValue) Descriptor() ([]byte, []int) {
	return file_NeuralNetwork_proto_rawDescGZIP(), []int{87, 0}
}

func (x *CustomLayerParams_CustomLayerParamValue) GetValue() isCustomLayerParams_CustomLayerParamValue_Value {
	if x != nil {
		return x.Value
	}
	return nil
}

func (x *CustomLayerParams_CustomLayerParamValue) GetDoubleValue() float64 {
	if x != nil {
		if x, ok := x.Value.(*CustomLayerParams_CustomLayerParamValue_DoubleValue); ok {
			return x.DoubleValue
		}
	}
	return 0
}

func (x *CustomLayerParams_CustomLayerParamValue) GetStringValue() string {
	if x != nil {
		if x, ok := x.Value.(*CustomLayerParams_CustomLayerParamValue_StringValue); ok {
			return x.StringValue
		}
	}
	return ""
}

func (x *CustomLayerParams_CustomLayerParamValue) GetIntValue() int32 {
	if x != nil {
		if x, ok := x.Value.(*CustomLayerParams_CustomLayerParamValue_IntValue); ok {
			return x.IntValue
		}
	}
	return 0
}

func (x *CustomLayerParams_CustomLayerParamValue) GetLongValue() int64 {
	if x != nil {
		if x, ok := x.Value.(*CustomLayerParams_CustomLayerParamValue_LongValue); ok {
			return x.LongValue
		}
	}
	return 0
}

func (x *CustomLayerParams_CustomLayerParamValue) GetBoolValue() bool {
	if x != nil {
		if x, ok := x.Value.(*CustomLayerParams_CustomLayerParamValue_BoolValue); ok {
			return x.BoolValue
		}
	}
	return false
}

type isCustomLayerParams_CustomLayerParamValue_Value interface {
	isCustomLayerParams_CustomLayerParamValue_Value()
}

type CustomLayerParams_CustomLayerParamValue_DoubleValue struct {
	DoubleValue float64 `protobuf:"fixed64,10,opt,name=doubleValue,proto3,oneof"`
}

type CustomLayerParams_CustomLayerParamValue_StringValue struct {
	StringValue string `protobuf:"bytes,20,opt,name=stringValue,proto3,oneof"`
}

type CustomLayerParams_CustomLayerParamValue_IntValue struct {
	IntValue int32 `protobuf:"varint,30,opt,name=intValue,proto3,oneof"`
}

type CustomLayerParams_CustomLayerParamValue_LongValue struct {
	LongValue int64 `protobuf:"varint,40,opt,name=longValue,proto3,oneof"`
}

type CustomLayerParams_CustomLayerParamValue_BoolValue struct {
	BoolValue bool `protobuf:"varint,50,opt,name=boolValue,proto3,oneof"`
}

func (*CustomLayerParams_CustomLayerParamValue_DoubleValue) isCustomLayerParams_CustomLayerParamValue_Value() {
}

func (*CustomLayerParams_CustomLayerParamValue_StringValue) isCustomLayerParams_CustomLayerParamValue_Value() {
}

func (*CustomLayerParams_CustomLayerParamValue_IntValue) isCustomLayerParams_CustomLayerParamValue_Value() {
}

func (*CustomLayerParams_CustomLayerParamValue_LongValue) isCustomLayerParams_CustomLayerParamValue_Value() {
}

func (*CustomLayerParams_CustomLayerParamValue_BoolValue) isCustomLayerParams_CustomLayerParamValue_Value() {
}

var File_NeuralNetwork_proto protoreflect.FileDescriptor

const file_NeuralNetwork_proto_rawDesc = "" +
	"\n" +
	"\x13NeuralNetwork.proto\x12\x14CoreML.Specification\x1a\x14DataStructures.proto\x1a\x10Parameters.proto\"\xdd\x03\n" +
	"\rNeuralNetwork\x12@\n" +
	"\x06layers\x18\x01 \x03(\v2(.CoreML.Specification.NeuralNetworkLayerR\x06layers\x12V\n" +
	"\rpreprocessing\x18\x02 \x03(\v20.CoreML.Specification.NeuralNetworkPreprocessingR\rpreprocessing\x12q\n" +
	"\x16arrayInputShapeMapping\x18\x05 \x01(\x0e29.CoreML.Specification.NeuralNetworkMultiArrayShapeMappingR\x16arrayInputShapeMapping\x12l\n" +
	"\x16imageInputShapeMapping\x18\x06 \x01(\x0e24.CoreML.Specification.NeuralNetworkImageShapeMappingR\x16imageInputShapeMapping\x12Q\n" +
	"\fupdateParams\x18\n" +
	" \x01(\v2-.CoreML.Specification.NetworkUpdateParametersR\fupdateParams\"\xae\x01\n" +
	"\x18NeuralNetworkImageScaler\x12\"\n" +
	"\fchannelScale\x18\n" +
	" \x01(\x02R\fchannelScale\x12\x1a\n" +
	"\bblueBias\x18\x14 \x01(\x02R\bblueBias\x12\x1c\n" +
	"\tgreenBias\x18\x15 \x01(\x02R\tgreenBias\x12\x18\n" +
	"\aredBias\x18\x16 \x01(\x02R\aredBias\x12\x1a\n" +
	"\bgrayBias\x18\x1e \x01(\x02R\bgrayBias\"6\n" +
	"\x16NeuralNetworkMeanImage\x12\x1c\n" +
	"\tmeanImage\x18\x01 \x03(\x02R\tmeanImage\"\xe6\x01\n" +
	"\x1aNeuralNetworkPreprocessing\x12 \n" +
	"\vfeatureName\x18\x01 \x01(\tR\vfeatureName\x12H\n" +
	"\x06scaler\x18\n" +
	" \x01(\v2..CoreML.Specification.NeuralNetworkImageScalerH\x00R\x06scaler\x12L\n" +
	"\tmeanImage\x18\v \x01(\v2,.CoreML.Specification.NeuralNetworkMeanImageH\x00R\tmeanImageB\x0e\n" +
	"\fpreprocessor\"\x10\n" +
	"\x0eActivationReLU\"+\n" +
	"\x13ActivationLeakyReLU\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"\x10\n" +
	"\x0eActivationTanh\"@\n" +
	"\x14ActivationScaledTanh\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\x12\x12\n" +
	"\x04beta\x18\x02 \x01(\x02R\x04beta\"\x13\n" +
	"\x11ActivationSigmoid\"<\n" +
	"\x10ActivationLinear\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\x12\x12\n" +
	"\x04beta\x18\x02 \x01(\x02R\x04beta\"A\n" +
	"\x15ActivationSigmoidHard\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\x12\x12\n" +
	"\x04beta\x18\x02 \x01(\x02R\x04beta\"K\n" +
	"\x0fActivationPReLU\x128\n" +
	"\x05alpha\x18\x01 \x01(\v2\".CoreML.Specification.WeightParamsR\x05alpha\"%\n" +
	"\rActivationELU\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"1\n" +
	"\x19ActivationThresholdedReLU\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"\x14\n" +
	"\x12ActivationSoftsign\"\x14\n" +
	"\x12ActivationSoftplus\"\x90\x01\n" +
	"\x1cActivationParametricSoftplus\x128\n" +
	"\x05alpha\x18\x01 \x01(\v2\".CoreML.Specification.WeightParamsR\x05alpha\x126\n" +
	"\x04beta\x18\x02 \x01(\v2\".CoreML.Specification.WeightParamsR\x04beta\"\xda\a\n" +
	"\x10ActivationParams\x12@\n" +
	"\x06linear\x18\x05 \x01(\v2&.CoreML.Specification.ActivationLinearH\x00R\x06linear\x12:\n" +
	"\x04ReLU\x18\n" +
	" \x01(\v2$.CoreML.Specification.ActivationReLUH\x00R\x04ReLU\x12I\n" +
	"\tleakyReLU\x18\x0f \x01(\v2).CoreML.Specification.ActivationLeakyReLUH\x00R\tleakyReLU\x12[\n" +
	"\x0fthresholdedReLU\x18\x14 \x01(\v2/.CoreML.Specification.ActivationThresholdedReLUH\x00R\x0fthresholdedReLU\x12=\n" +
	"\x05PReLU\x18\x19 \x01(\v2%.CoreML.Specification.ActivationPReLUH\x00R\x05PReLU\x12:\n" +
	"\x04tanh\x18\x1e \x01(\v2$.CoreML.Specification.ActivationTanhH\x00R\x04tanh\x12L\n" +
	"\n" +
	"scaledTanh\x18\x1f \x01(\v2*.CoreML.Specification.ActivationScaledTanhH\x00R\n" +
	"scaledTanh\x12C\n" +
	"\asigmoid\x18( \x01(\v2'.CoreML.Specification.ActivationSigmoidH\x00R\asigmoid\x12O\n" +
	"\vsigmoidHard\x18) \x01(\v2+.CoreML.Specification.ActivationSigmoidHardH\x00R\vsigmoidHard\x127\n" +
	"\x03ELU\x182 \x01(\v2#.CoreML.Specification.ActivationELUH\x00R\x03ELU\x12F\n" +
	"\bsoftsign\x18< \x01(\v2(.CoreML.Specification.ActivationSoftsignH\x00R\bsoftsign\x12F\n" +
	"\bsoftplus\x18F \x01(\v2(.CoreML.Specification.ActivationSoftplusH\x00R\bsoftplus\x12d\n" +
	"\x12parametricSoftplus\x18G \x01(\v22.CoreML.Specification.ActivationParametricSoftplusH\x00R\x12parametricSoftplusB\x12\n" +
	"\x10NonlinearityType\"8\n" +
	"\x06Tensor\x12\x12\n" +
	"\x04rank\x18\x01 \x01(\rR\x04rank\x12\x1a\n" +
	"\bdimValue\x18\x02 \x03(\x03R\bdimValue\"\x96e\n" +
	"\x12NeuralNetworkLayer\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x14\n" +
	"\x05input\x18\x02 \x03(\tR\x05input\x12\x16\n" +
	"\x06output\x18\x03 \x03(\tR\x06output\x12>\n" +
	"\vinputTensor\x18\x04 \x03(\v2\x1c.CoreML.Specification.TensorR\vinputTensor\x12@\n" +
	"\foutputTensor\x18\x05 \x03(\v2\x1c.CoreML.Specification.TensorR\foutputTensor\x12 \n" +
	"\visUpdatable\x18\n" +
	" \x01(\bR\visUpdatable\x12P\n" +
	"\vconvolution\x18d \x01(\v2,.CoreML.Specification.ConvolutionLayerParamsH\x00R\vconvolution\x12D\n" +
	"\apooling\x18x \x01(\v2(.CoreML.Specification.PoolingLayerParamsH\x00R\apooling\x12I\n" +
	"\n" +
	"activation\x18\x82\x01 \x01(\v2&.CoreML.Specification.ActivationParamsH\x00R\n" +
	"activation\x12T\n" +
	"\finnerProduct\x18\x8c\x01 \x01(\v2-.CoreML.Specification.InnerProductLayerParamsH\x00R\finnerProduct\x12K\n" +
	"\tembedding\x18\x96\x01 \x01(\v2*.CoreML.Specification.EmbeddingLayerParamsH\x00R\tembedding\x12K\n" +
	"\tbatchnorm\x18\xa0\x01 \x01(\v2*.CoreML.Specification.BatchnormLayerParamsH\x00R\tbatchnorm\x12K\n" +
	"\x03mvn\x18\xa5\x01 \x01(\v26.CoreML.Specification.MeanVarianceNormalizeLayerParamsH\x00R\x03mvn\x12Q\n" +
	"\vl2normalize\x18\xaa\x01 \x01(\v2,.CoreML.Specification.L2NormalizeLayerParamsH\x00R\vl2normalize\x12E\n" +
	"\asoftmax\x18\xaf\x01 \x01(\v2(.CoreML.Specification.SoftmaxLayerParamsH\x00R\asoftmax\x129\n" +
	"\x03lrn\x18\xb4\x01 \x01(\v2$.CoreML.Specification.LRNLayerParamsH\x00R\x03lrn\x12<\n" +
	"\x04crop\x18\xbe\x01 \x01(\v2%.CoreML.Specification.CropLayerParamsH\x00R\x04crop\x12E\n" +
	"\apadding\x18\xc8\x01 \x01(\v2(.CoreML.Specification.PaddingLayerParamsH\x00R\apadding\x12H\n" +
	"\bupsample\x18\xd2\x01 \x01(\v2).CoreML.Specification.UpsampleLayerParamsH\x00R\bupsample\x12Z\n" +
	"\x0eresizeBilinear\x18\xd3\x01 \x01(\v2/.CoreML.Specification.ResizeBilinearLayerParamsH\x00R\x0eresizeBilinear\x12N\n" +
	"\n" +
	"cropResize\x18\xd4\x01 \x01(\v2+.CoreML.Specification.CropResizeLayerParamsH\x00R\n" +
	"cropResize\x12G\n" +
	"\x05unary\x18\xdc\x01 \x01(\v2..CoreML.Specification.UnaryFunctionLayerParamsH\x00R\x05unary\x129\n" +
	"\x03add\x18\xe6\x01 \x01(\v2$.CoreML.Specification.AddLayerParamsH\x00R\x03add\x12H\n" +
	"\bmultiply\x18\xe7\x01 \x01(\v2).CoreML.Specification.MultiplyLayerParamsH\x00R\bmultiply\x12E\n" +
	"\aaverage\x18\xf0\x01 \x01(\v2(.CoreML.Specification.AverageLayerParamsH\x00R\aaverage\x12?\n" +
	"\x05scale\x18\xf5\x01 \x01(\v2&.CoreML.Specification.ScaleLayerParamsH\x00R\x05scale\x12<\n" +
	"\x04bias\x18\xfa\x01 \x01(\v2%.CoreML.Specification.BiasLayerParamsH\x00R\x04bias\x129\n" +
	"\x03max\x18\x84\x02 \x01(\v2$.CoreML.Specification.MaxLayerParamsH\x00R\x03max\x129\n" +
	"\x03min\x18\x85\x02 \x01(\v2$.CoreML.Specification.MinLayerParamsH\x00R\x03min\x12@\n" +
	"\x03dot\x18\x8e\x02 \x01(\v2+.CoreML.Specification.DotProductLayerParamsH\x00R\x03dot\x12B\n" +
	"\x06reduce\x18\x98\x02 \x01(\v2'.CoreML.Specification.ReduceLayerParamsH\x00R\x06reduce\x12T\n" +
	"\floadConstant\x18\xa2\x02 \x01(\v2-.CoreML.Specification.LoadConstantLayerParamsH\x00R\floadConstant\x12E\n" +
	"\areshape\x18\xac\x02 \x01(\v2(.CoreML.Specification.ReshapeLayerParamsH\x00R\areshape\x12E\n" +
	"\aflatten\x18\xad\x02 \x01(\v2(.CoreML.Specification.FlattenLayerParamsH\x00R\aflatten\x12E\n" +
	"\apermute\x18\xb6\x02 \x01(\v2(.CoreML.Specification.PermuteLayerParamsH\x00R\apermute\x12B\n" +
	"\x06concat\x18\xc0\x02 \x01(\v2'.CoreML.Specification.ConcatLayerParamsH\x00R\x06concat\x12?\n" +
	"\x05split\x18\xca\x02 \x01(\v2&.CoreML.Specification.SplitLayerParamsH\x00R\x05split\x12Z\n" +
	"\x0esequenceRepeat\x18\xd4\x02 \x01(\v2/.CoreML.Specification.SequenceRepeatLayerParamsH\x00R\x0esequenceRepeat\x12Z\n" +
	"\x0ereorganizeData\x18\xd9\x02 \x01(\v2/.CoreML.Specification.ReorganizeDataLayerParamsH\x00R\x0ereorganizeData\x12?\n" +
	"\x05slice\x18\xde\x02 \x01(\v2&.CoreML.Specification.SliceLayerParamsH\x00R\x05slice\x12]\n" +
	"\x0fsimpleRecurrent\x18\x90\x03 \x01(\v20.CoreML.Specification.SimpleRecurrentLayerParamsH\x00R\x0fsimpleRecurrent\x129\n" +
	"\x03gru\x18\x9a\x03 \x01(\v2$.CoreML.Specification.GRULayerParamsH\x00R\x03gru\x12f\n" +
	"\x12uniDirectionalLSTM\x18\xa4\x03 \x01(\v23.CoreML.Specification.UniDirectionalLSTMLayerParamsH\x00R\x12uniDirectionalLSTM\x12c\n" +
	"\x11biDirectionalLSTM\x18\xae\x03 \x01(\v22.CoreML.Specification.BiDirectionalLSTMLayerParamsH\x00R\x11biDirectionalLSTM\x12B\n" +
	"\x06custom\x18\xf4\x03 \x01(\v2'.CoreML.Specification.CustomLayerParamsH\x00R\x06custom\x12<\n" +
	"\x04copy\x18\xd8\x04 \x01(\v2%.CoreML.Specification.CopyLayerParamsH\x00R\x04copy\x12B\n" +
	"\x06branch\x18\xdd\x04 \x01(\v2'.CoreML.Specification.BranchLayerParamsH\x00R\x06branch\x12<\n" +
	"\x04loop\x18\xe7\x04 \x01(\v2%.CoreML.Specification.LoopLayerParamsH\x00R\x04loop\x12K\n" +
	"\tloopBreak\x18\xec\x04 \x01(\v2*.CoreML.Specification.LoopBreakLayerParamsH\x00R\tloopBreak\x12T\n" +
	"\floopContinue\x18\xf1\x04 \x01(\v2-.CoreML.Specification.LoopContinueLayerParamsH\x00R\floopContinue\x12Q\n" +
	"\vrangeStatic\x18\xfb\x04 \x01(\v2,.CoreML.Specification.RangeStaticLayerParamsH\x00R\vrangeStatic\x12T\n" +
	"\frangeDynamic\x18\x80\x05 \x01(\v2-.CoreML.Specification.RangeDynamicLayerParamsH\x00R\frangeDynamic\x12<\n" +
	"\x04clip\x18\x94\x05 \x01(\v2%.CoreML.Specification.ClipLayerParamsH\x00R\x04clip\x12<\n" +
	"\x04ceil\x18\x99\x05 \x01(\v2%.CoreML.Specification.CeilLayerParamsH\x00R\x04ceil\x12?\n" +
	"\x05floor\x18\x9e\x05 \x01(\v2&.CoreML.Specification.FloorLayerParamsH\x00R\x05floor\x12<\n" +
	"\x04sign\x18\xa8\x05 \x01(\v2%.CoreML.Specification.SignLayerParamsH\x00R\x04sign\x12?\n" +
	"\x05round\x18\xad\x05 \x01(\v2&.CoreML.Specification.RoundLayerParamsH\x00R\x05round\x12<\n" +
	"\x04exp2\x18\xbc\x05 \x01(\v2%.CoreML.Specification.Exp2LayerParamsH\x00R\x04exp2\x129\n" +
	"\x03sin\x18\xc6\x05 \x01(\v2$.CoreML.Specification.SinLayerParamsH\x00R\x03sin\x129\n" +
	"\x03cos\x18\xcb\x05 \x01(\v2$.CoreML.Specification.CosLayerParamsH\x00R\x03cos\x129\n" +
	"\x03tan\x18\xd0\x05 \x01(\v2$.CoreML.Specification.TanLayerParamsH\x00R\x03tan\x12<\n" +
	"\x04asin\x18\xda\x05 \x01(\v2%.CoreML.Specification.AsinLayerParamsH\x00R\x04asin\x12<\n" +
	"\x04acos\x18\xdf\x05 \x01(\v2%.CoreML.Specification.AcosLayerParamsH\x00R\x04acos\x12<\n" +
	"\x04atan\x18\xe4\x05 \x01(\v2%.CoreML.Specification.AtanLayerParamsH\x00R\x04atan\x12<\n" +
	"\x04sinh\x18\xee\x05 \x01(\v2%.CoreML.Specification.SinhLayerParamsH\x00R\x04sinh\x12<\n" +
	"\x04cosh\x18\xf3\x05 \x01(\v2%.CoreML.Specification.CoshLayerParamsH\x00R\x04cosh\x12<\n" +
	"\x04tanh\x18\xf8\x05 \x01(\v2%.CoreML.Specification.TanhLayerParamsH\x00R\x04tanh\x12?\n" +
	"\x05asinh\x18\x82\x06 \x01(\v2&.CoreML.Specification.AsinhLayerParamsH\x00R\x05asinh\x12?\n" +
	"\x05acosh\x18\x87\x06 \x01(\v2&.CoreML.Specification.AcoshLayerParamsH\x00R\x05acosh\x12?\n" +
	"\x05atanh\x18\x8c\x06 \x01(\v2&.CoreML.Specification.AtanhLayerParamsH\x00R\x05atanh\x129\n" +
	"\x03erf\x18\x96\x06 \x01(\v2$.CoreML.Specification.ErfLayerParamsH\x00R\x03erf\x12<\n" +
	"\x04gelu\x18\x9b\x06 \x01(\v2%.CoreML.Specification.GeluLayerParamsH\x00R\x04gelu\x12?\n" +
	"\x05equal\x18\xaf\x06 \x01(\v2&.CoreML.Specification.EqualLayerParamsH\x00R\x05equal\x12H\n" +
	"\bnotEqual\x18\xb4\x06 \x01(\v2).CoreML.Specification.NotEqualLayerParamsH\x00R\bnotEqual\x12H\n" +
	"\blessThan\x18\xb9\x06 \x01(\v2).CoreML.Specification.LessThanLayerParamsH\x00R\blessThan\x12K\n" +
	"\tlessEqual\x18\xbb\x06 \x01(\v2*.CoreML.Specification.LessEqualLayerParamsH\x00R\tlessEqual\x12Q\n" +
	"\vgreaterThan\x18\xbe\x06 \x01(\v2,.CoreML.Specification.GreaterThanLayerParamsH\x00R\vgreaterThan\x12T\n" +
	"\fgreaterEqual\x18\xc0\x06 \x01(\v2-.CoreML.Specification.GreaterEqualLayerParamsH\x00R\fgreaterEqual\x12K\n" +
	"\tlogicalOr\x18\xc8\x06 \x01(\v2*.CoreML.Specification.LogicalOrLayerParamsH\x00R\tlogicalOr\x12N\n" +
	"\n" +
	"logicalXor\x18\xcd\x06 \x01(\v2+.CoreML.Specification.LogicalXorLayerParamsH\x00R\n" +
	"logicalXor\x12N\n" +
	"\n" +
	"logicalNot\x18\xd2\x06 \x01(\v2+.CoreML.Specification.LogicalNotLayerParamsH\x00R\n" +
	"logicalNot\x12N\n" +
	"\n" +
	"logicalAnd\x18\xd7\x06 \x01(\v2+.CoreML.Specification.LogicalAndLayerParamsH\x00R\n" +
	"logicalAnd\x12`\n" +
	"\x10modBroadcastable\x18\xe1\x06 \x01(\v21.CoreML.Specification.ModBroadcastableLayerParamsH\x00R\x10modBroadcastable\x12`\n" +
	"\x10minBroadcastable\x18\xe6\x06 \x01(\v21.CoreML.Specification.MinBroadcastableLayerParamsH\x00R\x10minBroadcastable\x12`\n" +
	"\x10maxBroadcastable\x18\xeb\x06 \x01(\v21.CoreML.Specification.MaxBroadcastableLayerParamsH\x00R\x10maxBroadcastable\x12`\n" +
	"\x10addBroadcastable\x18\xf0\x06 \x01(\v21.CoreML.Specification.AddBroadcastableLayerParamsH\x00R\x10addBroadcastable\x12`\n" +
	"\x10powBroadcastable\x18\xf5\x06 \x01(\v21.CoreML.Specification.PowBroadcastableLayerParamsH\x00R\x10powBroadcastable\x12i\n" +
	"\x13divideBroadcastable\x18\xfa\x06 \x01(\v24.CoreML.Specification.DivideBroadcastableLayerParamsH\x00R\x13divideBroadcastable\x12o\n" +
	"\x15floorDivBroadcastable\x18\xff\x06 \x01(\v26.CoreML.Specification.FloorDivBroadcastableLayerParamsH\x00R\x15floorDivBroadcastable\x12o\n" +
	"\x15multiplyBroadcastable\x18\x84\a \x01(\v26.CoreML.Specification.MultiplyBroadcastableLayerParamsH\x00R\x15multiplyBroadcastable\x12o\n" +
	"\x15subtractBroadcastable\x18\x89\a \x01(\v26.CoreML.Specification.SubtractBroadcastableLayerParamsH\x00R\x15subtractBroadcastable\x12<\n" +
	"\x04tile\x18\x98\a \x01(\v2%.CoreML.Specification.TileLayerParamsH\x00R\x04tile\x12?\n" +
	"\x05stack\x18\x9d\a \x01(\v2&.CoreML.Specification.StackLayerParamsH\x00R\x05stack\x12B\n" +
	"\x06gather\x18\xa2\a \x01(\v2'.CoreML.Specification.GatherLayerParamsH\x00R\x06gather\x12E\n" +
	"\ascatter\x18\xa7\a \x01(\v2(.CoreML.Specification.ScatterLayerParamsH\x00R\ascatter\x12H\n" +
	"\bgatherND\x18\xac\a \x01(\v2).CoreML.Specification.GatherNDLayerParamsH\x00R\bgatherND\x12K\n" +
	"\tscatterND\x18\xb1\a \x01(\v2*.CoreML.Specification.ScatterNDLayerParamsH\x00R\tscatterND\x12K\n" +
	"\tsoftmaxND\x18\xb6\a \x01(\v2*.CoreML.Specification.SoftmaxNDLayerParamsH\x00R\tsoftmaxND\x12]\n" +
	"\x0fgatherAlongAxis\x18\xb8\a \x01(\v20.CoreML.Specification.GatherAlongAxisLayerParamsH\x00R\x0fgatherAlongAxis\x12`\n" +
	"\x10scatterAlongAxis\x18\xba\a \x01(\v21.CoreML.Specification.ScatterAlongAxisLayerParamsH\x00R\x10scatterAlongAxis\x12E\n" +
	"\areverse\x18\xc0\a \x01(\v2(.CoreML.Specification.ReverseLayerParamsH\x00R\areverse\x12N\n" +
	"\n" +
	"reverseSeq\x18\xc5\a \x01(\v2+.CoreML.Specification.ReverseSeqLayerParamsH\x00R\n" +
	"reverseSeq\x12E\n" +
	"\asplitND\x18\xcf\a \x01(\v2(.CoreML.Specification.SplitNDLayerParamsH\x00R\asplitND\x12H\n" +
	"\bconcatND\x18\xd4\a \x01(\v2).CoreML.Specification.ConcatNDLayerParamsH\x00R\bconcatND\x12K\n" +
	"\ttranspose\x18\xd9\a \x01(\v2*.CoreML.Specification.TransposeLayerParamsH\x00R\ttranspose\x12Q\n" +
	"\vsliceStatic\x18\xe3\a \x01(\v2,.CoreML.Specification.SliceStaticLayerParamsH\x00R\vsliceStatic\x12T\n" +
	"\fsliceDynamic\x18\xe8\a \x01(\v2-.CoreML.Specification.SliceDynamicLayerParamsH\x00R\fsliceDynamic\x12Z\n" +
	"\x0eslidingWindows\x18\xed\a \x01(\v2/.CoreML.Specification.SlidingWindowsLayerParamsH\x00R\x0eslidingWindows\x12<\n" +
	"\x04topK\x18\xf7\a \x01(\v2%.CoreML.Specification.TopKLayerParamsH\x00R\x04topK\x12B\n" +
	"\x06argMin\x18\xfc\a \x01(\v2'.CoreML.Specification.ArgMinLayerParamsH\x00R\x06argMin\x12B\n" +
	"\x06argMax\x18\x81\b \x01(\v2'.CoreML.Specification.ArgMaxLayerParamsH\x00R\x06argMax\x12Q\n" +
	"\vembeddingND\x18\x90\b \x01(\v2,.CoreML.Specification.EmbeddingNDLayerParamsH\x00R\vembeddingND\x12W\n" +
	"\rbatchedMatmul\x18\x95\b \x01(\v2..CoreML.Specification.BatchedMatMulLayerParamsH\x00R\rbatchedMatmul\x12H\n" +
	"\bgetShape\x18\xa9\b \x01(\v2).CoreML.Specification.GetShapeLayerParamsH\x00R\bgetShape\x12Z\n" +
	"\x0eloadConstantND\x18\xae\b \x01(\v2/.CoreML.Specification.LoadConstantNDLayerParamsH\x00R\x0eloadConstantND\x12H\n" +
	"\bfillLike\x18\xb8\b \x01(\v2).CoreML.Specification.FillLikeLayerParamsH\x00R\bfillLike\x12N\n" +
	"\n" +
	"fillStatic\x18\xbd\b \x01(\v2+.CoreML.Specification.FillStaticLayerParamsH\x00R\n" +
	"fillStatic\x12Q\n" +
	"\vfillDynamic\x18\xc2\b \x01(\v2,.CoreML.Specification.FillDynamicLayerParamsH\x00R\vfillDynamic\x12]\n" +
	"\x0fbroadcastToLike\x18\xcc\b \x01(\v20.CoreML.Specification.BroadcastToLikeLayerParamsH\x00R\x0fbroadcastToLike\x12c\n" +
	"\x11broadcastToStatic\x18\xd1\b \x01(\v22.CoreML.Specification.BroadcastToStaticLayerParamsH\x00R\x11broadcastToStatic\x12f\n" +
	"\x12broadcastToDynamic\x18\xd6\b \x01(\v23.CoreML.Specification.BroadcastToDynamicLayerParamsH\x00R\x12broadcastToDynamic\x12E\n" +
	"\asqueeze\x18\xe0\b \x01(\v2(.CoreML.Specification.SqueezeLayerParamsH\x00R\asqueeze\x12N\n" +
	"\n" +
	"expandDims\x18\xe5\b \x01(\v2+.CoreML.Specification.ExpandDimsLayerParamsH\x00R\n" +
	"expandDims\x12Q\n" +
	"\vflattenTo2D\x18\xea\b \x01(\v2,.CoreML.Specification.FlattenTo2DLayerParamsH\x00R\vflattenTo2D\x12Q\n" +
	"\vreshapeLike\x18\xef\b \x01(\v2,.CoreML.Specification.ReshapeLikeLayerParamsH\x00R\vreshapeLike\x12W\n" +
	"\rreshapeStatic\x18\xf4\b \x01(\v2..CoreML.Specification.ReshapeStaticLayerParamsH\x00R\rreshapeStatic\x12Z\n" +
	"\x0ereshapeDynamic\x18\xf9\b \x01(\v2/.CoreML.Specification.ReshapeDynamicLayerParamsH\x00R\x0ereshapeDynamic\x12o\n" +
	"\x15rankPreservingReshape\x18\xfe\b \x01(\v26.CoreML.Specification.RankPreservingReshapeLayerParamsH\x00R\x15rankPreservingReshape\x12U\n" +
	"\vconstantPad\x18\x83\t \x01(\v20.CoreML.Specification.ConstantPaddingLayerParamsH\x00R\vconstantPad\x12`\n" +
	"\x10randomNormalLike\x18\x92\t \x01(\v21.CoreML.Specification.RandomNormalLikeLayerParamsH\x00R\x10randomNormalLike\x12f\n" +
	"\x12randomNormalStatic\x18\x97\t \x01(\v23.CoreML.Specification.RandomNormalStaticLayerParamsH\x00R\x12randomNormalStatic\x12i\n" +
	"\x13randomNormalDynamic\x18\x9c\t \x01(\v24.CoreML.Specification.RandomNormalDynamicLayerParamsH\x00R\x13randomNormalDynamic\x12c\n" +
	"\x11randomUniformLike\x18\xa6\t \x01(\v22.CoreML.Specification.RandomUniformLikeLayerParamsH\x00R\x11randomUniformLike\x12i\n" +
	"\x13randomUniformStatic\x18\xab\t \x01(\v24.CoreML.Specification.RandomUniformStaticLayerParamsH\x00R\x13randomUniformStatic\x12l\n" +
	"\x14randomUniformDynamic\x18\xb0\t \x01(\v25.CoreML.Specification.RandomUniformDynamicLayerParamsH\x00R\x14randomUniformDynamic\x12i\n" +
	"\x13randomBernoulliLike\x18\xba\t \x01(\v24.CoreML.Specification.RandomBernoulliLikeLayerParamsH\x00R\x13randomBernoulliLike\x12o\n" +
	"\x15randomBernoulliStatic\x18\xbf\t \x01(\v26.CoreML.Specification.RandomBernoulliStaticLayerParamsH\x00R\x15randomBernoulliStatic\x12r\n" +
	"\x16randomBernoulliDynamic\x18\xc4\t \x01(\v27.CoreML.Specification.RandomBernoulliDynamicLayerParamsH\x00R\x16randomBernoulliDynamic\x12u\n" +
	"\x17categoricalDistribution\x18\xce\t \x01(\v28.CoreML.Specification.CategoricalDistributionLayerParamsH\x00R\x17categoricalDistribution\x12H\n" +
	"\breduceL1\x18\xe2\t \x01(\v2).CoreML.Specification.ReduceL1LayerParamsH\x00R\breduceL1\x12H\n" +
	"\breduceL2\x18\xe7\t \x01(\v2).CoreML.Specification.ReduceL2LayerParamsH\x00R\breduceL2\x12K\n" +
	"\treduceMax\x18\xec\t \x01(\v2*.CoreML.Specification.ReduceMaxLayerParamsH\x00R\treduceMax\x12K\n" +
	"\treduceMin\x18\xf1\t \x01(\v2*.CoreML.Specification.ReduceMinLayerParamsH\x00R\treduceMin\x12K\n" +
	"\treduceSum\x18\xf6\t \x01(\v2*.CoreML.Specification.ReduceSumLayerParamsH\x00R\treduceSum\x12N\n" +
	"\n" +
	"reduceProd\x18\xfb\t \x01(\v2+.CoreML.Specification.ReduceProdLayerParamsH\x00R\n" +
	"reduceProd\x12N\n" +
	"\n" +
	"reduceMean\x18\x80\n" +
	" \x01(\v2+.CoreML.Specification.ReduceMeanLayerParamsH\x00R\n" +
	"reduceMean\x12T\n" +
	"\freduceLogSum\x18\x85\n" +
	" \x01(\v2-.CoreML.Specification.ReduceLogSumLayerParamsH\x00R\freduceLogSum\x12]\n" +
	"\x0freduceSumSquare\x18\x8a\n" +
	" \x01(\v20.CoreML.Specification.ReduceSumSquareLayerParamsH\x00R\x0freduceSumSquare\x12]\n" +
	"\x0freduceLogSumExp\x18\x8f\n" +
	" \x01(\v20.CoreML.Specification.ReduceLogSumExpLayerParamsH\x00R\x0freduceLogSumExp\x12T\n" +
	"\fwhereNonZero\x18\xa1\n" +
	" \x01(\v2-.CoreML.Specification.WhereNonZeroLayerParamsH\x00R\fwhereNonZero\x12Z\n" +
	"\x0ematrixBandPart\x18\xa3\n" +
	" \x01(\v2/.CoreML.Specification.MatrixBandPartLayerParamsH\x00R\x0ematrixBandPart\x12]\n" +
	"\x0flowerTriangular\x18\xa8\n" +
	" \x01(\v20.CoreML.Specification.LowerTriangularLayerParamsH\x00R\x0flowerTriangular\x12]\n" +
	"\x0fupperTriangular\x18\xad\n" +
	" \x01(\v20.CoreML.Specification.UpperTriangularLayerParamsH\x00R\x0fupperTriangular\x12f\n" +
	"\x12whereBroadcastable\x18\xb2\n" +
	" \x01(\v23.CoreML.Specification.WhereBroadcastableLayerParamsH\x00R\x12whereBroadcastable\x12f\n" +
	"\x12layerNormalization\x18\xc6\n" +
	" \x01(\v23.CoreML.Specification.LayerNormalizationLayerParamsH\x00R\x12layerNormalization\x12o\n" +
	"\x15NonMaximumSuppression\x18\xf8\n" +
	" \x01(\v26.CoreML.Specification.NonMaximumSuppressionLayerParamsH\x00R\x15NonMaximumSuppression\x12B\n" +
	"\x06oneHot\x18\xaa\v \x01(\v2'.CoreML.Specification.OneHotLayerParamsH\x00R\x06oneHot\x12B\n" +
	"\x06cumSum\x18\xaf\v \x01(\v2'.CoreML.Specification.CumSumLayerParamsH\x00R\x06cumSum\x12Q\n" +
	"\vclampedReLU\x18\xb4\v \x01(\v2,.CoreML.Specification.ClampedReLULayerParamsH\x00R\vclampedReLU\x12E\n" +
	"\aargSort\x18\xb5\v \x01(\v2(.CoreML.Specification.ArgSortLayerParamsH\x00R\aargSort\x12K\n" +
	"\tpooling3d\x18\xb9\v \x01(\v2*.CoreML.Specification.Pooling3DLayerParamsH\x00R\tpooling3d\x12]\n" +
	"\x0fglobalPooling3d\x18\xba\v \x01(\v20.CoreML.Specification.GlobalPooling3DLayerParamsH\x00R\x0fglobalPooling3d\x12Q\n" +
	"\vsliceBySize\x18\xbe\v \x01(\v2,.CoreML.Specification.SliceBySizeLayerParamsH\x00R\vsliceBySize\x12W\n" +
	"\rconvolution3d\x18\xbf\v \x01(\v2..CoreML.Specification.Convolution3DLayerParamsH\x00R\rconvolution3dB\a\n" +
	"\x05layer\"\x99\x01\n" +
	"\x11BranchLayerParams\x12?\n" +
	"\bifBranch\x18\x01 \x01(\v2#.CoreML.Specification.NeuralNetworkR\bifBranch\x12C\n" +
	"\n" +
	"elseBranch\x18\x02 \x01(\v2#.CoreML.Specification.NeuralNetworkR\n" +
	"elseBranch\"\xfb\x01\n" +
	"\x0fLoopLayerParams\x12,\n" +
	"\x11maxLoopIterations\x18\x01 \x01(\x04R\x11maxLoopIterations\x12\"\n" +
	"\fconditionVar\x18\x02 \x01(\tR\fconditionVar\x12O\n" +
	"\x10conditionNetwork\x18\x03 \x01(\v2#.CoreML.Specification.NeuralNetworkR\x10conditionNetwork\x12E\n" +
	"\vbodyNetwork\x18\x04 \x01(\v2#.CoreML.Specification.NeuralNetworkR\vbodyNetwork\"\x16\n" +
	"\x14LoopBreakLayerParams\"\x19\n" +
	"\x17LoopContinueLayerParams\"\x11\n" +
	"\x0fCopyLayerParams\".\n" +
	"\x16GreaterThanLayerParams\x12\x14\n" +
	"\x05alpha\x18\x02 \x01(\x02R\x05alpha\"/\n" +
	"\x17GreaterEqualLayerParams\x12\x14\n" +
	"\x05alpha\x18\x02 \x01(\x02R\x05alpha\"+\n" +
	"\x13LessThanLayerParams\x12\x14\n" +
	"\x05alpha\x18\x02 \x01(\x02R\x05alpha\",\n" +
	"\x14LessEqualLayerParams\x12\x14\n" +
	"\x05alpha\x18\x02 \x01(\x02R\x05alpha\"(\n" +
	"\x10EqualLayerParams\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"+\n" +
	"\x13NotEqualLayerParams\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"\x17\n" +
	"\x15LogicalAndLayerParams\"\x16\n" +
	"\x14LogicalOrLayerParams\"\x17\n" +
	"\x15LogicalXorLayerParams\"\x17\n" +
	"\x15LogicalNotLayerParams\"\xb9\x01\n" +
	"\rBorderAmounts\x12S\n" +
	"\rborderAmounts\x18\n" +
	" \x03(\v2-.CoreML.Specification.BorderAmounts.EdgeSizesR\rborderAmounts\x1aS\n" +
	"\tEdgeSizes\x12$\n" +
	"\rstartEdgeSize\x18\x01 \x01(\x04R\rstartEdgeSize\x12 \n" +
	"\vendEdgeSize\x18\x02 \x01(\x04R\vendEdgeSize\"[\n" +
	"\fValidPadding\x12K\n" +
	"\x0epaddingAmounts\x18\x01 \x01(\v2#.CoreML.Specification.BorderAmountsR\x0epaddingAmounts\"\xa5\x01\n" +
	"\vSamePadding\x12W\n" +
	"\rasymmetryMode\x18\x01 \x01(\x0e21.CoreML.Specification.SamePadding.SamePaddingModeR\rasymmetryMode\"=\n" +
	"\x0fSamePaddingMode\x12\x16\n" +
	"\x12BOTTOM_RIGHT_HEAVY\x10\x00\x12\x12\n" +
	"\x0eTOP_LEFT_HEAVY\x10\x01\"\xcd\x01\n" +
	"\fSamplingMode\x12Q\n" +
	"\x0esamplingMethod\x18\x01 \x01(\x0e2).CoreML.Specification.SamplingMode.MethodR\x0esamplingMethod\"j\n" +
	"\x06Method\x12\x1f\n" +
	"\x1bSTRICT_ALIGN_ENDPOINTS_MODE\x10\x00\x12\x18\n" +
	"\x14ALIGN_ENDPOINTS_MODE\x10\x01\x12\x11\n" +
	"\rUPSAMPLE_MODE\x10\x02\x12\x12\n" +
	"\x0eROI_ALIGN_MODE\x10\x03\"\xe1\x01\n" +
	"\x12BoxCoordinatesMode\x12N\n" +
	"\aboxMode\x18\x01 \x01(\x0e24.CoreML.Specification.BoxCoordinatesMode.CoordinatesR\aboxMode\"{\n" +
	"\vCoordinates\x12\x18\n" +
	"\x14CORNERS_HEIGHT_FIRST\x10\x00\x12\x17\n" +
	"\x13CORNERS_WIDTH_FIRST\x10\x01\x12\x1c\n" +
	"\x18CENTER_SIZE_HEIGHT_FIRST\x10\x02\x12\x1b\n" +
	"\x17CENTER_SIZE_WIDTH_FIRST\x10\x03\"\x82\x02\n" +
	"\fWeightParams\x12\x1e\n" +
	"\n" +
	"floatValue\x18\x01 \x03(\x02R\n" +
	"floatValue\x12\"\n" +
	"\ffloat16Value\x18\x02 \x01(\fR\ffloat16Value\x12\x1a\n" +
	"\brawValue\x18\x1e \x01(\fR\brawValue\x12\"\n" +
	"\fint8RawValue\x18\x1f \x01(\fR\fint8RawValue\x12L\n" +
	"\fquantization\x18( \x01(\v2(.CoreML.Specification.QuantizationParamsR\fquantization\x12 \n" +
	"\visUpdatable\x182 \x01(\bR\visUpdatable\"\x9f\x02\n" +
	"\x12QuantizationParams\x12\"\n" +
	"\fnumberOfBits\x18\x01 \x01(\x04R\fnumberOfBits\x12`\n" +
	"\x12linearQuantization\x18e \x01(\v2..CoreML.Specification.LinearQuantizationParamsH\x00R\x12linearQuantization\x12o\n" +
	"\x17lookupTableQuantization\x18f \x01(\v23.CoreML.Specification.LookUpTableQuantizationParamsH\x00R\x17lookupTableQuantizationB\x12\n" +
	"\x10QuantizationType\"D\n" +
	"\x18LinearQuantizationParams\x12\x14\n" +
	"\x05scale\x18\x01 \x03(\x02R\x05scale\x12\x12\n" +
	"\x04bias\x18\x02 \x03(\x02R\x04bias\"?\n" +
	"\x1dLookUpTableQuantizationParams\x12\x1e\n" +
	"\n" +
	"floatValue\x18\x01 \x03(\x02R\n" +
	"floatValue\"\xcd\x04\n" +
	"\x16ConvolutionLayerParams\x12&\n" +
	"\x0eoutputChannels\x18\x01 \x01(\x04R\x0eoutputChannels\x12&\n" +
	"\x0ekernelChannels\x18\x02 \x01(\x04R\x0ekernelChannels\x12\x18\n" +
	"\anGroups\x18\n" +
	" \x01(\x04R\anGroups\x12\x1e\n" +
	"\n" +
	"kernelSize\x18\x14 \x03(\x04R\n" +
	"kernelSize\x12\x16\n" +
	"\x06stride\x18\x1e \x03(\x04R\x06stride\x12&\n" +
	"\x0edilationFactor\x18( \x03(\x04R\x0edilationFactor\x12:\n" +
	"\x05valid\x182 \x01(\v2\".CoreML.Specification.ValidPaddingH\x00R\x05valid\x127\n" +
	"\x04same\x183 \x01(\v2!.CoreML.Specification.SamePaddingH\x00R\x04same\x12(\n" +
	"\x0fisDeconvolution\x18< \x01(\bR\x0fisDeconvolution\x12\x18\n" +
	"\ahasBias\x18F \x01(\bR\ahasBias\x12<\n" +
	"\aweights\x18Z \x01(\v2\".CoreML.Specification.WeightParamsR\aweights\x126\n" +
	"\x04bias\x18[ \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\x12 \n" +
	"\voutputShape\x18d \x03(\x04R\voutputShapeB\x18\n" +
	"\x16ConvolutionPaddingType\"\xca\b\n" +
	"\x18Convolution3DLayerParams\x12&\n" +
	"\x0eoutputChannels\x18\x01 \x01(\x05R\x0eoutputChannels\x12$\n" +
	"\rinputChannels\x18\x02 \x01(\x05R\rinputChannels\x12\x18\n" +
	"\anGroups\x18\n" +
	" \x01(\x05R\anGroups\x12 \n" +
	"\vkernelDepth\x18\x14 \x01(\x05R\vkernelDepth\x12\"\n" +
	"\fkernelHeight\x18\x15 \x01(\x05R\fkernelHeight\x12 \n" +
	"\vkernelWidth\x18\x16 \x01(\x05R\vkernelWidth\x12 \n" +
	"\vstrideDepth\x18\x1f \x01(\x05R\vstrideDepth\x12\"\n" +
	"\fstrideHeight\x18  \x01(\x05R\fstrideHeight\x12 \n" +
	"\vstrideWidth\x18! \x01(\x05R\vstrideWidth\x12$\n" +
	"\rdilationDepth\x18( \x01(\x05R\rdilationDepth\x12&\n" +
	"\x0edilationHeight\x18) \x01(\x05R\x0edilationHeight\x12$\n" +
	"\rdilationWidth\x18* \x01(\x05R\rdilationWidth\x12\x18\n" +
	"\ahasBias\x182 \x01(\bR\ahasBias\x12<\n" +
	"\aweights\x18< \x01(\v2\".CoreML.Specification.WeightParamsR\aweights\x126\n" +
	"\x04bias\x18= \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\x12\\\n" +
	"\vpaddingType\x18F \x01(\x0e2:.CoreML.Specification.Convolution3DLayerParams.PaddingTypeR\vpaddingType\x12.\n" +
	"\x12customPaddingFront\x18P \x01(\x05R\x12customPaddingFront\x12,\n" +
	"\x11customPaddingBack\x18Q \x01(\x05R\x11customPaddingBack\x12*\n" +
	"\x10customPaddingTop\x18R \x01(\x05R\x10customPaddingTop\x120\n" +
	"\x13customPaddingBottom\x18S \x01(\x05R\x13customPaddingBottom\x12,\n" +
	"\x11customPaddingLeft\x18T \x01(\x05R\x11customPaddingLeft\x12.\n" +
	"\x12customPaddingRight\x18U \x01(\x05R\x12customPaddingRight\x12(\n" +
	"\x0fisDeconvolution\x18V \x01(\bR\x0fisDeconvolution\x12 \n" +
	"\voutputShape\x18W \x03(\x04R\voutputShape\".\n" +
	"\vPaddingType\x12\n" +
	"\n" +
	"\x06CUSTOM\x10\x00\x12\t\n" +
	"\x05VALID\x10\x01\x12\b\n" +
	"\x04SAME\x10\x02\"\xa9\x02\n" +
	"\x17InnerProductLayerParams\x12$\n" +
	"\rinputChannels\x18\x01 \x01(\x04R\rinputChannels\x12&\n" +
	"\x0eoutputChannels\x18\x02 \x01(\x04R\x0eoutputChannels\x12\x18\n" +
	"\ahasBias\x18\n" +
	" \x01(\bR\ahasBias\x12<\n" +
	"\aweights\x18\x14 \x01(\v2\".CoreML.Specification.WeightParamsR\aweights\x126\n" +
	"\x04bias\x18\x15 \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\x120\n" +
	"\x13int8DynamicQuantize\x18\x16 \x01(\bR\x13int8DynamicQuantize\"\xea\x01\n" +
	"\x14EmbeddingLayerParams\x12\x1a\n" +
	"\binputDim\x18\x01 \x01(\x04R\binputDim\x12&\n" +
	"\x0eoutputChannels\x18\x02 \x01(\x04R\x0eoutputChannels\x12\x18\n" +
	"\ahasBias\x18\n" +
	" \x01(\bR\ahasBias\x12<\n" +
	"\aweights\x18\x14 \x01(\v2\".CoreML.Specification.WeightParamsR\aweights\x126\n" +
	"\x04bias\x18\x15 \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\"\xec\x01\n" +
	"\x16EmbeddingNDLayerParams\x12\x1c\n" +
	"\tvocabSize\x18\x01 \x01(\x04R\tvocabSize\x12$\n" +
	"\rembeddingSize\x18\x02 \x01(\x04R\rembeddingSize\x12\x18\n" +
	"\ahasBias\x18\x03 \x01(\bR\ahasBias\x12<\n" +
	"\aweights\x18\x14 \x01(\v2\".CoreML.Specification.WeightParamsR\aweights\x126\n" +
	"\x04bias\x18\x15 \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\"\x94\x03\n" +
	"\x14BatchnormLayerParams\x12\x1a\n" +
	"\bchannels\x18\x01 \x01(\x04R\bchannels\x12&\n" +
	"\x0ecomputeMeanVar\x18\x05 \x01(\bR\x0ecomputeMeanVar\x124\n" +
	"\x15instanceNormalization\x18\x06 \x01(\bR\x15instanceNormalization\x12\x18\n" +
	"\aepsilon\x18\n" +
	" \x01(\x02R\aepsilon\x128\n" +
	"\x05gamma\x18\x0f \x01(\v2\".CoreML.Specification.WeightParamsR\x05gamma\x126\n" +
	"\x04beta\x18\x10 \x01(\v2\".CoreML.Specification.WeightParamsR\x04beta\x126\n" +
	"\x04mean\x18\x11 \x01(\v2\".CoreML.Specification.WeightParamsR\x04mean\x12>\n" +
	"\bvariance\x18\x12 \x01(\v2\".CoreML.Specification.WeightParamsR\bvariance\"\xd7\x04\n" +
	"\x12PoolingLayerParams\x12H\n" +
	"\x04type\x18\x01 \x01(\x0e24.CoreML.Specification.PoolingLayerParams.PoolingTypeR\x04type\x12\x1e\n" +
	"\n" +
	"kernelSize\x18\n" +
	" \x03(\x04R\n" +
	"kernelSize\x12\x16\n" +
	"\x06stride\x18\x14 \x03(\x04R\x06stride\x12:\n" +
	"\x05valid\x18\x1e \x01(\v2\".CoreML.Specification.ValidPaddingH\x00R\x05valid\x127\n" +
	"\x04same\x18\x1f \x01(\v2!.CoreML.Specification.SamePaddingH\x00R\x04same\x12k\n" +
	"\x10includeLastPixel\x18  \x01(\v2=.CoreML.Specification.PoolingLayerParams.ValidCompletePaddingH\x00R\x10includeLastPixel\x124\n" +
	"\x15avgPoolExcludePadding\x182 \x01(\bR\x15avgPoolExcludePadding\x12$\n" +
	"\rglobalPooling\x18< \x01(\bR\rglobalPooling\x1a>\n" +
	"\x14ValidCompletePadding\x12&\n" +
	"\x0epaddingAmounts\x18\n" +
	" \x03(\x04R\x0epaddingAmounts\"+\n" +
	"\vPoolingType\x12\a\n" +
	"\x03MAX\x10\x00\x12\v\n" +
	"\aAVERAGE\x10\x01\x12\x06\n" +
	"\x02L2\x10\x02B\x14\n" +
	"\x12PoolingPaddingType\"\xc3\x06\n" +
	"\x14Pooling3DLayerParams\x12L\n" +
	"\x04type\x18\x01 \x01(\x0e28.CoreML.Specification.Pooling3DLayerParams.PoolingType3DR\x04type\x12 \n" +
	"\vkernelDepth\x18\x02 \x01(\x05R\vkernelDepth\x12\"\n" +
	"\fkernelHeight\x18\x03 \x01(\x05R\fkernelHeight\x12 \n" +
	"\vkernelWidth\x18\x04 \x01(\x05R\vkernelWidth\x12 \n" +
	"\vstrideDepth\x18\x05 \x01(\x05R\vstrideDepth\x12\"\n" +
	"\fstrideHeight\x18\x06 \x01(\x05R\fstrideHeight\x12 \n" +
	"\vstrideWidth\x18\a \x01(\x05R\vstrideWidth\x12a\n" +
	"\vpaddingType\x18\x0f \x01(\x0e2?.CoreML.Specification.Pooling3DLayerParams.Pooling3DPaddingTypeR\vpaddingType\x12.\n" +
	"\x12customPaddingFront\x18\b \x01(\x05R\x12customPaddingFront\x12,\n" +
	"\x11customPaddingBack\x18\t \x01(\x05R\x11customPaddingBack\x12*\n" +
	"\x10customPaddingTop\x18\n" +
	" \x01(\x05R\x10customPaddingTop\x120\n" +
	"\x13customPaddingBottom\x18\v \x01(\x05R\x13customPaddingBottom\x12,\n" +
	"\x11customPaddingLeft\x18\f \x01(\x05R\x11customPaddingLeft\x12.\n" +
	"\x12customPaddingRight\x18\r \x01(\x05R\x12customPaddingRight\x120\n" +
	"\x13countExcludePadding\x18\x0e \x01(\bR\x13countExcludePadding\"%\n" +
	"\rPoolingType3D\x12\a\n" +
	"\x03MAX\x10\x00\x12\v\n" +
	"\aAVERAGE\x10\x01\"7\n" +
	"\x14Pooling3DPaddingType\x12\n" +
	"\n" +
	"\x06CUSTOM\x10\x00\x12\t\n" +
	"\x05VALID\x10\x01\x12\b\n" +
	"\x04SAME\x10\x02\"\xa3\x01\n" +
	"\x1aGlobalPooling3DLayerParams\x12X\n" +
	"\x04type\x18\x01 \x01(\x0e2D.CoreML.Specification.GlobalPooling3DLayerParams.GlobalPoolingType3DR\x04type\"+\n" +
	"\x13GlobalPoolingType3D\x12\a\n" +
	"\x03MAX\x10\x00\x12\v\n" +
	"\aAVERAGE\x10\x01\"\xdb\x03\n" +
	"\x12PaddingLayerParams\x12V\n" +
	"\bconstant\x18\x01 \x01(\v28.CoreML.Specification.PaddingLayerParams.PaddingConstantH\x00R\bconstant\x12\\\n" +
	"\n" +
	"reflection\x18\x02 \x01(\v2:.CoreML.Specification.PaddingLayerParams.PaddingReflectionH\x00R\n" +
	"reflection\x12_\n" +
	"\vreplication\x18\x03 \x01(\v2;.CoreML.Specification.PaddingLayerParams.PaddingReplicationH\x00R\vreplication\x12K\n" +
	"\x0epaddingAmounts\x18\n" +
	" \x01(\v2#.CoreML.Specification.BorderAmountsR\x0epaddingAmounts\x1a'\n" +
	"\x0fPaddingConstant\x12\x14\n" +
	"\x05value\x18\x01 \x01(\x02R\x05value\x1a\x13\n" +
	"\x11PaddingReflection\x1a\x14\n" +
	"\x12PaddingReplicationB\r\n" +
	"\vPaddingType\";\n" +
	"\x11ConcatLayerParams\x12&\n" +
	"\x0esequenceConcat\x18d \x01(\bR\x0esequenceConcat\"f\n" +
	"\x0eLRNLayerParams\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\x12\x12\n" +
	"\x04beta\x18\x02 \x01(\x02R\x04beta\x12\x1c\n" +
	"\tlocalSize\x18\x03 \x01(\x04R\tlocalSize\x12\f\n" +
	"\x01k\x18\x04 \x01(\x02R\x01k\"\x14\n" +
	"\x12SoftmaxLayerParams\".\n" +
	"\x10SplitLayerParams\x12\x1a\n" +
	"\bnOutputs\x18\x01 \x01(\x04R\bnOutputs\"&\n" +
	"\x0eAddLayerParams\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"+\n" +
	"\x13MultiplyLayerParams\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\"\xa8\x02\n" +
	"\x18UnaryFunctionLayerParams\x12L\n" +
	"\x04type\x18\x01 \x01(\x0e28.CoreML.Specification.UnaryFunctionLayerParams.OperationR\x04type\x12\x14\n" +
	"\x05alpha\x18\x02 \x01(\x02R\x05alpha\x12\x18\n" +
	"\aepsilon\x18\x03 \x01(\x02R\aepsilon\x12\x14\n" +
	"\x05shift\x18\x04 \x01(\x02R\x05shift\x12\x14\n" +
	"\x05scale\x18\x05 \x01(\x02R\x05scale\"b\n" +
	"\tOperation\x12\b\n" +
	"\x04SQRT\x10\x00\x12\t\n" +
	"\x05RSQRT\x10\x01\x12\v\n" +
	"\aINVERSE\x10\x02\x12\t\n" +
	"\x05POWER\x10\x03\x12\a\n" +
	"\x03EXP\x10\x04\x12\a\n" +
	"\x03LOG\x10\x05\x12\a\n" +
	"\x03ABS\x10\x06\x12\r\n" +
	"\tTHRESHOLD\x10\a\"\xb3\x03\n" +
	"\x13UpsampleLayerParams\x12$\n" +
	"\rscalingFactor\x18\x01 \x03(\x04R\rscalingFactor\x128\n" +
	"\x17fractionalScalingFactor\x18\a \x03(\x02R\x17fractionalScalingFactor\x12O\n" +
	"\x04mode\x18\x05 \x01(\x0e2;.CoreML.Specification.UpsampleLayerParams.InterpolationModeR\x04mode\x12l\n" +
	"\x12linearUpsampleMode\x18\x06 \x01(\x0e2<.CoreML.Specification.UpsampleLayerParams.LinearUpsampleModeR\x12linearUpsampleMode\")\n" +
	"\x11InterpolationMode\x12\x06\n" +
	"\x02NN\x10\x00\x12\f\n" +
	"\bBILINEAR\x10\x01\"R\n" +
	"\x12LinearUpsampleMode\x12\v\n" +
	"\aDEFAULT\x10\x00\x12\x16\n" +
	"\x12ALIGN_CORNERS_TRUE\x10\x01\x12\x17\n" +
	"\x13ALIGN_CORNERS_FALSE\x10\x02\"s\n" +
	"\x19ResizeBilinearLayerParams\x12\x1e\n" +
	"\n" +
	"targetSize\x18\x01 \x03(\x04R\n" +
	"targetSize\x126\n" +
	"\x04mode\x18\x02 \x01(\v2\".CoreML.Specification.SamplingModeR\x04mode\"\x9b\x02\n" +
	"\x15CropResizeLayerParams\x12\x1e\n" +
	"\n" +
	"targetSize\x18\x01 \x03(\x04R\n" +
	"targetSize\x124\n" +
	"\x15normalizedCoordinates\x18\x02 \x01(\bR\x15normalizedCoordinates\x126\n" +
	"\x04mode\x18\x03 \x01(\v2\".CoreML.Specification.SamplingModeR\x04mode\x12P\n" +
	"\x0eboxIndicesMode\x18\x04 \x01(\v2(.CoreML.Specification.BoxCoordinatesModeR\x0eboxIndicesMode\x12\"\n" +
	"\fspatialScale\x18\x05 \x01(\x02R\fspatialScale\"_\n" +
	"\x0fBiasLayerParams\x12\x14\n" +
	"\x05shape\x18\x01 \x03(\x04R\x05shape\x126\n" +
	"\x04bias\x18\x02 \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\"\xdc\x01\n" +
	"\x10ScaleLayerParams\x12\x1e\n" +
	"\n" +
	"shapeScale\x18\x01 \x03(\x04R\n" +
	"shapeScale\x128\n" +
	"\x05scale\x18\x02 \x01(\v2\".CoreML.Specification.WeightParamsR\x05scale\x12\x18\n" +
	"\ahasBias\x18\x03 \x01(\bR\ahasBias\x12\x1c\n" +
	"\tshapeBias\x18\x04 \x03(\x04R\tshapeBias\x126\n" +
	"\x04bias\x18\x05 \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\"g\n" +
	"\x17LoadConstantLayerParams\x12\x14\n" +
	"\x05shape\x18\x01 \x03(\x04R\x05shape\x126\n" +
	"\x04data\x18\x02 \x01(\v2\".CoreML.Specification.WeightParamsR\x04data\"2\n" +
	"\x16L2NormalizeLayerParams\x12\x18\n" +
	"\aepsilon\x18\x01 \x01(\x02R\aepsilon\"\x94\x01\n" +
	"\x12FlattenLayerParams\x12I\n" +
	"\x04mode\x18\x01 \x01(\x0e25.CoreML.Specification.FlattenLayerParams.FlattenOrderR\x04mode\"3\n" +
	"\fFlattenOrder\x12\x11\n" +
	"\rCHANNEL_FIRST\x10\x00\x12\x10\n" +
	"\fCHANNEL_LAST\x10\x01\"\xb6\x01\n" +
	"\x12ReshapeLayerParams\x12 \n" +
	"\vtargetShape\x18\x01 \x03(\x03R\vtargetShape\x12I\n" +
	"\x04mode\x18\x02 \x01(\x0e25.CoreML.Specification.ReshapeLayerParams.ReshapeOrderR\x04mode\"3\n" +
	"\fReshapeOrder\x12\x11\n" +
	"\rCHANNEL_FIRST\x10\x00\x12\x10\n" +
	"\fCHANNEL_LAST\x10\x01\"(\n" +
	"\x12PermuteLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x03(\x04R\x04axis\"\xe2\x01\n" +
	"\x19ReorganizeDataLayerParams\x12V\n" +
	"\x04mode\x18\x01 \x01(\x0e2B.CoreML.Specification.ReorganizeDataLayerParams.ReorganizationTypeR\x04mode\x12\x1c\n" +
	"\tblockSize\x18\x02 \x01(\x04R\tblockSize\"O\n" +
	"\x12ReorganizationType\x12\x12\n" +
	"\x0eSPACE_TO_DEPTH\x10\x00\x12\x12\n" +
	"\x0eDEPTH_TO_SPACE\x10\x01\x12\x11\n" +
	"\rPIXEL_SHUFFLE\x10\x02\"\xec\x01\n" +
	"\x10SliceLayerParams\x12\x1e\n" +
	"\n" +
	"startIndex\x18\x01 \x01(\x03R\n" +
	"startIndex\x12\x1a\n" +
	"\bendIndex\x18\x02 \x01(\x03R\bendIndex\x12\x16\n" +
	"\x06stride\x18\x03 \x01(\x04R\x06stride\x12D\n" +
	"\x04axis\x18\x04 \x01(\x0e20.CoreML.Specification.SliceLayerParams.SliceAxisR\x04axis\">\n" +
	"\tSliceAxis\x12\x10\n" +
	"\fCHANNEL_AXIS\x10\x00\x12\x0f\n" +
	"\vHEIGHT_AXIS\x10\x01\x12\x0e\n" +
	"\n" +
	"WIDTH_AXIS\x10\x02\"\xee\x02\n" +
	"\x11ReduceLayerParams\x12K\n" +
	"\x04mode\x18\x01 \x01(\x0e27.CoreML.Specification.ReduceLayerParams.ReduceOperationR\x04mode\x12\x18\n" +
	"\aepsilon\x18\x02 \x01(\x02R\aepsilon\x12F\n" +
	"\x04axis\x18\x03 \x01(\x0e22.CoreML.Specification.ReduceLayerParams.ReduceAxisR\x04axis\"v\n" +
	"\x0fReduceOperation\x12\a\n" +
	"\x03SUM\x10\x00\x12\a\n" +
	"\x03AVG\x10\x01\x12\b\n" +
	"\x04PROD\x10\x02\x12\n" +
	"\n" +
	"\x06LOGSUM\x10\x03\x12\r\n" +
	"\tSUMSQUARE\x10\x04\x12\x06\n" +
	"\x02L1\x10\x05\x12\x06\n" +
	"\x02L2\x10\x06\x12\a\n" +
	"\x03MAX\x10\a\x12\a\n" +
	"\x03MIN\x10\b\x12\n" +
	"\n" +
	"\x06ARGMAX\x10\t\"2\n" +
	"\n" +
	"ReduceAxis\x12\a\n" +
	"\x03CHW\x10\x00\x12\x06\n" +
	"\x02HW\x10\x01\x12\x05\n" +
	"\x01C\x10\x02\x12\x05\n" +
	"\x01H\x10\x03\x12\x05\n" +
	"\x01W\x10\x04\"p\n" +
	"\x0fCropLayerParams\x12E\n" +
	"\vcropAmounts\x18\x01 \x01(\v2#.CoreML.Specification.BorderAmountsR\vcropAmounts\x12\x16\n" +
	"\x06offset\x18\x05 \x03(\x04R\x06offset\"\x14\n" +
	"\x12AverageLayerParams\"\x10\n" +
	"\x0eMaxLayerParams\"\x10\n" +
	"\x0eMinLayerParams\"C\n" +
	"\x15DotProductLayerParams\x12*\n" +
	"\x10cosineSimilarity\x18\x01 \x01(\bR\x10cosineSimilarity\"\x92\x01\n" +
	" MeanVarianceNormalizeLayerParams\x12&\n" +
	"\x0eacrossChannels\x18\x01 \x01(\bR\x0eacrossChannels\x12,\n" +
	"\x11normalizeVariance\x18\x02 \x01(\bR\x11normalizeVariance\x12\x18\n" +
	"\aepsilon\x18\x03 \x01(\x02R\aepsilon\"?\n" +
	"\x19SequenceRepeatLayerParams\x12\"\n" +
	"\fnRepetitions\x18\x01 \x01(\x04R\fnRepetitions\"\x86\x04\n" +
	"\x1aSimpleRecurrentLayerParams\x12(\n" +
	"\x0finputVectorSize\x18\x01 \x01(\x04R\x0finputVectorSize\x12*\n" +
	"\x10outputVectorSize\x18\x02 \x01(\x04R\x10outputVectorSize\x12F\n" +
	"\n" +
	"activation\x18\n" +
	" \x01(\v2&.CoreML.Specification.ActivationParamsR\n" +
	"activation\x12&\n" +
	"\x0esequenceOutput\x18\x0f \x01(\bR\x0esequenceOutput\x12$\n" +
	"\rhasBiasVector\x18\x14 \x01(\bR\rhasBiasVector\x12F\n" +
	"\fweightMatrix\x18\x1e \x01(\v2\".CoreML.Specification.WeightParamsR\fweightMatrix\x12L\n" +
	"\x0frecursionMatrix\x18\x1f \x01(\v2\".CoreML.Specification.WeightParamsR\x0frecursionMatrix\x12B\n" +
	"\n" +
	"biasVector\x18  \x01(\v2\".CoreML.Specification.WeightParamsR\n" +
	"biasVector\x12\"\n" +
	"\freverseInput\x18d \x01(\bR\freverseInput\"\xe0\b\n" +
	"\x0eGRULayerParams\x12(\n" +
	"\x0finputVectorSize\x18\x01 \x01(\x04R\x0finputVectorSize\x12*\n" +
	"\x10outputVectorSize\x18\x02 \x01(\x04R\x10outputVectorSize\x12H\n" +
	"\vactivations\x18\n" +
	" \x03(\v2&.CoreML.Specification.ActivationParamsR\vactivations\x12&\n" +
	"\x0esequenceOutput\x18\x0f \x01(\bR\x0esequenceOutput\x12&\n" +
	"\x0ehasBiasVectors\x18\x14 \x01(\bR\x0ehasBiasVectors\x12Z\n" +
	"\x16updateGateWeightMatrix\x18\x1e \x01(\v2\".CoreML.Specification.WeightParamsR\x16updateGateWeightMatrix\x12X\n" +
	"\x15resetGateWeightMatrix\x18\x1f \x01(\v2\".CoreML.Specification.WeightParamsR\x15resetGateWeightMatrix\x12Z\n" +
	"\x16outputGateWeightMatrix\x18  \x01(\v2\".CoreML.Specification.WeightParamsR\x16outputGateWeightMatrix\x12`\n" +
	"\x19updateGateRecursionMatrix\x182 \x01(\v2\".CoreML.Specification.WeightParamsR\x19updateGateRecursionMatrix\x12^\n" +
	"\x18resetGateRecursionMatrix\x183 \x01(\v2\".CoreML.Specification.WeightParamsR\x18resetGateRecursionMatrix\x12`\n" +
	"\x19outputGateRecursionMatrix\x184 \x01(\v2\".CoreML.Specification.WeightParamsR\x19outputGateRecursionMatrix\x12V\n" +
	"\x14updateGateBiasVector\x18F \x01(\v2\".CoreML.Specification.WeightParamsR\x14updateGateBiasVector\x12T\n" +
	"\x13resetGateBiasVector\x18G \x01(\v2\".CoreML.Specification.WeightParamsR\x13resetGateBiasVector\x12V\n" +
	"\x14outputGateBiasVector\x18H \x01(\v2\".CoreML.Specification.WeightParamsR\x14outputGateBiasVector\x12\"\n" +
	"\freverseInput\x18d \x01(\bR\freverseInput\"\x98\x02\n" +
	"\n" +
	"LSTMParams\x12&\n" +
	"\x0esequenceOutput\x18\n" +
	" \x01(\bR\x0esequenceOutput\x12&\n" +
	"\x0ehasBiasVectors\x18\x14 \x01(\bR\x0ehasBiasVectors\x12\x1e\n" +
	"\n" +
	"forgetBias\x18\x1e \x01(\bR\n" +
	"forgetBias\x12.\n" +
	"\x12hasPeepholeVectors\x18( \x01(\bR\x12hasPeepholeVectors\x12<\n" +
	"\x19coupledInputAndForgetGate\x182 \x01(\bR\x19coupledInputAndForgetGate\x12,\n" +
	"\x11cellClipThreshold\x18< \x01(\x02R\x11cellClipThreshold\"\x82\v\n" +
	"\x10LSTMWeightParams\x12X\n" +
	"\x15inputGateWeightMatrix\x18\x01 \x01(\v2\".CoreML.Specification.WeightParamsR\x15inputGateWeightMatrix\x12Z\n" +
	"\x16forgetGateWeightMatrix\x18\x02 \x01(\v2\".CoreML.Specification.WeightParamsR\x16forgetGateWeightMatrix\x12Z\n" +
	"\x16blockInputWeightMatrix\x18\x03 \x01(\v2\".CoreML.Specification.WeightParamsR\x16blockInputWeightMatrix\x12Z\n" +
	"\x16outputGateWeightMatrix\x18\x04 \x01(\v2\".CoreML.Specification.WeightParamsR\x16outputGateWeightMatrix\x12^\n" +
	"\x18inputGateRecursionMatrix\x18\x14 \x01(\v2\".CoreML.Specification.WeightParamsR\x18inputGateRecursionMatrix\x12`\n" +
	"\x19forgetGateRecursionMatrix\x18\x15 \x01(\v2\".CoreML.Specification.WeightParamsR\x19forgetGateRecursionMatrix\x12`\n" +
	"\x19blockInputRecursionMatrix\x18\x16 \x01(\v2\".CoreML.Specification.WeightParamsR\x19blockInputRecursionMatrix\x12`\n" +
	"\x19outputGateRecursionMatrix\x18\x17 \x01(\v2\".CoreML.Specification.WeightParamsR\x19outputGateRecursionMatrix\x12T\n" +
	"\x13inputGateBiasVector\x18( \x01(\v2\".CoreML.Specification.WeightParamsR\x13inputGateBiasVector\x12V\n" +
	"\x14forgetGateBiasVector\x18) \x01(\v2\".CoreML.Specification.WeightParamsR\x14forgetGateBiasVector\x12V\n" +
	"\x14blockInputBiasVector\x18* \x01(\v2\".CoreML.Specification.WeightParamsR\x14blockInputBiasVector\x12V\n" +
	"\x14outputGateBiasVector\x18+ \x01(\v2\".CoreML.Specification.WeightParamsR\x14outputGateBiasVector\x12\\\n" +
	"\x17inputGatePeepholeVector\x18< \x01(\v2\".CoreML.Specification.WeightParamsR\x17inputGatePeepholeVector\x12^\n" +
	"\x18forgetGatePeepholeVector\x18= \x01(\v2\".CoreML.Specification.WeightParamsR\x18forgetGatePeepholeVector\x12^\n" +
	"\x18outputGatePeepholeVector\x18> \x01(\v2\".CoreML.Specification.WeightParamsR\x18outputGatePeepholeVector\"\xe9\x02\n" +
	"\x1dUniDirectionalLSTMLayerParams\x12(\n" +
	"\x0finputVectorSize\x18\x01 \x01(\x04R\x0finputVectorSize\x12*\n" +
	"\x10outputVectorSize\x18\x02 \x01(\x04R\x10outputVectorSize\x12H\n" +
	"\vactivations\x18\n" +
	" \x03(\v2&.CoreML.Specification.ActivationParamsR\vactivations\x128\n" +
	"\x06params\x18\x0f \x01(\v2 .CoreML.Specification.LSTMParamsR\x06params\x12J\n" +
	"\fweightParams\x18\x14 \x01(\v2&.CoreML.Specification.LSTMWeightParamsR\fweightParams\x12\"\n" +
	"\freverseInput\x18d \x01(\bR\freverseInput\"\xbc\x03\n" +
	"\x1cBiDirectionalLSTMLayerParams\x12(\n" +
	"\x0finputVectorSize\x18\x01 \x01(\x04R\x0finputVectorSize\x12*\n" +
	"\x10outputVectorSize\x18\x02 \x01(\x04R\x10outputVectorSize\x12^\n" +
	"\x16activationsForwardLSTM\x18\n" +
	" \x03(\v2&.CoreML.Specification.ActivationParamsR\x16activationsForwardLSTM\x12`\n" +
	"\x17activationsBackwardLSTM\x18\v \x03(\v2&.CoreML.Specification.ActivationParamsR\x17activationsBackwardLSTM\x128\n" +
	"\x06params\x18\x0f \x01(\v2 .CoreML.Specification.LSTMParamsR\x06params\x12J\n" +
	"\fweightParams\x18\x14 \x03(\v2&.CoreML.Specification.LSTMWeightParamsR\fweightParams\"\xb1\x04\n" +
	"\x11CustomLayerParams\x12\x1c\n" +
	"\tclassName\x18\n" +
	" \x01(\tR\tclassName\x12<\n" +
	"\aweights\x18\x14 \x03(\v2\".CoreML.Specification.WeightParamsR\aweights\x12W\n" +
	"\n" +
	"parameters\x18\x1e \x03(\v27.CoreML.Specification.CustomLayerParams.ParametersEntryR\n" +
	"parameters\x12 \n" +
	"\vdescription\x18( \x01(\tR\vdescription\x1a\xc6\x01\n" +
	"\x15CustomLayerParamValue\x12\"\n" +
	"\vdoubleValue\x18\n" +
	" \x01(\x01H\x00R\vdoubleValue\x12\"\n" +
	"\vstringValue\x18\x14 \x01(\tH\x00R\vstringValue\x12\x1c\n" +
	"\bintValue\x18\x1e \x01(\x05H\x00R\bintValue\x12\x1e\n" +
	"\tlongValue\x18( \x01(\x03H\x00R\tlongValue\x12\x1e\n" +
	"\tboolValue\x182 \x01(\bH\x00R\tboolValueB\a\n" +
	"\x05value\x1a|\n" +
	"\x0fParametersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12S\n" +
	"\x05value\x18\x02 \x01(\v2=.CoreML.Specification.CustomLayerParams.CustomLayerParamValueR\x05value:\x028\x01\"*\n" +
	"\x14TransposeLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x04R\x04axes\"\x9e\x03\n" +
	"\x18BatchedMatMulLayerParams\x12\x1e\n" +
	"\n" +
	"transposeA\x18\x01 \x01(\bR\n" +
	"transposeA\x12\x1e\n" +
	"\n" +
	"transposeB\x18\x02 \x01(\bR\n" +
	"transposeB\x12>\n" +
	"\x1aweightMatrixFirstDimension\x18\x05 \x01(\x04R\x1aweightMatrixFirstDimension\x12@\n" +
	"\x1bweightMatrixSecondDimension\x18\x06 \x01(\x04R\x1bweightMatrixSecondDimension\x12\x18\n" +
	"\ahasBias\x18\a \x01(\bR\ahasBias\x12<\n" +
	"\aweights\x18\b \x01(\v2\".CoreML.Specification.WeightParamsR\aweights\x126\n" +
	"\x04bias\x18\t \x01(\v2\".CoreML.Specification.WeightParamsR\x04bias\x120\n" +
	"\x13int8DynamicQuantize\x18\n" +
	" \x01(\bR\x13int8DynamicQuantize\"I\n" +
	"\x13ConcatNDLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\x1e\n" +
	"\n" +
	"interleave\x18\x02 \x01(\bR\n" +
	"interleave\"*\n" +
	"\x14SoftmaxNDLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\"4\n" +
	"\x12ReverseLayerParams\x12\x1e\n" +
	"\n" +
	"reverseDim\x18\x01 \x03(\bR\n" +
	"reverseDim\"Y\n" +
	"\x15ReverseSeqLayerParams\x12\x1c\n" +
	"\tbatchAxis\x18\x01 \x01(\x03R\tbatchAxis\x12\"\n" +
	"\fsequenceAxis\x18\x02 \x01(\x03R\fsequenceAxis\"i\n" +
	"\x19LoadConstantNDLayerParams\x12\x14\n" +
	"\x05shape\x18\x01 \x03(\x04R\x05shape\x126\n" +
	"\x04data\x18\x02 \x01(\v2\".CoreML.Specification.WeightParamsR\x04data\"+\n" +
	"\x13FillLikeLayerParams\x12\x14\n" +
	"\x05value\x18\x01 \x01(\x02R\x05value\"O\n" +
	"\x15FillStaticLayerParams\x12\x14\n" +
	"\x05value\x18\x01 \x01(\x02R\x05value\x12 \n" +
	"\vtargetShape\x18\x02 \x03(\x04R\vtargetShape\".\n" +
	"\x16FillDynamicLayerParams\x12\x14\n" +
	"\x05value\x18\x01 \x01(\x02R\x05value\"\x1f\n" +
	"\x1dWhereBroadcastableLayerParams\"\x10\n" +
	"\x0eSinLayerParams\"\x10\n" +
	"\x0eCosLayerParams\"\x10\n" +
	"\x0eTanLayerParams\"\x11\n" +
	"\x0fAsinLayerParams\"\x11\n" +
	"\x0fAcosLayerParams\"\x11\n" +
	"\x0fAtanLayerParams\"\x11\n" +
	"\x0fSinhLayerParams\"\x11\n" +
	"\x0fCoshLayerParams\"\x11\n" +
	"\x0fTanhLayerParams\"\x12\n" +
	"\x10AsinhLayerParams\"\x12\n" +
	"\x10AcoshLayerParams\"\x12\n" +
	"\x10AtanhLayerParams\"\x1d\n" +
	"\x1bPowBroadcastableLayerParams\"\x11\n" +
	"\x0fExp2LayerParams\"\x19\n" +
	"\x17WhereNonZeroLayerParams\"S\n" +
	"\x19MatrixBandPartLayerParams\x12\x1a\n" +
	"\bnumLower\x18\x01 \x01(\x03R\bnumLower\x12\x1a\n" +
	"\bnumUpper\x18\x02 \x01(\x03R\bnumUpper\"*\n" +
	"\x1aUpperTriangularLayerParams\x12\f\n" +
	"\x01k\x18\x01 \x01(\x03R\x01k\"*\n" +
	"\x1aLowerTriangularLayerParams\x12\f\n" +
	"\x01k\x18\x01 \x01(\x03R\x01k\"\x1c\n" +
	"\x1aBroadcastToLikeLayerParams\"@\n" +
	"\x1cBroadcastToStaticLayerParams\x12 \n" +
	"\vtargetShape\x18\x01 \x03(\x04R\vtargetShape\"\x1f\n" +
	"\x1dBroadcastToDynamicLayerParams\"\x1d\n" +
	"\x1bAddBroadcastableLayerParams\"\x1d\n" +
	"\x1bMaxBroadcastableLayerParams\"\x1d\n" +
	"\x1bMinBroadcastableLayerParams\"\x1d\n" +
	"\x1bModBroadcastableLayerParams\"\"\n" +
	" FloorDivBroadcastableLayerParams\"\"\n" +
	" SubtractBroadcastableLayerParams\"\"\n" +
	" MultiplyBroadcastableLayerParams\" \n" +
	"\x1eDivideBroadcastableLayerParams\"'\n" +
	"\x11GatherLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\"_\n" +
	"\x12ScatterLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x125\n" +
	"\x04mode\x18\x02 \x01(\x0e2!.CoreML.Specification.ScatterModeR\x04mode\"\x15\n" +
	"\x13GatherNDLayerParams\"M\n" +
	"\x14ScatterNDLayerParams\x125\n" +
	"\x04mode\x18\x01 \x01(\x0e2!.CoreML.Specification.ScatterModeR\x04mode\"0\n" +
	"\x1aGatherAlongAxisLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\"h\n" +
	"\x1bScatterAlongAxisLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x125\n" +
	"\x04mode\x18\x02 \x01(\x0e2!.CoreML.Specification.ScatterModeR\x04mode\"&\n" +
	"\x10StackLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\"D\n" +
	" RankPreservingReshapeLayerParams\x12 \n" +
	"\vtargetShape\x18\x01 \x03(\x03R\vtargetShape\"\x8e\x01\n" +
	"\x1aConstantPaddingLayerParams\x12\x14\n" +
	"\x05value\x18\x01 \x01(\x02R\x05value\x12\x1e\n" +
	"\n" +
	"padAmounts\x18\x02 \x03(\x04R\n" +
	"padAmounts\x12:\n" +
	"\x18padToGivenOutputSizeMode\x18\x03 \x01(\bR\x18padToGivenOutputSizeMode\"]\n" +
	"\x1bRandomNormalLikeLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x12\n" +
	"\x04mean\x18\x02 \x01(\x02R\x04mean\x12\x16\n" +
	"\x06stdDev\x18\x03 \x01(\x02R\x06stdDev\"\x81\x01\n" +
	"\x1dRandomNormalStaticLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x12\n" +
	"\x04mean\x18\x02 \x01(\x02R\x04mean\x12\x16\n" +
	"\x06stdDev\x18\x03 \x01(\x02R\x06stdDev\x12 \n" +
	"\voutputShape\x18\x04 \x03(\x04R\voutputShape\"`\n" +
	"\x1eRandomNormalDynamicLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x12\n" +
	"\x04mean\x18\x02 \x01(\x02R\x04mean\x12\x16\n" +
	"\x06stdDev\x18\x03 \x01(\x02R\x06stdDev\"b\n" +
	"\x1cRandomUniformLikeLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x16\n" +
	"\x06minVal\x18\x02 \x01(\x02R\x06minVal\x12\x16\n" +
	"\x06maxVal\x18\x03 \x01(\x02R\x06maxVal\"\x86\x01\n" +
	"\x1eRandomUniformStaticLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x16\n" +
	"\x06minVal\x18\x02 \x01(\x02R\x06minVal\x12\x16\n" +
	"\x06maxVal\x18\x03 \x01(\x02R\x06maxVal\x12 \n" +
	"\voutputShape\x18\x04 \x03(\x04R\voutputShape\"e\n" +
	"\x1fRandomUniformDynamicLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x16\n" +
	"\x06minVal\x18\x02 \x01(\x02R\x06minVal\x12\x16\n" +
	"\x06maxVal\x18\x03 \x01(\x02R\x06maxVal\"H\n" +
	"\x1eRandomBernoulliLikeLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x12\n" +
	"\x04prob\x18\x02 \x01(\x02R\x04prob\"l\n" +
	" RandomBernoulliStaticLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x12\n" +
	"\x04prob\x18\x02 \x01(\x02R\x04prob\x12 \n" +
	"\voutputShape\x18\x03 \x03(\x04R\voutputShape\"K\n" +
	"!RandomBernoulliDynamicLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x12\n" +
	"\x04prob\x18\x02 \x01(\x02R\x04prob\"\xa8\x01\n" +
	"\"CategoricalDistributionLayerParams\x12\x12\n" +
	"\x04seed\x18\x01 \x01(\x03R\x04seed\x12\x1e\n" +
	"\n" +
	"numSamples\x18\x02 \x01(\x03R\n" +
	"numSamples\x12\x1a\n" +
	"\bisLogits\x18\x03 \x01(\bR\bisLogits\x12\x10\n" +
	"\x03eps\x18\x04 \x01(\x02R\x03eps\x12 \n" +
	"\vtemperature\x18\x05 \x01(\x02R\vtemperature\"c\n" +
	"\x13ReduceL1LayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"c\n" +
	"\x13ReduceL2LayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"d\n" +
	"\x14ReduceMaxLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"d\n" +
	"\x14ReduceMinLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"d\n" +
	"\x14ReduceSumLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"e\n" +
	"\x15ReduceProdLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"e\n" +
	"\x15ReduceMeanLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"g\n" +
	"\x17ReduceLogSumLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"j\n" +
	"\x1aReduceSumSquareLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"j\n" +
	"\x1aReduceLogSumExpLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1a\n" +
	"\bkeepDims\x18\x02 \x01(\bR\bkeepDims\x12\x1c\n" +
	"\treduceAll\x18\x03 \x01(\bR\treduceAll\"+\n" +
	"\x15ExpandDimsLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\",\n" +
	"\x16FlattenTo2DLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\"<\n" +
	"\x18ReshapeStaticLayerParams\x12 \n" +
	"\vtargetShape\x18\x01 \x03(\x03R\vtargetShape\"\x18\n" +
	"\x16ReshapeLikeLayerParams\"\x1b\n" +
	"\x19ReshapeDynamicLayerParams\"H\n" +
	"\x12SqueezeLayerParams\x12\x12\n" +
	"\x04axes\x18\x01 \x03(\x03R\x04axes\x12\x1e\n" +
	"\n" +
	"squeezeAll\x18\x02 \x01(\bR\n" +
	"squeezeAll\"S\n" +
	"\x0fTopKLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\f\n" +
	"\x01K\x18\x02 \x01(\x04R\x01K\x12\x1e\n" +
	"\n" +
	"useBottomK\x18\x03 \x01(\bR\n" +
	"useBottomK\"E\n" +
	"\x11ArgMaxLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\x1c\n" +
	"\tremoveDim\x18\x02 \x01(\bR\tremoveDim\"E\n" +
	"\x11ArgMinLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\x1c\n" +
	"\tremoveDim\x18\x02 \x01(\bR\tremoveDim\"f\n" +
	"\x12SplitNDLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\x1c\n" +
	"\tnumSplits\x18\x02 \x01(\x04R\tnumSplits\x12\x1e\n" +
	"\n" +
	"splitSizes\x18\x03 \x03(\x04R\n" +
	"splitSizes\"\x11\n" +
	"\x0fCeilLayerParams\"\x12\n" +
	"\x10RoundLayerParams\"\x12\n" +
	"\x10FloorLayerParams\"\x11\n" +
	"\x0fSignLayerParams\"A\n" +
	"\x0fClipLayerParams\x12\x16\n" +
	"\x06minVal\x18\x01 \x01(\x02R\x06minVal\x12\x16\n" +
	"\x06maxVal\x18\x02 \x01(\x02R\x06maxVal\"\xc6\x01\n" +
	"\x16SliceStaticLayerParams\x12\x1a\n" +
	"\bbeginIds\x18\x01 \x03(\x03R\bbeginIds\x12\x1e\n" +
	"\n" +
	"beginMasks\x18\x02 \x03(\bR\n" +
	"beginMasks\x12\x16\n" +
	"\x06endIds\x18\x03 \x03(\x03R\x06endIds\x12\x1a\n" +
	"\bendMasks\x18\x04 \x03(\bR\bendMasks\x12\x18\n" +
	"\astrides\x18\x05 \x03(\x03R\astrides\x12\"\n" +
	"\fsqueezeMasks\x18\x06 \x03(\bR\fsqueezeMasks\"\xab\x01\n" +
	"\x17SliceDynamicLayerParams\x12\x1e\n" +
	"\n" +
	"beginMasks\x18\x02 \x03(\bR\n" +
	"beginMasks\x12\x16\n" +
	"\x06endIds\x18\x03 \x03(\x03R\x06endIds\x12\x1a\n" +
	"\bendMasks\x18\x04 \x03(\bR\bendMasks\x12\x18\n" +
	"\astrides\x18\x05 \x03(\x03R\astrides\x12\"\n" +
	"\fsqueezeMasks\x18\x06 \x03(\bR\fsqueezeMasks\"%\n" +
	"\x0fTileLayerParams\x12\x12\n" +
	"\x04reps\x18\x01 \x03(\x04R\x04reps\"\x15\n" +
	"\x13GetShapeLayerParams\"\x10\n" +
	"\x0eErfLayerParams\"\x9f\x01\n" +
	"\x0fGeluLayerParams\x12B\n" +
	"\x04mode\x18\x01 \x01(\x0e2..CoreML.Specification.GeluLayerParams.GeluModeR\x04mode\"H\n" +
	"\bGeluMode\x12\t\n" +
	"\x05EXACT\x10\x00\x12\x16\n" +
	"\x12TANH_APPROXIMATION\x10\x01\x12\x19\n" +
	"\x15SIGMOID_APPROXIMATION\x10\x02\"z\n" +
	"\x16RangeStaticLayerParams\x12\x1a\n" +
	"\bendValue\x18\x01 \x01(\x02R\bendValue\x12\x1e\n" +
	"\n" +
	"startValue\x18\x02 \x01(\x02R\n" +
	"startValue\x12$\n" +
	"\rstepSizeValue\x18\x03 \x01(\x02R\rstepSizeValue\"_\n" +
	"\x17RangeDynamicLayerParams\x12\x1e\n" +
	"\n" +
	"startValue\x18\x02 \x01(\x02R\n" +
	"startValue\x12$\n" +
	"\rstepSizeValue\x18\x03 \x01(\x02R\rstepSizeValue\"c\n" +
	"\x19SlidingWindowsLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\x1e\n" +
	"\n" +
	"windowSize\x18\x02 \x01(\x04R\n" +
	"windowSize\x12\x12\n" +
	"\x04step\x18\x03 \x01(\x04R\x04step\"\xcd\x01\n" +
	"\x1dLayerNormalizationLayerParams\x12(\n" +
	"\x0fnormalizedShape\x18\x01 \x03(\x03R\x0fnormalizedShape\x12\x10\n" +
	"\x03eps\x18\x02 \x01(\x02R\x03eps\x128\n" +
	"\x05gamma\x18\x03 \x01(\v2\".CoreML.Specification.WeightParamsR\x05gamma\x126\n" +
	"\x04beta\x18\x04 \x01(\v2\".CoreML.Specification.WeightParamsR\x04beta\"\xbc\x01\n" +
	" NonMaximumSuppressionLayerParams\x12\"\n" +
	"\fiouThreshold\x18\x01 \x01(\x02R\fiouThreshold\x12&\n" +
	"\x0escoreThreshold\x18\x02 \x01(\x02R\x0escoreThreshold\x12\x1a\n" +
	"\bmaxBoxes\x18\x03 \x01(\x04R\bmaxBoxes\x120\n" +
	"\x13perClassSuppression\x18\x04 \x01(\bR\x13perClassSuppression\"B\n" +
	"\x16ClampedReLULayerParams\x12\x14\n" +
	"\x05alpha\x18\x01 \x01(\x02R\x05alpha\x12\x12\n" +
	"\x04beta\x18\x02 \x01(\x02R\x04beta\"H\n" +
	"\x12ArgSortLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12\x1e\n" +
	"\n" +
	"descending\x18\x02 \x01(\bR\n" +
	"descending\"@\n" +
	"\x16SliceBySizeLayerParams\x12\x12\n" +
	"\x04size\x18\x02 \x01(\x03R\x04size\x12\x12\n" +
	"\x04axis\x18\x03 \x01(\x03R\x04axis\"\xda\x05\n" +
	"\x17NeuralNetworkClassifier\x12@\n" +
	"\x06layers\x18\x01 \x03(\v2(.CoreML.Specification.NeuralNetworkLayerR\x06layers\x12V\n" +
	"\rpreprocessing\x18\x02 \x03(\v20.CoreML.Specification.NeuralNetworkPreprocessingR\rpreprocessing\x12q\n" +
	"\x16arrayInputShapeMapping\x18\x05 \x01(\x0e29.CoreML.Specification.NeuralNetworkMultiArrayShapeMappingR\x16arrayInputShapeMapping\x12l\n" +
	"\x16imageInputShapeMapping\x18\x06 \x01(\x0e24.CoreML.Specification.NeuralNetworkImageShapeMappingR\x16imageInputShapeMapping\x12Q\n" +
	"\fupdateParams\x18\n" +
	" \x01(\v2-.CoreML.Specification.NetworkUpdateParametersR\fupdateParams\x12R\n" +
	"\x11stringClassLabels\x18d \x01(\v2\".CoreML.Specification.StringVectorH\x00R\x11stringClassLabels\x12O\n" +
	"\x10int64ClassLabels\x18e \x01(\v2!.CoreML.Specification.Int64VectorH\x00R\x10int64ClassLabels\x12=\n" +
	"\x19labelProbabilityLayerName\x18\xc8\x01 \x01(\tR\x19labelProbabilityLayerNameB\r\n" +
	"\vClassLabels\"\x89\x01\n" +
	"\x11OneHotLayerParams\x12*\n" +
	"\x10oneHotVectorSize\x18\x01 \x01(\x04R\x10oneHotVectorSize\x12\x12\n" +
	"\x04axis\x18\x02 \x01(\x03R\x04axis\x12\x18\n" +
	"\aonValue\x18\x03 \x01(\x02R\aonValue\x12\x1a\n" +
	"\boffValue\x18\x04 \x01(\x02R\boffValue\"k\n" +
	"\x11CumSumLayerParams\x12\x12\n" +
	"\x04axis\x18\x01 \x01(\x03R\x04axis\x12(\n" +
	"\x0fexcludeFinalSum\x18\x02 \x01(\bR\x0fexcludeFinalSum\x12\x18\n" +
	"\areverse\x18\x03 \x01(\bR\areverse\"\xe6\x03\n" +
	"\x16NeuralNetworkRegressor\x12@\n" +
	"\x06layers\x18\x01 \x03(\v2(.CoreML.Specification.NeuralNetworkLayerR\x06layers\x12V\n" +
	"\rpreprocessing\x18\x02 \x03(\v20.CoreML.Specification.NeuralNetworkPreprocessingR\rpreprocessing\x12q\n" +
	"\x16arrayInputShapeMapping\x18\x05 \x01(\x0e29.CoreML.Specification.NeuralNetworkMultiArrayShapeMappingR\x16arrayInputShapeMapping\x12l\n" +
	"\x16imageInputShapeMapping\x18\x06 \x01(\x0e24.CoreML.Specification.NeuralNetworkImageShapeMappingR\x16imageInputShapeMapping\x12Q\n" +
	"\fupdateParams\x18\n" +
	" \x01(\v2-.CoreML.Specification.NetworkUpdateParametersR\fupdateParams\"\xd0\x02\n" +
	"\x17NetworkUpdateParameters\x12?\n" +
	"\n" +
	"lossLayers\x18\x01 \x03(\v2\x1f.CoreML.Specification.LossLayerR\n" +
	"lossLayers\x12=\n" +
	"\toptimizer\x18\x02 \x01(\v2\x1f.CoreML.Specification.OptimizerR\toptimizer\x12<\n" +
	"\x06epochs\x18\x03 \x01(\v2$.CoreML.Specification.Int64ParameterR\x06epochs\x12=\n" +
	"\ashuffle\x18\n" +
	" \x01(\v2#.CoreML.Specification.BoolParameterR\ashuffle\x128\n" +
	"\x04seed\x18\x14 \x01(\v2$.CoreML.Specification.Int64ParameterR\x04seed\"\xa8\x02\n" +
	"\tLossLayer\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x84\x01\n" +
	" categoricalCrossEntropyLossLayer\x18\n" +
	" \x01(\v26.CoreML.Specification.CategoricalCrossEntropyLossLayerH\x00R categoricalCrossEntropyLossLayer\x12o\n" +
	"\x19meanSquaredErrorLossLayer\x18\v \x01(\v2/.CoreML.Specification.MeanSquaredErrorLossLayerH\x00R\x19meanSquaredErrorLossLayerB\x0f\n" +
	"\rLossLayerType\"P\n" +
	" CategoricalCrossEntropyLossLayer\x12\x14\n" +
	"\x05input\x18\x01 \x01(\tR\x05input\x12\x16\n" +
	"\x06target\x18\x02 \x01(\tR\x06target\"I\n" +
	"\x19MeanSquaredErrorLossLayer\x12\x14\n" +
	"\x05input\x18\x01 \x01(\tR\x05input\x12\x16\n" +
	"\x06target\x18\x02 \x01(\tR\x06target\"\xb3\x01\n" +
	"\tOptimizer\x12H\n" +
	"\fsgdOptimizer\x18\n" +
	" \x01(\v2\".CoreML.Specification.SGDOptimizerH\x00R\fsgdOptimizer\x12K\n" +
	"\radamOptimizer\x18\v \x01(\v2#.CoreML.Specification.AdamOptimizerH\x00R\radamOptimizerB\x0f\n" +
	"\rOptimizerType\"\xe8\x01\n" +
	"\fSGDOptimizer\x12I\n" +
	"\flearningRate\x18\x01 \x01(\v2%.CoreML.Specification.DoubleParameterR\flearningRate\x12J\n" +
	"\rminiBatchSize\x18\x02 \x01(\v2$.CoreML.Specification.Int64ParameterR\rminiBatchSize\x12A\n" +
	"\bmomentum\x18\x03 \x01(\v2%.CoreML.Specification.DoubleParameterR\bmomentum\"\xd9\x02\n" +
	"\rAdamOptimizer\x12I\n" +
	"\flearningRate\x18\x01 \x01(\v2%.CoreML.Specification.DoubleParameterR\flearningRate\x12J\n" +
	"\rminiBatchSize\x18\x02 \x01(\v2$.CoreML.Specification.Int64ParameterR\rminiBatchSize\x12;\n" +
	"\x05beta1\x18\x03 \x01(\v2%.CoreML.Specification.DoubleParameterR\x05beta1\x12;\n" +
	"\x05beta2\x18\x04 \x01(\v2%.CoreML.Specification.DoubleParameterR\x05beta2\x127\n" +
	"\x03eps\x18\x05 \x01(\v2%.CoreML.Specification.DoubleParameterR\x03eps*W\n" +
	"#NeuralNetworkMultiArrayShapeMapping\x12\x17\n" +
	"\x13RANK5_ARRAY_MAPPING\x10\x00\x12\x17\n" +
	"\x13EXACT_ARRAY_MAPPING\x10\x01*R\n" +
	"\x1eNeuralNetworkImageShapeMapping\x12\x17\n" +
	"\x13RANK5_IMAGE_MAPPING\x10\x00\x12\x17\n" +
	"\x13RANK4_IMAGE_MAPPING\x10\x01*\x87\x01\n" +
	"\vScatterMode\x12\x12\n" +
	"\x0eSCATTER_UPDATE\x10\x00\x12\x0f\n" +
	"\vSCATTER_ADD\x10\x01\x12\x0f\n" +
	"\vSCATTER_SUB\x10\x02\x12\x0f\n" +
	"\vSCATTER_MUL\x10\x03\x12\x0f\n" +
	"\vSCATTER_DIV\x10\x04\x12\x0f\n" +
	"\vSCATTER_MAX\x10\x05\x12\x0f\n" +
	"\vSCATTER_MIN\x10\x06B0H\x03Z,github.com/gomlx/go-coreml/proto/coreml/specP\x00P\x01b\x06proto3"

var (
	file_NeuralNetwork_proto_rawDescOnce sync.Once
	file_NeuralNetwork_proto_rawDescData []byte
)

func file_NeuralNetwork_proto_rawDescGZIP() []byte {
	file_NeuralNetwork_proto_rawDescOnce.Do(func() {
		file_NeuralNetwork_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_NeuralNetwork_proto_rawDesc), len(file_NeuralNetwork_proto_rawDesc)))
	})
	return file_NeuralNetwork_proto_rawDescData
}

var file_NeuralNetwork_proto_enumTypes = make([]protoimpl.EnumInfo, 21)
var file_NeuralNetwork_proto_msgTypes = make([]protoimpl.MessageInfo, 204)
var file_NeuralNetwork_proto_goTypes = []any{
	(NeuralNetworkMultiArrayShapeMapping)(0),            // 0: CoreML.Specification.NeuralNetworkMultiArrayShapeMapping
	(NeuralNetworkImageShapeMapping)(0),                 // 1: CoreML.Specification.NeuralNetworkImageShapeMapping
	(ScatterMode)(0),                                    // 2: CoreML.Specification.ScatterMode
	(SamePadding_SamePaddingMode)(0),                    // 3: CoreML.Specification.SamePadding.SamePaddingMode
	(SamplingMode_Method)(0),                            // 4: CoreML.Specification.SamplingMode.Method
	(BoxCoordinatesMode_Coordinates)(0),                 // 5: CoreML.Specification.BoxCoordinatesMode.Coordinates
	(Convolution3DLayerParams_PaddingType)(0),           // 6: CoreML.Specification.Convolution3DLayerParams.PaddingType
	(PoolingLayerParams_PoolingType)(0),                 // 7: CoreML.Specification.PoolingLayerParams.PoolingType
	(Pooling3DLayerParams_PoolingType3D)(0),             // 8: CoreML.Specification.Pooling3DLayerParams.PoolingType3D
	(Pooling3DLayerParams_Pooling3DPaddingType)(0),      // 9: CoreML.Specification.Pooling3DLayerParams.Pooling3DPaddingType
	(GlobalPooling3DLayerParams_GlobalPoolingType3D)(0), // 10: CoreML.Specification.GlobalPooling3DLayerParams.GlobalPoolingType3D
	(UnaryFunctionLayerParams_Operation)(0),             // 11: CoreML.Specification.UnaryFunctionLayerParams.Operation
	(UpsampleLayerParams_InterpolationMode)(0),          // 12: CoreML.Specification.UpsampleLayerParams.InterpolationMode
	(UpsampleLayerParams_LinearUpsampleMode)(0),         // 13: CoreML.Specification.UpsampleLayerParams.LinearUpsampleMode
	(FlattenLayerParams_FlattenOrder)(0),                // 14: CoreML.Specification.FlattenLayerParams.FlattenOrder
	(ReshapeLayerParams_ReshapeOrder)(0),                // 15: CoreML.Specification.ReshapeLayerParams.ReshapeOrder
	(ReorganizeDataLayerParams_ReorganizationType)(0),   // 16: CoreML.Specification.ReorganizeDataLayerParams.ReorganizationType
	(SliceLayerParams_SliceAxis)(0),                     // 17: CoreML.Specification.SliceLayerParams.SliceAxis
	(ReduceLayerParams_ReduceOperation)(0),              // 18: CoreML.Specification.ReduceLayerParams.ReduceOperation
	(ReduceLayerParams_ReduceAxis)(0),                   // 19: CoreML.Specification.ReduceLayerParams.ReduceAxis
	(GeluLayerParams_GeluMode)(0),                       // 20: CoreML.Specification.GeluLayerParams.GeluMode
	(*NeuralNetwork)(nil),                               // 21: CoreML.Specification.NeuralNetwork
	(*NeuralNetworkImageScaler)(nil),                    // 22: CoreML.Specification.NeuralNetworkImageScaler
	(*NeuralNetworkMeanImage)(nil),                      // 23: CoreML.Specification.NeuralNetworkMeanImage
	(*NeuralNetworkPreprocessing)(nil),                  // 24: CoreML.Specification.NeuralNetworkPreprocessing
	(*ActivationReLU)(nil),                              // 25: CoreML.Specification.ActivationReLU
	(*ActivationLeakyReLU)(nil),                         // 26: CoreML.Specification.ActivationLeakyReLU
	(*ActivationTanh)(nil),                              // 27: CoreML.Specification.ActivationTanh
	(*ActivationScaledTanh)(nil),                        // 28: CoreML.Specification.ActivationScaledTanh
	(*ActivationSigmoid)(nil),                           // 29: CoreML.Specification.ActivationSigmoid
	(*ActivationLinear)(nil),                            // 30: CoreML.Specification.ActivationLinear
	(*ActivationSigmoidHard)(nil),                       // 31: CoreML.Specification.ActivationSigmoidHard
	(*ActivationPReLU)(nil),                             // 32: CoreML.Specification.ActivationPReLU
	(*ActivationELU)(nil),                               // 33: CoreML.Specification.ActivationELU
	(*ActivationThresholdedReLU)(nil),                   // 34: CoreML.Specification.ActivationThresholdedReLU
	(*ActivationSoftsign)(nil),                          // 35: CoreML.Specification.ActivationSoftsign
	(*ActivationSoftplus)(nil),                          // 36: CoreML.Specification.ActivationSoftplus
	(*ActivationParametricSoftplus)(nil),                // 37: CoreML.Specification.ActivationParametricSoftplus
	(*ActivationParams)(nil),                            // 38: CoreML.Specification.ActivationParams
	(*Tensor)(nil),                                      // 39: CoreML.Specification.Tensor
	(*NeuralNetworkLayer)(nil),                          // 40: CoreML.Specification.NeuralNetworkLayer
	(*BranchLayerParams)(nil),                           // 41: CoreML.Specification.BranchLayerParams
	(*LoopLayerParams)(nil),                             // 42: CoreML.Specification.LoopLayerParams
	(*LoopBreakLayerParams)(nil),                        // 43: CoreML.Specification.LoopBreakLayerParams
	(*LoopContinueLayerParams)(nil),                     // 44: CoreML.Specification.LoopContinueLayerParams
	(*CopyLayerParams)(nil),                             // 45: CoreML.Specification.CopyLayerParams
	(*GreaterThanLayerParams)(nil),                      // 46: CoreML.Specification.GreaterThanLayerParams
	(*GreaterEqualLayerParams)(nil),                     // 47: CoreML.Specification.GreaterEqualLayerParams
	(*LessThanLayerParams)(nil),                         // 48: CoreML.Specification.LessThanLayerParams
	(*LessEqualLayerParams)(nil),                        // 49: CoreML.Specification.LessEqualLayerParams
	(*EqualLayerParams)(nil),                            // 50: CoreML.Specification.EqualLayerParams
	(*NotEqualLayerParams)(nil),                         // 51: CoreML.Specification.NotEqualLayerParams
	(*LogicalAndLayerParams)(nil),                       // 52: CoreML.Specification.LogicalAndLayerParams
	(*LogicalOrLayerParams)(nil),                        // 53: CoreML.Specification.LogicalOrLayerParams
	(*LogicalXorLayerParams)(nil),                       // 54: CoreML.Specification.LogicalXorLayerParams
	(*LogicalNotLayerParams)(nil),                       // 55: CoreML.Specification.LogicalNotLayerParams
	(*BorderAmounts)(nil),                               // 56: CoreML.Specification.BorderAmounts
	(*ValidPadding)(nil),                                // 57: CoreML.Specification.ValidPadding
	(*SamePadding)(nil),                                 // 58: CoreML.Specification.SamePadding
	(*SamplingMode)(nil),                                // 59: CoreML.Specification.SamplingMode
	(*BoxCoordinatesMode)(nil),                          // 60: CoreML.Specification.BoxCoordinatesMode
	(*WeightParams)(nil),                                // 61: CoreML.Specification.WeightParams
	(*QuantizationParams)(nil),                          // 62: CoreML.Specification.QuantizationParams
	(*LinearQuantizationParams)(nil),                    // 63: CoreML.Specification.LinearQuantizationParams
	(*LookUpTableQuantizationParams)(nil),               // 64: CoreML.Specification.LookUpTableQuantizationParams
	(*ConvolutionLayerParams)(nil),                      // 65: CoreML.Specification.ConvolutionLayerParams
	(*Convolution3DLayerParams)(nil),                    // 66: CoreML.Specification.Convolution3DLayerParams
	(*InnerProductLayerParams)(nil),                     // 67: CoreML.Specification.InnerProductLayerParams
	(*EmbeddingLayerParams)(nil),                        // 68: CoreML.Specification.EmbeddingLayerParams
	(*EmbeddingNDLayerParams)(nil),                      // 69: CoreML.Specification.EmbeddingNDLayerParams
	(*BatchnormLayerParams)(nil),                        // 70: CoreML.Specification.BatchnormLayerParams
	(*PoolingLayerParams)(nil),                          // 71: CoreML.Specification.PoolingLayerParams
	(*Pooling3DLayerParams)(nil),                        // 72: CoreML.Specification.Pooling3DLayerParams
	(*GlobalPooling3DLayerParams)(nil),                  // 73: CoreML.Specification.GlobalPooling3DLayerParams
	(*PaddingLayerParams)(nil),                          // 74: CoreML.Specification.PaddingLayerParams
	(*ConcatLayerParams)(nil),                           // 75: CoreML.Specification.ConcatLayerParams
	(*LRNLayerParams)(nil),                              // 76: CoreML.Specification.LRNLayerParams
	(*SoftmaxLayerParams)(nil),                          // 77: CoreML.Specification.SoftmaxLayerParams
	(*SplitLayerParams)(nil),                            // 78: CoreML.Specification.SplitLayerParams
	(*AddLayerParams)(nil),                              // 79: CoreML.Specification.AddLayerParams
	(*MultiplyLayerParams)(nil),                         // 80: CoreML.Specification.MultiplyLayerParams
	(*UnaryFunctionLayerParams)(nil),                    // 81: CoreML.Specification.UnaryFunctionLayerParams
	(*UpsampleLayerParams)(nil),                         // 82: CoreML.Specification.UpsampleLayerParams
	(*ResizeBilinearLayerParams)(nil),                   // 83: CoreML.Specification.ResizeBilinearLayerParams
	(*CropResizeLayerParams)(nil),                       // 84: CoreML.Specification.CropResizeLayerParams
	(*BiasLayerParams)(nil),                             // 85: CoreML.Specification.BiasLayerParams
	(*ScaleLayerParams)(nil),                            // 86: CoreML.Specification.ScaleLayerParams
	(*LoadConstantLayerParams)(nil),                     // 87: CoreML.Specification.LoadConstantLayerParams
	(*L2NormalizeLayerParams)(nil),                      // 88: CoreML.Specification.L2NormalizeLayerParams
	(*FlattenLayerParams)(nil),                          // 89: CoreML.Specification.FlattenLayerParams
	(*ReshapeLayerParams)(nil),                          // 90: CoreML.Specification.ReshapeLayerParams
	(*PermuteLayerParams)(nil),                          // 91: CoreML.Specification.PermuteLayerParams
	(*ReorganizeDataLayerParams)(nil),                   // 92: CoreML.Specification.ReorganizeDataLayerParams
	(*SliceLayerParams)(nil),                            // 93: CoreML.Specification.SliceLayerParams
	(*ReduceLayerParams)(nil),                           // 94: CoreML.Specification.ReduceLayerParams
	(*CropLayerParams)(nil),                             // 95: CoreML.Specification.CropLayerParams
	(*AverageLayerParams)(nil),                          // 96: CoreML.Specification.AverageLayerParams
	(*MaxLayerParams)(nil),                              // 97: CoreML.Specification.MaxLayerParams
	(*MinLayerParams)(nil),                              // 98: CoreML.Specification.MinLayerParams
	(*DotProductLayerParams)(nil),                       // 99: CoreML.Specification.DotProductLayerParams
	(*MeanVarianceNormalizeLayerParams)(nil),            // 100: CoreML.Specification.MeanVarianceNormalizeLayerParams
	(*SequenceRepeatLayerParams)(nil),                   // 101: CoreML.Specification.SequenceRepeatLayerParams
	(*SimpleRecurrentLayerParams)(nil),                  // 102: CoreML.Specification.SimpleRecurrentLayerParams
	(*GRULayerParams)(nil),                              // 103: CoreML.Specification.GRULayerParams
	(*LSTMParams)(nil),                                  // 104: CoreML.Specification.LSTMParams
	(*LSTMWeightParams)(nil),                            // 105: CoreML.Specification.LSTMWeightParams
	(*UniDirectionalLSTMLayerParams)(nil),               // 106: CoreML.Specification.UniDirectionalLSTMLayerParams
	(*BiDirectionalLSTMLayerParams)(nil),                // 107: CoreML.Specification.BiDirectionalLSTMLayerParams
	(*CustomLayerParams)(nil),                           // 108: CoreML.Specification.CustomLayerParams
	(*TransposeLayerParams)(nil),                        // 109: CoreML.Specification.TransposeLayerParams
	(*BatchedMatMulLayerParams)(nil),                    // 110: CoreML.Specification.BatchedMatMulLayerParams
	(*ConcatNDLayerParams)(nil),                         // 111: CoreML.Specification.ConcatNDLayerParams
	(*SoftmaxNDLayerParams)(nil),                        // 112: CoreML.Specification.SoftmaxNDLayerParams
	(*ReverseLayerParams)(nil),                          // 113: CoreML.Specification.ReverseLayerParams
	(*ReverseSeqLayerParams)(nil),                       // 114: CoreML.Specification.ReverseSeqLayerParams
	(*LoadConstantNDLayerParams)(nil),                   // 115: CoreML.Specification.LoadConstantNDLayerParams
	(*FillLikeLayerParams)(nil),                         // 116: CoreML.Specification.FillLikeLayerParams
	(*FillStaticLayerParams)(nil),                       // 117: CoreML.Specification.FillStaticLayerParams
	(*FillDynamicLayerParams)(nil),                      // 118: CoreML.Specification.FillDynamicLayerParams
	(*WhereBroadcastableLayerParams)(nil),               // 119: CoreML.Specification.WhereBroadcastableLayerParams
	(*SinLayerParams)(nil),                              // 120: CoreML.Specification.SinLayerParams
	(*CosLayerParams)(nil),                              // 121: CoreML.Specification.CosLayerParams
	(*TanLayerParams)(nil),                              // 122: CoreML.Specification.TanLayerParams
	(*AsinLayerParams)(nil),                             // 123: CoreML.Specification.AsinLayerParams
	(*AcosLayerParams)(nil),                             // 124: CoreML.Specification.AcosLayerParams
	(*AtanLayerParams)(nil),                             // 125: CoreML.Specification.AtanLayerParams
	(*SinhLayerParams)(nil),                             // 126: CoreML.Specification.SinhLayerParams
	(*CoshLayerParams)(nil),                             // 127: CoreML.Specification.CoshLayerParams
	(*TanhLayerParams)(nil),                             // 128: CoreML.Specification.TanhLayerParams
	(*AsinhLayerParams)(nil),                            // 129: CoreML.Specification.AsinhLayerParams
	(*AcoshLayerParams)(nil),                            // 130: CoreML.Specification.AcoshLayerParams
	(*AtanhLayerParams)(nil),                            // 131: CoreML.Specification.AtanhLayerParams
	(*PowBroadcastableLayerParams)(nil),                 // 132: CoreML.Specification.PowBroadcastableLayerParams
	(*Exp2LayerParams)(nil),                             // 133: CoreML.Specification.Exp2LayerParams
	(*WhereNonZeroLayerParams)(nil),                     // 134: CoreML.Specification.WhereNonZeroLayerParams
	(*MatrixBandPartLayerParams)(nil),                   // 135: CoreML.Specification.MatrixBandPartLayerParams
	(*UpperTriangularLayerParams)(nil),                  // 136: CoreML.Specification.UpperTriangularLayerParams
	(*LowerTriangularLayerParams)(nil),                  // 137: CoreML.Specification.LowerTriangularLayerParams
	(*BroadcastToLikeLayerParams)(nil),                  // 138: CoreML.Specification.BroadcastToLikeLayerParams
	(*BroadcastToStaticLayerParams)(nil),                // 139: CoreML.Specification.BroadcastToStaticLayerParams
	(*BroadcastToDynamicLayerParams)(nil),               // 140: CoreML.Specification.BroadcastToDynamicLayerParams
	(*AddBroadcastableLayerParams)(nil),                 // 141: CoreML.Specification.AddBroadcastableLayerParams
	(*MaxBroadcastableLayerParams)(nil),                 // 142: CoreML.Specification.MaxBroadcastableLayerParams
	(*MinBroadcastableLayerParams)(nil),                 // 143: CoreML.Specification.MinBroadcastableLayerParams
	(*ModBroadcastableLayerParams)(nil),                 // 144: CoreML.Specification.ModBroadcastableLayerParams
	(*FloorDivBroadcastableLayerParams)(nil),            // 145: CoreML.Specification.FloorDivBroadcastableLayerParams
	(*SubtractBroadcastableLayerParams)(nil),            // 146: CoreML.Specification.SubtractBroadcastableLayerParams
	(*MultiplyBroadcastableLayerParams)(nil),            // 147: CoreML.Specification.MultiplyBroadcastableLayerParams
	(*DivideBroadcastableLayerParams)(nil),              // 148: CoreML.Specification.DivideBroadcastableLayerParams
	(*GatherLayerParams)(nil),                           // 149: CoreML.Specification.GatherLayerParams
	(*ScatterLayerParams)(nil),                          // 150: CoreML.Specification.ScatterLayerParams
	(*GatherNDLayerParams)(nil),                         // 151: CoreML.Specification.GatherNDLayerParams
	(*ScatterNDLayerParams)(nil),                        // 152: CoreML.Specification.ScatterNDLayerParams
	(*GatherAlongAxisLayerParams)(nil),                  // 153: CoreML.Specification.GatherAlongAxisLayerParams
	(*ScatterAlongAxisLayerParams)(nil),                 // 154: CoreML.Specification.ScatterAlongAxisLayerParams
	(*StackLayerParams)(nil),                            // 155: CoreML.Specification.StackLayerParams
	(*RankPreservingReshapeLayerParams)(nil),            // 156: CoreML.Specification.RankPreservingReshapeLayerParams
	(*ConstantPaddingLayerParams)(nil),                  // 157: CoreML.Specification.ConstantPaddingLayerParams
	(*RandomNormalLikeLayerParams)(nil),                 // 158: CoreML.Specification.RandomNormalLikeLayerParams
	(*RandomNormalStaticLayerParams)(nil),               // 159: CoreML.Specification.RandomNormalStaticLayerParams
	(*RandomNormalDynamicLayerParams)(nil),              // 160: CoreML.Specification.RandomNormalDynamicLayerParams
	(*RandomUniformLikeLayerParams)(nil),                // 161: CoreML.Specification.RandomUniformLikeLayerParams
	(*RandomUniformStaticLayerParams)(nil),              // 162: CoreML.Specification.RandomUniformStaticLayerParams
	(*RandomUniformDynamicLayerParams)(nil),             // 163: CoreML.Specification.RandomUniformDynamicLayerParams
	(*RandomBernoulliLikeLayerParams)(nil),              // 164: CoreML.Specification.RandomBernoulliLikeLayerParams
	(*RandomBernoulliStaticLayerParams)(nil),            // 165: CoreML.Specification.RandomBernoulliStaticLayerParams
	(*RandomBernoulliDynamicLayerParams)(nil),           // 166: CoreML.Specification.RandomBernoulliDynamicLayerParams
	(*CategoricalDistributionLayerParams)(nil),          // 167: CoreML.Specification.CategoricalDistributionLayerParams
	(*ReduceL1LayerParams)(nil),                         // 168: CoreML.Specification.ReduceL1LayerParams
	(*ReduceL2LayerParams)(nil),                         // 169: CoreML.Specification.ReduceL2LayerParams
	(*ReduceMaxLayerParams)(nil),                        // 170: CoreML.Specification.ReduceMaxLayerParams
	(*ReduceMinLayerParams)(nil),                        // 171: CoreML.Specification.ReduceMinLayerParams
	(*ReduceSumLayerParams)(nil),                        // 172: CoreML.Specification.ReduceSumLayerParams
	(*ReduceProdLayerParams)(nil),                       // 173: CoreML.Specification.ReduceProdLayerParams
	(*ReduceMeanLayerParams)(nil),                       // 174: CoreML.Specification.ReduceMeanLayerParams
	(*ReduceLogSumLayerParams)(nil),                     // 175: CoreML.Specification.ReduceLogSumLayerParams
	(*ReduceSumSquareLayerParams)(nil),                  // 176: CoreML.Specification.ReduceSumSquareLayerParams
	(*ReduceLogSumExpLayerParams)(nil),                  // 177: CoreML.Specification.ReduceLogSumExpLayerParams
	(*ExpandDimsLayerParams)(nil),                       // 178: CoreML.Specification.ExpandDimsLayerParams
	(*FlattenTo2DLayerParams)(nil),                      // 179: CoreML.Specification.FlattenTo2DLayerParams
	(*ReshapeStaticLayerParams)(nil),                    // 180: CoreML.Specification.ReshapeStaticLayerParams
	(*ReshapeLikeLayerParams)(nil),                      // 181: CoreML.Specification.ReshapeLikeLayerParams
	(*ReshapeDynamicLayerParams)(nil),                   // 182: CoreML.Specification.ReshapeDynamicLayerParams
	(*SqueezeLayerParams)(nil),                          // 183: CoreML.Specification.SqueezeLayerParams
	(*TopKLayerParams)(nil),                             // 184: CoreML.Specification.TopKLayerParams
	(*ArgMaxLayerParams)(nil),                           // 185: CoreML.Specification.ArgMaxLayerParams
	(*ArgMinLayerParams)(nil),                           // 186: CoreML.Specification.ArgMinLayerParams
	(*SplitNDLayerParams)(nil),                          // 187: CoreML.Specification.SplitNDLayerParams
	(*CeilLayerParams)(nil),                             // 188: CoreML.Specification.CeilLayerParams
	(*RoundLayerParams)(nil),                            // 189: CoreML.Specification.RoundLayerParams
	(*FloorLayerParams)(nil),                            // 190: CoreML.Specification.FloorLayerParams
	(*SignLayerParams)(nil),                             // 191: CoreML.Specification.SignLayerParams
	(*ClipLayerParams)(nil),                             // 192: CoreML.Specification.ClipLayerParams
	(*SliceStaticLayerParams)(nil),                      // 193: CoreML.Specification.SliceStaticLayerParams
	(*SliceDynamicLayerParams)(nil),                     // 194: CoreML.Specification.SliceDynamicLayerParams
	(*TileLayerParams)(nil),                             // 195: CoreML.Specification.TileLayerParams
	(*GetShapeLayerParams)(nil),                         // 196: CoreML.Specification.GetShapeLayerParams
	(*ErfLayerParams)(nil),                              // 197: CoreML.Specification.ErfLayerParams
	(*GeluLayerParams)(nil),                             // 198: CoreML.Specification.GeluLayerParams
	(*RangeStaticLayerParams)(nil),                      // 199: CoreML.Specification.RangeStaticLayerParams
	(*RangeDynamicLayerParams)(nil),                     // 200: CoreML.Specification.RangeDynamicLayerParams
	(*SlidingWindowsLayerParams)(nil),                   // 201: CoreML.Specification.SlidingWindowsLayerParams
	(*LayerNormalizationLayerParams)(nil),               // 202: CoreML.Specification.LayerNormalizationLayerParams
	(*NonMaximumSuppressionLayerParams)(nil),            // 203: CoreML.Specification.NonMaximumSuppressionLayerParams
	(*ClampedReLULayerParams)(nil),                      // 204: CoreML.Specification.ClampedReLULayerParams
	(*ArgSortLayerParams)(nil),                          // 205: CoreML.Specification.ArgSortLayerParams
	(*SliceBySizeLayerParams)(nil),                      // 206: CoreML.Specification.SliceBySizeLayerParams
	(*NeuralNetworkClassifier)(nil),                     // 207: CoreML.Specification.NeuralNetworkClassifier
	(*OneHotLayerParams)(nil),                           // 208: CoreML.Specification.OneHotLayerParams
	(*CumSumLayerParams)(nil),                           // 209: CoreML.Specification.CumSumLayerParams
	(*NeuralNetworkRegressor)(nil),                      // 210: CoreML.Specification.NeuralNetworkRegressor
	(*NetworkUpdateParameters)(nil),                     // 211: CoreML.Specification.NetworkUpdateParameters
	(*LossLayer)(nil),                                   // 212: CoreML.Specification.LossLayer
	(*CategoricalCrossEntropyLossLayer)(nil),            // 213: CoreML.Specification.CategoricalCrossEntropyLossLayer
	(*MeanSquaredErrorLossLayer)(nil),                   // 214: CoreML.Specification.MeanSquaredErrorLossLayer
	(*Optimizer)(nil),                                   // 215: CoreML.Specification.Optimizer
	(*SGDOptimizer)(nil),                                // 216: CoreML.Specification.SGDOptimizer
	(*AdamOptimizer)(nil),                               // 217: CoreML.Specification.AdamOptimizer
	(*BorderAmounts_EdgeSizes)(nil),                     // 218: CoreML.Specification.BorderAmounts.EdgeSizes
	(*PoolingLayerParams_ValidCompletePadding)(nil),     // 219: CoreML.Specification.PoolingLayerParams.ValidCompletePadding
	(*PaddingLayerParams_PaddingConstant)(nil),          // 220: CoreML.Specification.PaddingLayerParams.PaddingConstant
	(*PaddingLayerParams_PaddingReflection)(nil),        // 221: CoreML.Specification.PaddingLayerParams.PaddingReflection
	(*PaddingLayerParams_PaddingReplication)(nil),       // 222: CoreML.Specification.PaddingLayerParams.PaddingReplication
	(*CustomLayerParams_CustomLayerParamValue)(nil),     // 223: CoreML.Specification.CustomLayerParams.CustomLayerParamValue
	nil,                     // 224: CoreML.Specification.CustomLayerParams.ParametersEntry
	(*StringVector)(nil),    // 225: CoreML.Specification.StringVector
	(*Int64Vector)(nil),     // 226: CoreML.Specification.Int64Vector
	(*Int64Parameter)(nil),  // 227: CoreML.Specification.Int64Parameter
	(*BoolParameter)(nil),   // 228: CoreML.Specification.BoolParameter
	(*DoubleParameter)(nil), // 229: CoreML.Specification.DoubleParameter
}
var file_NeuralNetwork_proto_depIdxs = []int32{
	40,  // 0: CoreML.Specification.NeuralNetwork.layers:type_name -> CoreML.Specification.NeuralNetworkLayer
	24,  // 1: CoreML.Specification.NeuralNetwork.preprocessing:type_name -> CoreML.Specification.NeuralNetworkPreprocessing
	0,   // 2: CoreML.Specification.NeuralNetwork.arrayInputShapeMapping:type_name -> CoreML.Specification.NeuralNetworkMultiArrayShapeMapping
	1,   // 3: CoreML.Specification.NeuralNetwork.imageInputShapeMapping:type_name -> CoreML.Specification.NeuralNetworkImageShapeMapping
	211, // 4: CoreML.Specification.NeuralNetwork.updateParams:type_name -> CoreML.Specification.NetworkUpdateParameters
	22,  // 5: CoreML.Specification.NeuralNetworkPreprocessing.scaler:type_name -> CoreML.Specification.NeuralNetworkImageScaler
	23,  // 6: CoreML.Specification.NeuralNetworkPreprocessing.meanImage:type_name -> CoreML.Specification.NeuralNetworkMeanImage
	61,  // 7: CoreML.Specification.ActivationPReLU.alpha:type_name -> CoreML.Specification.WeightParams
	61,  // 8: CoreML.Specification.ActivationParametricSoftplus.alpha:type_name -> CoreML.Specification.WeightParams
	61,  // 9: CoreML.Specification.ActivationParametricSoftplus.beta:type_name -> CoreML.Specification.WeightParams
	30,  // 10: CoreML.Specification.ActivationParams.linear:type_name -> CoreML.Specification.ActivationLinear
	25,  // 11: CoreML.Specification.ActivationParams.ReLU:type_name -> CoreML.Specification.ActivationReLU
	26,  // 12: CoreML.Specification.ActivationParams.leakyReLU:type_name -> CoreML.Specification.ActivationLeakyReLU
	34,  // 13: CoreML.Specification.ActivationParams.thresholdedReLU:type_name -> CoreML.Specification.ActivationThresholdedReLU
	32,  // 14: CoreML.Specification.ActivationParams.PReLU:type_name -> CoreML.Specification.ActivationPReLU
	27,  // 15: CoreML.Specification.ActivationParams.tanh:type_name -> CoreML.Specification.ActivationTanh
	28,  // 16: CoreML.Specification.ActivationParams.scaledTanh:type_name -> CoreML.Specification.ActivationScaledTanh
	29,  // 17: CoreML.Specification.ActivationParams.sigmoid:type_name -> CoreML.Specification.ActivationSigmoid
	31,  // 18: CoreML.Specification.ActivationParams.sigmoidHard:type_name -> CoreML.Specification.ActivationSigmoidHard
	33,  // 19: CoreML.Specification.ActivationParams.ELU:type_name -> CoreML.Specification.ActivationELU
	35,  // 20: CoreML.Specification.ActivationParams.softsign:type_name -> CoreML.Specification.ActivationSoftsign
	36,  // 21: CoreML.Specification.ActivationParams.softplus:type_name -> CoreML.Specification.ActivationSoftplus
	37,  // 22: CoreML.Specification.ActivationParams.parametricSoftplus:type_name -> CoreML.Specification.ActivationParametricSoftplus
	39,  // 23: CoreML.Specification.NeuralNetworkLayer.inputTensor:type_name -> CoreML.Specification.Tensor
	39,  // 24: CoreML.Specification.NeuralNetworkLayer.outputTensor:type_name -> CoreML.Specification.Tensor
	65,  // 25: CoreML.Specification.NeuralNetworkLayer.convolution:type_name -> CoreML.Specification.ConvolutionLayerParams
	71,  // 26: CoreML.Specification.NeuralNetworkLayer.pooling:type_name -> CoreML.Specification.PoolingLayerParams
	38,  // 27: CoreML.Specification.NeuralNetworkLayer.activation:type_name -> CoreML.Specification.ActivationParams
	67,  // 28: CoreML.Specification.NeuralNetworkLayer.innerProduct:type_name -> CoreML.Specification.InnerProductLayerParams
	68,  // 29: CoreML.Specification.NeuralNetworkLayer.embedding:type_name -> CoreML.Specification.EmbeddingLayerParams
	70,  // 30: CoreML.Specification.NeuralNetworkLayer.batchnorm:type_name -> CoreML.Specification.BatchnormLayerParams
	100, // 31: CoreML.Specification.NeuralNetworkLayer.mvn:type_name -> CoreML.Specification.MeanVarianceNormalizeLayerParams
	88,  // 32: CoreML.Specification.NeuralNetworkLayer.l2normalize:type_name -> CoreML.Specification.L2NormalizeLayerParams
	77,  // 33: CoreML.Specification.NeuralNetworkLayer.softmax:type_name -> CoreML.Specification.SoftmaxLayerParams
	76,  // 34: CoreML.Specification.NeuralNetworkLayer.lrn:type_name -> CoreML.Specification.LRNLayerParams
	95,  // 35: CoreML.Specification.NeuralNetworkLayer.crop:type_name -> CoreML.Specification.CropLayerParams
	74,  // 36: CoreML.Specification.NeuralNetworkLayer.padding:type_name -> CoreML.Specification.PaddingLayerParams
	82,  // 37: CoreML.Specification.NeuralNetworkLayer.upsample:type_name -> CoreML.Specification.UpsampleLayerParams
	83,  // 38: CoreML.Specification.NeuralNetworkLayer.resizeBilinear:type_name -> CoreML.Specification.ResizeBilinearLayerParams
	84,  // 39: CoreML.Specification.NeuralNetworkLayer.cropResize:type_name -> CoreML.Specification.CropResizeLayerParams
	81,  // 40: CoreML.Specification.NeuralNetworkLayer.unary:type_name -> CoreML.Specification.UnaryFunctionLayerParams
	79,  // 41: CoreML.Specification.NeuralNetworkLayer.add:type_name -> CoreML.Specification.AddLayerParams
	80,  // 42: CoreML.Specification.NeuralNetworkLayer.multiply:type_name -> CoreML.Specification.MultiplyLayerParams
	96,  // 43: CoreML.Specification.NeuralNetworkLayer.average:type_name -> CoreML.Specification.AverageLayerParams
	86,  // 44: CoreML.Specification.NeuralNetworkLayer.scale:type_name -> CoreML.Specification.ScaleLayerParams
	85,  // 45: CoreML.Specification.NeuralNetworkLayer.bias:type_name -> CoreML.Specification.BiasLayerParams
	97,  // 46: CoreML.Specification.NeuralNetworkLayer.max:type_name -> CoreML.Specification.MaxLayerParams
	98,  // 47: CoreML.Specification.NeuralNetworkLayer.min:type_name -> CoreML.Specification.MinLayerParams
	99,  // 48: CoreML.Specification.NeuralNetworkLayer.dot:type_name -> CoreML.Specification.DotProductLayerParams
	94,  // 49: CoreML.Specification.NeuralNetworkLayer.reduce:type_name -> CoreML.Specification.ReduceLayerParams
	87,  // 50: CoreML.Specification.NeuralNetworkLayer.loadConstant:type_name -> CoreML.Specification.LoadConstantLayerParams
	90,  // 51: CoreML.Specification.NeuralNetworkLayer.reshape:type_name -> CoreML.Specification.ReshapeLayerParams
	89,  // 52: CoreML.Specification.NeuralNetworkLayer.flatten:type_name -> CoreML.Specification.FlattenLayerParams
	91,  // 53: CoreML.Specification.NeuralNetworkLayer.permute:type_name -> CoreML.Specification.PermuteLayerParams
	75,  // 54: CoreML.Specification.NeuralNetworkLayer.concat:type_name -> CoreML.Specification.ConcatLayerParams
	78,  // 55: CoreML.Specification.NeuralNetworkLayer.split:type_name -> CoreML.Specification.SplitLayerParams
	101, // 56: CoreML.Specification.NeuralNetworkLayer.sequenceRepeat:type_name -> CoreML.Specification.SequenceRepeatLayerParams
	92,  // 57: CoreML.Specification.NeuralNetworkLayer.reorganizeData:type_name -> CoreML.Specification.ReorganizeDataLayerParams
	93,  // 58: CoreML.Specification.NeuralNetworkLayer.slice:type_name -> CoreML.Specification.SliceLayerParams
	102, // 59: CoreML.Specification.NeuralNetworkLayer.simpleRecurrent:type_name -> CoreML.Specification.SimpleRecurrentLayerParams
	103, // 60: CoreML.Specification.NeuralNetworkLayer.gru:type_name -> CoreML.Specification.GRULayerParams
	106, // 61: CoreML.Specification.NeuralNetworkLayer.uniDirectionalLSTM:type_name -> CoreML.Specification.UniDirectionalLSTMLayerParams
	107, // 62: CoreML.Specification.NeuralNetworkLayer.biDirectionalLSTM:type_name -> CoreML.Specification.BiDirectionalLSTMLayerParams
	108, // 63: CoreML.Specification.NeuralNetworkLayer.custom:type_name -> CoreML.Specification.CustomLayerParams
	45,  // 64: CoreML.Specification.NeuralNetworkLayer.copy:type_name -> CoreML.Specification.CopyLayerParams
	41,  // 65: CoreML.Specification.NeuralNetworkLayer.branch:type_name -> CoreML.Specification.BranchLayerParams
	42,  // 66: CoreML.Specification.NeuralNetworkLayer.loop:type_name -> CoreML.Specification.LoopLayerParams
	43,  // 67: CoreML.Specification.NeuralNetworkLayer.loopBreak:type_name -> CoreML.Specification.LoopBreakLayerParams
	44,  // 68: CoreML.Specification.NeuralNetworkLayer.loopContinue:type_name -> CoreML.Specification.LoopContinueLayerParams
	199, // 69: CoreML.Specification.NeuralNetworkLayer.rangeStatic:type_name -> CoreML.Specification.RangeStaticLayerParams
	200, // 70: CoreML.Specification.NeuralNetworkLayer.rangeDynamic:type_name -> CoreML.Specification.RangeDynamicLayerParams
	192, // 71: CoreML.Specification.NeuralNetworkLayer.clip:type_name -> CoreML.Specification.ClipLayerParams
	188, // 72: CoreML.Specification.NeuralNetworkLayer.ceil:type_name -> CoreML.Specification.CeilLayerParams
	190, // 73: CoreML.Specification.NeuralNetworkLayer.floor:type_name -> CoreML.Specification.FloorLayerParams
	191, // 74: CoreML.Specification.NeuralNetworkLayer.sign:type_name -> CoreML.Specification.SignLayerParams
	189, // 75: CoreML.Specification.NeuralNetworkLayer.round:type_name -> CoreML.Specification.RoundLayerParams
	133, // 76: CoreML.Specification.NeuralNetworkLayer.exp2:type_name -> CoreML.Specification.Exp2LayerParams
	120, // 77: CoreML.Specification.NeuralNetworkLayer.sin:type_name -> CoreML.Specification.SinLayerParams
	121, // 78: CoreML.Specification.NeuralNetworkLayer.cos:type_name -> CoreML.Specification.CosLayerParams
	122, // 79: CoreML.Specification.NeuralNetworkLayer.tan:type_name -> CoreML.Specification.TanLayerParams
	123, // 80: CoreML.Specification.NeuralNetworkLayer.asin:type_name -> CoreML.Specification.AsinLayerParams
	124, // 81: CoreML.Specification.NeuralNetworkLayer.acos:type_name -> CoreML.Specification.AcosLayerParams
	125, // 82: CoreML.Specification.NeuralNetworkLayer.atan:type_name -> CoreML.Specification.AtanLayerParams
	126, // 83: CoreML.Specification.NeuralNetworkLayer.sinh:type_name -> CoreML.Specification.SinhLayerParams
	127, // 84: CoreML.Specification.NeuralNetworkLayer.cosh:type_name -> CoreML.Specification.CoshLayerParams
	128, // 85: CoreML.Specification.NeuralNetworkLayer.tanh:type_name -> CoreML.Specification.TanhLayerParams
	129, // 86: CoreML.Specification.NeuralNetworkLayer.asinh:type_name -> CoreML.Specification.AsinhLayerParams
	130, // 87: CoreML.Specification.NeuralNetworkLayer.acosh:type_name -> CoreML.Specification.AcoshLayerParams
	131, // 88: CoreML.Specification.NeuralNetworkLayer.atanh:type_name -> CoreML.Specification.AtanhLayerParams
	197, // 89: CoreML.Specification.NeuralNetworkLayer.erf:type_name -> CoreML.Specification.ErfLayerParams
	198, // 90: CoreML.Specification.NeuralNetworkLayer.gelu:type_name -> CoreML.Specification.GeluLayerParams
	50,  // 91: CoreML.Specification.NeuralNetworkLayer.equal:type_name -> CoreML.Specification.EqualLayerParams
	51,  // 92: CoreML.Specification.NeuralNetworkLayer.notEqual:type_name -> CoreML.Specification.NotEqualLayerParams
	48,  // 93: CoreML.Specification.NeuralNetworkLayer.lessThan:type_name -> CoreML.Specification.LessThanLayerParams
	49,  // 94: CoreML.Specification.NeuralNetworkLayer.lessEqual:type_name -> CoreML.Specification.LessEqualLayerParams
	46,  // 95: CoreML.Specification.NeuralNetworkLayer.greaterThan:type_name -> CoreML.Specification.GreaterThanLayerParams
	47,  // 96: CoreML.Specification.NeuralNetworkLayer.greaterEqual:type_name -> CoreML.Specification.GreaterEqualLayerParams
	53,  // 97: CoreML.Specification.NeuralNetworkLayer.logicalOr:type_name -> CoreML.Specification.LogicalOrLayerParams
	54,  // 98: CoreML.Specification.NeuralNetworkLayer.logicalXor:type_name -> CoreML.Specification.LogicalXorLayerParams
	55,  // 99: CoreML.Specification.NeuralNetworkLayer.logicalNot:type_name -> CoreML.Specification.LogicalNotLayerParams
	52,  // 100: CoreML.Specification.NeuralNetworkLayer.logicalAnd:type_name -> CoreML.Specification.LogicalAndLayerParams
	144, // 101: CoreML.Specification.NeuralNetworkLayer.modBroadcastable:type_name -> CoreML.Specification.ModBroadcastableLayerParams
	143, // 102: CoreML.Specification.NeuralNetworkLayer.minBroadcastable:type_name -> CoreML.Specification.MinBroadcastableLayerParams
	142, // 103: CoreML.Specification.NeuralNetworkLayer.maxBroadcastable:type_name -> CoreML.Specification.MaxBroadcastableLayerParams
	141, // 104: CoreML.Specification.NeuralNetworkLayer.addBroadcastable:type_name -> CoreML.Specification.AddBroadcastableLayerParams
	132, // 105: CoreML.Specification.NeuralNetworkLayer.powBroadcastable:type_name -> CoreML.Specification.PowBroadcastableLayerParams
	148, // 106: CoreML.Specification.NeuralNetworkLayer.divideBroadcastable:type_name -> CoreML.Specification.DivideBroadcastableLayerParams
	145, // 107: CoreML.Specification.NeuralNetworkLayer.floorDivBroadcastable:type_name -> CoreML.Specification.FloorDivBroadcastableLayerParams
	147, // 108: CoreML.Specification.NeuralNetworkLayer.multiplyBroadcastable:type_name -> CoreML.Specification.MultiplyBroadcastableLayerParams
	146, // 109: CoreML.Specification.NeuralNetworkLayer.subtractBroadcastable:type_name -> CoreML.Specification.SubtractBroadcastableLayerParams
	195, // 110: CoreML.Specification.NeuralNetworkLayer.tile:type_name -> CoreML.Specification.TileLayerParams
	155, // 111: CoreML.Specification.NeuralNetworkLayer.stack:type_name -> CoreML.Specification.StackLayerParams
	149, // 112: CoreML.Specification.NeuralNetworkLayer.gather:type_name -> CoreML.Specification.GatherLayerParams
	150, // 113: CoreML.Specification.NeuralNetworkLayer.scatter:type_name -> CoreML.Specification.ScatterLayerParams
	151, // 114: CoreML.Specification.NeuralNetworkLayer.gatherND:type_name -> CoreML.Specification.GatherNDLayerParams
	152, // 115: CoreML.Specification.NeuralNetworkLayer.scatterND:type_name -> CoreML.Specification.ScatterNDLayerParams
	112, // 116: CoreML.Specification.NeuralNetworkLayer.softmaxND:type_name -> CoreML.Specification.SoftmaxNDLayerParams
	153, // 117: CoreML.Specification.NeuralNetworkLayer.gatherAlongAxis:type_name -> CoreML.Specification.GatherAlongAxisLayerParams
	154, // 118: CoreML.Specification.NeuralNetworkLayer.scatterAlongAxis:type_name -> CoreML.Specification.ScatterAlongAxisLayerParams
	113, // 119: CoreML.Specification.NeuralNetworkLayer.reverse:type_name -> CoreML.Specification.ReverseLayerParams
	114, // 120: CoreML.Specification.NeuralNetworkLayer.reverseSeq:type_name -> CoreML.Specification.ReverseSeqLayerParams
	187, // 121: CoreML.Specification.NeuralNetworkLayer.splitND:type_name -> CoreML.Specification.SplitNDLayerParams
	111, // 122: CoreML.Specification.NeuralNetworkLayer.concatND:type_name -> CoreML.Specification.ConcatNDLayerParams
	109, // 123: CoreML.Specification.NeuralNetworkLayer.transpose:type_name -> CoreML.Specification.TransposeLayerParams
	193, // 124: CoreML.Specification.NeuralNetworkLayer.sliceStatic:type_name -> CoreML.Specification.SliceStaticLayerParams
	194, // 125: CoreML.Specification.NeuralNetworkLayer.sliceDynamic:type_name -> CoreML.Specification.SliceDynamicLayerParams
	201, // 126: CoreML.Specification.NeuralNetworkLayer.slidingWindows:type_name -> CoreML.Specification.SlidingWindowsLayerParams
	184, // 127: CoreML.Specification.NeuralNetworkLayer.topK:type_name -> CoreML.Specification.TopKLayerParams
	186, // 128: CoreML.Specification.NeuralNetworkLayer.argMin:type_name -> CoreML.Specification.ArgMinLayerParams
	185, // 129: CoreML.Specification.NeuralNetworkLayer.argMax:type_name -> CoreML.Specification.ArgMaxLayerParams
	69,  // 130: CoreML.Specification.NeuralNetworkLayer.embeddingND:type_name -> CoreML.Specification.EmbeddingNDLayerParams
	110, // 131: CoreML.Specification.NeuralNetworkLayer.batchedMatmul:type_name -> CoreML.Specification.BatchedMatMulLayerParams
	196, // 132: CoreML.Specification.NeuralNetworkLayer.getShape:type_name -> CoreML.Specification.GetShapeLayerParams
	115, // 133: CoreML.Specification.NeuralNetworkLayer.loadConstantND:type_name -> CoreML.Specification.LoadConstantNDLayerParams
	116, // 134: CoreML.Specification.NeuralNetworkLayer.fillLike:type_name -> CoreML.Specification.FillLikeLayerParams
	117, // 135: CoreML.Specification.NeuralNetworkLayer.fillStatic:type_name -> CoreML.Specification.FillStaticLayerParams
	118, // 136: CoreML.Specification.NeuralNetworkLayer.fillDynamic:type_name -> CoreML.Specification.FillDynamicLayerParams
	138, // 137: CoreML.Specification.NeuralNetworkLayer.broadcastToLike:type_name -> CoreML.Specification.BroadcastToLikeLayerParams
	139, // 138: CoreML.Specification.NeuralNetworkLayer.broadcastToStatic:type_name -> CoreML.Specification.BroadcastToStaticLayerParams
	140, // 139: CoreML.Specification.NeuralNetworkLayer.broadcastToDynamic:type_name -> CoreML.Specification.BroadcastToDynamicLayerParams
	183, // 140: CoreML.Specification.NeuralNetworkLayer.squeeze:type_name -> CoreML.Specification.SqueezeLayerParams
	178, // 141: CoreML.Specification.NeuralNetworkLayer.expandDims:type_name -> CoreML.Specification.ExpandDimsLayerParams
	179, // 142: CoreML.Specification.NeuralNetworkLayer.flattenTo2D:type_name -> CoreML.Specification.FlattenTo2DLayerParams
	181, // 143: CoreML.Specification.NeuralNetworkLayer.reshapeLike:type_name -> CoreML.Specification.ReshapeLikeLayerParams
	180, // 144: CoreML.Specification.NeuralNetworkLayer.reshapeStatic:type_name -> CoreML.Specification.ReshapeStaticLayerParams
	182, // 145: CoreML.Specification.NeuralNetworkLayer.reshapeDynamic:type_name -> CoreML.Specification.ReshapeDynamicLayerParams
	156, // 146: CoreML.Specification.NeuralNetworkLayer.rankPreservingReshape:type_name -> CoreML.Specification.RankPreservingReshapeLayerParams
	157, // 147: CoreML.Specification.NeuralNetworkLayer.constantPad:type_name -> CoreML.Specification.ConstantPaddingLayerParams
	158, // 148: CoreML.Specification.NeuralNetworkLayer.randomNormalLike:type_name -> CoreML.Specification.RandomNormalLikeLayerParams
	159, // 149: CoreML.Specification.NeuralNetworkLayer.randomNormalStatic:type_name -> CoreML.Specification.RandomNormalStaticLayerParams
	160, // 150: CoreML.Specification.NeuralNetworkLayer.randomNormalDynamic:type_name -> CoreML.Specification.RandomNormalDynamicLayerParams
	161, // 151: CoreML.Specification.NeuralNetworkLayer.randomUniformLike:type_name -> CoreML.Specification.RandomUniformLikeLayerParams
	162, // 152: CoreML.Specification.NeuralNetworkLayer.randomUniformStatic:type_name -> CoreML.Specification.RandomUniformStaticLayerParams
	163, // 153: CoreML.Specification.NeuralNetworkLayer.randomUniformDynamic:type_name -> CoreML.Specification.RandomUniformDynamicLayerParams
	164, // 154: CoreML.Specification.NeuralNetworkLayer.randomBernoulliLike:type_name -> CoreML.Specification.RandomBernoulliLikeLayerParams
	165, // 155: CoreML.Specification.NeuralNetworkLayer.randomBernoulliStatic:type_name -> CoreML.Specification.RandomBernoulliStaticLayerParams
	166, // 156: CoreML.Specification.NeuralNetworkLayer.randomBernoulliDynamic:type_name -> CoreML.Specification.RandomBernoulliDynamicLayerParams
	167, // 157: CoreML.Specification.NeuralNetworkLayer.categoricalDistribution:type_name -> CoreML.Specification.CategoricalDistributionLayerParams
	168, // 158: CoreML.Specification.NeuralNetworkLayer.reduceL1:type_name -> CoreML.Specification.ReduceL1LayerParams
	169, // 159: CoreML.Specification.NeuralNetworkLayer.reduceL2:type_name -> CoreML.Specification.ReduceL2LayerParams
	170, // 160: CoreML.Specification.NeuralNetworkLayer.reduceMax:type_name -> CoreML.Specification.ReduceMaxLayerParams
	171, // 161: CoreML.Specification.NeuralNetworkLayer.reduceMin:type_name -> CoreML.Specification.ReduceMinLayerParams
	172, // 162: CoreML.Specification.NeuralNetworkLayer.reduceSum:type_name -> CoreML.Specification.ReduceSumLayerParams
	173, // 163: CoreML.Specification.NeuralNetworkLayer.reduceProd:type_name -> CoreML.Specification.ReduceProdLayerParams
	174, // 164: CoreML.Specification.NeuralNetworkLayer.reduceMean:type_name -> CoreML.Specification.ReduceMeanLayerParams
	175, // 165: CoreML.Specification.NeuralNetworkLayer.reduceLogSum:type_name -> CoreML.Specification.ReduceLogSumLayerParams
	176, // 166: CoreML.Specification.NeuralNetworkLayer.reduceSumSquare:type_name -> CoreML.Specification.ReduceSumSquareLayerParams
	177, // 167: CoreML.Specification.NeuralNetworkLayer.reduceLogSumExp:type_name -> CoreML.Specification.ReduceLogSumExpLayerParams
	134, // 168: CoreML.Specification.NeuralNetworkLayer.whereNonZero:type_name -> CoreML.Specification.WhereNonZeroLayerParams
	135, // 169: CoreML.Specification.NeuralNetworkLayer.matrixBandPart:type_name -> CoreML.Specification.MatrixBandPartLayerParams
	137, // 170: CoreML.Specification.NeuralNetworkLayer.lowerTriangular:type_name -> CoreML.Specification.LowerTriangularLayerParams
	136, // 171: CoreML.Specification.NeuralNetworkLayer.upperTriangular:type_name -> CoreML.Specification.UpperTriangularLayerParams
	119, // 172: CoreML.Specification.NeuralNetworkLayer.whereBroadcastable:type_name -> CoreML.Specification.WhereBroadcastableLayerParams
	202, // 173: CoreML.Specification.NeuralNetworkLayer.layerNormalization:type_name -> CoreML.Specification.LayerNormalizationLayerParams
	203, // 174: CoreML.Specification.NeuralNetworkLayer.NonMaximumSuppression:type_name -> CoreML.Specification.NonMaximumSuppressionLayerParams
	208, // 175: CoreML.Specification.NeuralNetworkLayer.oneHot:type_name -> CoreML.Specification.OneHotLayerParams
	209, // 176: CoreML.Specification.NeuralNetworkLayer.cumSum:type_name -> CoreML.Specification.CumSumLayerParams
	204, // 177: CoreML.Specification.NeuralNetworkLayer.clampedReLU:type_name -> CoreML.Specification.ClampedReLULayerParams
	205, // 178: CoreML.Specification.NeuralNetworkLayer.argSort:type_name -> CoreML.Specification.ArgSortLayerParams
	72,  // 179: CoreML.Specification.NeuralNetworkLayer.pooling3d:type_name -> CoreML.Specification.Pooling3DLayerParams
	73,  // 180: CoreML.Specification.NeuralNetworkLayer.globalPooling3d:type_name -> CoreML.Specification.GlobalPooling3DLayerParams
	206, // 181: CoreML.Specification.NeuralNetworkLayer.sliceBySize:type_name -> CoreML.Specification.SliceBySizeLayerParams
	66,  // 182: CoreML.Specification.NeuralNetworkLayer.convolution3d:type_name -> CoreML.Specification.Convolution3DLayerParams
	21,  // 183: CoreML.Specification.BranchLayerParams.ifBranch:type_name -> CoreML.Specification.NeuralNetwork
	21,  // 184: CoreML.Specification.BranchLayerParams.elseBranch:type_name -> CoreML.Specification.NeuralNetwork
	21,  // 185: CoreML.Specification.LoopLayerParams.conditionNetwork:type_name -> CoreML.Specification.NeuralNetwork
	21,  // 186: CoreML.Specification.LoopLayerParams.bodyNetwork:type_name -> CoreML.Specification.NeuralNetwork
	218, // 187: CoreML.Specification.BorderAmounts.borderAmounts:type_name -> CoreML.Specification.BorderAmounts.EdgeSizes
	56,  // 188: CoreML.Specification.ValidPadding.paddingAmounts:type_name -> CoreML.Specification.BorderAmounts
	3,   // 189: CoreML.Specification.SamePadding.asymmetryMode:type_name -> CoreML.Specification.SamePadding.SamePaddingMode
	4,   // 190: CoreML.Specification.SamplingMode.samplingMethod:type_name -> CoreML.Specification.SamplingMode.Method
	5,   // 191: CoreML.Specification.BoxCoordinatesMode.boxMode:type_name -> CoreML.Specification.BoxCoordinatesMode.Coordinates
	62,  // 192: CoreML.Specification.WeightParams.quantization:type_name -> CoreML.Specification.QuantizationParams
	63,  // 193: CoreML.Specification.QuantizationParams.linearQuantization:type_name -> CoreML.Specification.LinearQuantizationParams
	64,  // 194: CoreML.Specification.QuantizationParams.lookupTableQuantization:type_name -> CoreML.Specification.LookUpTableQuantizationParams
	57,  // 195: CoreML.Specification.ConvolutionLayerParams.valid:type_name -> CoreML.Specification.ValidPadding
	58,  // 196: CoreML.Specification.ConvolutionLayerParams.same:type_name -> CoreML.Specification.SamePadding
	61,  // 197: CoreML.Specification.ConvolutionLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	61,  // 198: CoreML.Specification.ConvolutionLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 199: CoreML.Specification.Convolution3DLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	61,  // 200: CoreML.Specification.Convolution3DLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	6,   // 201: CoreML.Specification.Convolution3DLayerParams.paddingType:type_name -> CoreML.Specification.Convolution3DLayerParams.PaddingType
	61,  // 202: CoreML.Specification.InnerProductLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	61,  // 203: CoreML.Specification.InnerProductLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 204: CoreML.Specification.EmbeddingLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	61,  // 205: CoreML.Specification.EmbeddingLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 206: CoreML.Specification.EmbeddingNDLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	61,  // 207: CoreML.Specification.EmbeddingNDLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 208: CoreML.Specification.BatchnormLayerParams.gamma:type_name -> CoreML.Specification.WeightParams
	61,  // 209: CoreML.Specification.BatchnormLayerParams.beta:type_name -> CoreML.Specification.WeightParams
	61,  // 210: CoreML.Specification.BatchnormLayerParams.mean:type_name -> CoreML.Specification.WeightParams
	61,  // 211: CoreML.Specification.BatchnormLayerParams.variance:type_name -> CoreML.Specification.WeightParams
	7,   // 212: CoreML.Specification.PoolingLayerParams.type:type_name -> CoreML.Specification.PoolingLayerParams.PoolingType
	57,  // 213: CoreML.Specification.PoolingLayerParams.valid:type_name -> CoreML.Specification.ValidPadding
	58,  // 214: CoreML.Specification.PoolingLayerParams.same:type_name -> CoreML.Specification.SamePadding
	219, // 215: CoreML.Specification.PoolingLayerParams.includeLastPixel:type_name -> CoreML.Specification.PoolingLayerParams.ValidCompletePadding
	8,   // 216: CoreML.Specification.Pooling3DLayerParams.type:type_name -> CoreML.Specification.Pooling3DLayerParams.PoolingType3D
	9,   // 217: CoreML.Specification.Pooling3DLayerParams.paddingType:type_name -> CoreML.Specification.Pooling3DLayerParams.Pooling3DPaddingType
	10,  // 218: CoreML.Specification.GlobalPooling3DLayerParams.type:type_name -> CoreML.Specification.GlobalPooling3DLayerParams.GlobalPoolingType3D
	220, // 219: CoreML.Specification.PaddingLayerParams.constant:type_name -> CoreML.Specification.PaddingLayerParams.PaddingConstant
	221, // 220: CoreML.Specification.PaddingLayerParams.reflection:type_name -> CoreML.Specification.PaddingLayerParams.PaddingReflection
	222, // 221: CoreML.Specification.PaddingLayerParams.replication:type_name -> CoreML.Specification.PaddingLayerParams.PaddingReplication
	56,  // 222: CoreML.Specification.PaddingLayerParams.paddingAmounts:type_name -> CoreML.Specification.BorderAmounts
	11,  // 223: CoreML.Specification.UnaryFunctionLayerParams.type:type_name -> CoreML.Specification.UnaryFunctionLayerParams.Operation
	12,  // 224: CoreML.Specification.UpsampleLayerParams.mode:type_name -> CoreML.Specification.UpsampleLayerParams.InterpolationMode
	13,  // 225: CoreML.Specification.UpsampleLayerParams.linearUpsampleMode:type_name -> CoreML.Specification.UpsampleLayerParams.LinearUpsampleMode
	59,  // 226: CoreML.Specification.ResizeBilinearLayerParams.mode:type_name -> CoreML.Specification.SamplingMode
	59,  // 227: CoreML.Specification.CropResizeLayerParams.mode:type_name -> CoreML.Specification.SamplingMode
	60,  // 228: CoreML.Specification.CropResizeLayerParams.boxIndicesMode:type_name -> CoreML.Specification.BoxCoordinatesMode
	61,  // 229: CoreML.Specification.BiasLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 230: CoreML.Specification.ScaleLayerParams.scale:type_name -> CoreML.Specification.WeightParams
	61,  // 231: CoreML.Specification.ScaleLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 232: CoreML.Specification.LoadConstantLayerParams.data:type_name -> CoreML.Specification.WeightParams
	14,  // 233: CoreML.Specification.FlattenLayerParams.mode:type_name -> CoreML.Specification.FlattenLayerParams.FlattenOrder
	15,  // 234: CoreML.Specification.ReshapeLayerParams.mode:type_name -> CoreML.Specification.ReshapeLayerParams.ReshapeOrder
	16,  // 235: CoreML.Specification.ReorganizeDataLayerParams.mode:type_name -> CoreML.Specification.ReorganizeDataLayerParams.ReorganizationType
	17,  // 236: CoreML.Specification.SliceLayerParams.axis:type_name -> CoreML.Specification.SliceLayerParams.SliceAxis
	18,  // 237: CoreML.Specification.ReduceLayerParams.mode:type_name -> CoreML.Specification.ReduceLayerParams.ReduceOperation
	19,  // 238: CoreML.Specification.ReduceLayerParams.axis:type_name -> CoreML.Specification.ReduceLayerParams.ReduceAxis
	56,  // 239: CoreML.Specification.CropLayerParams.cropAmounts:type_name -> CoreML.Specification.BorderAmounts
	38,  // 240: CoreML.Specification.SimpleRecurrentLayerParams.activation:type_name -> CoreML.Specification.ActivationParams
	61,  // 241: CoreML.Specification.SimpleRecurrentLayerParams.weightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 242: CoreML.Specification.SimpleRecurrentLayerParams.recursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 243: CoreML.Specification.SimpleRecurrentLayerParams.biasVector:type_name -> CoreML.Specification.WeightParams
	38,  // 244: CoreML.Specification.GRULayerParams.activations:type_name -> CoreML.Specification.ActivationParams
	61,  // 245: CoreML.Specification.GRULayerParams.updateGateWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 246: CoreML.Specification.GRULayerParams.resetGateWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 247: CoreML.Specification.GRULayerParams.outputGateWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 248: CoreML.Specification.GRULayerParams.updateGateRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 249: CoreML.Specification.GRULayerParams.resetGateRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 250: CoreML.Specification.GRULayerParams.outputGateRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 251: CoreML.Specification.GRULayerParams.updateGateBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 252: CoreML.Specification.GRULayerParams.resetGateBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 253: CoreML.Specification.GRULayerParams.outputGateBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 254: CoreML.Specification.LSTMWeightParams.inputGateWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 255: CoreML.Specification.LSTMWeightParams.forgetGateWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 256: CoreML.Specification.LSTMWeightParams.blockInputWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 257: CoreML.Specification.LSTMWeightParams.outputGateWeightMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 258: CoreML.Specification.LSTMWeightParams.inputGateRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 259: CoreML.Specification.LSTMWeightParams.forgetGateRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 260: CoreML.Specification.LSTMWeightParams.blockInputRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 261: CoreML.Specification.LSTMWeightParams.outputGateRecursionMatrix:type_name -> CoreML.Specification.WeightParams
	61,  // 262: CoreML.Specification.LSTMWeightParams.inputGateBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 263: CoreML.Specification.LSTMWeightParams.forgetGateBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 264: CoreML.Specification.LSTMWeightParams.blockInputBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 265: CoreML.Specification.LSTMWeightParams.outputGateBiasVector:type_name -> CoreML.Specification.WeightParams
	61,  // 266: CoreML.Specification.LSTMWeightParams.inputGatePeepholeVector:type_name -> CoreML.Specification.WeightParams
	61,  // 267: CoreML.Specification.LSTMWeightParams.forgetGatePeepholeVector:type_name -> CoreML.Specification.WeightParams
	61,  // 268: CoreML.Specification.LSTMWeightParams.outputGatePeepholeVector:type_name -> CoreML.Specification.WeightParams
	38,  // 269: CoreML.Specification.UniDirectionalLSTMLayerParams.activations:type_name -> CoreML.Specification.ActivationParams
	104, // 270: CoreML.Specification.UniDirectionalLSTMLayerParams.params:type_name -> CoreML.Specification.LSTMParams
	105, // 271: CoreML.Specification.UniDirectionalLSTMLayerParams.weightParams:type_name -> CoreML.Specification.LSTMWeightParams
	38,  // 272: CoreML.Specification.BiDirectionalLSTMLayerParams.activationsForwardLSTM:type_name -> CoreML.Specification.ActivationParams
	38,  // 273: CoreML.Specification.BiDirectionalLSTMLayerParams.activationsBackwardLSTM:type_name -> CoreML.Specification.ActivationParams
	104, // 274: CoreML.Specification.BiDirectionalLSTMLayerParams.params:type_name -> CoreML.Specification.LSTMParams
	105, // 275: CoreML.Specification.BiDirectionalLSTMLayerParams.weightParams:type_name -> CoreML.Specification.LSTMWeightParams
	61,  // 276: CoreML.Specification.CustomLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	224, // 277: CoreML.Specification.CustomLayerParams.parameters:type_name -> CoreML.Specification.CustomLayerParams.ParametersEntry
	61,  // 278: CoreML.Specification.BatchedMatMulLayerParams.weights:type_name -> CoreML.Specification.WeightParams
	61,  // 279: CoreML.Specification.BatchedMatMulLayerParams.bias:type_name -> CoreML.Specification.WeightParams
	61,  // 280: CoreML.Specification.LoadConstantNDLayerParams.data:type_name -> CoreML.Specification.WeightParams
	2,   // 281: CoreML.Specification.ScatterLayerParams.mode:type_name -> CoreML.Specification.ScatterMode
	2,   // 282: CoreML.Specification.ScatterNDLayerParams.mode:type_name -> CoreML.Specification.ScatterMode
	2,   // 283: CoreML.Specification.ScatterAlongAxisLayerParams.mode:type_name -> CoreML.Specification.ScatterMode
	20,  // 284: CoreML.Specification.GeluLayerParams.mode:type_name -> CoreML.Specification.GeluLayerParams.GeluMode
	61,  // 285: CoreML.Specification.LayerNormalizationLayerParams.gamma:type_name -> CoreML.Specification.WeightParams
	61,  // 286: CoreML.Specification.LayerNormalizationLayerParams.beta:type_name -> CoreML.Specification.WeightParams
	40,  // 287: CoreML.Specification.NeuralNetworkClassifier.layers:type_name -> CoreML.Specification.NeuralNetworkLayer
	24,  // 288: CoreML.Specification.NeuralNetworkClassifier.preprocessing:type_name -> CoreML.Specification.NeuralNetworkPreprocessing
	0,   // 289: CoreML.Specification.NeuralNetworkClassifier.arrayInputShapeMapping:type_name -> CoreML.Specification.NeuralNetworkMultiArrayShapeMapping
	1,   // 290: CoreML.Specification.NeuralNetworkClassifier.imageInputShapeMapping:type_name -> CoreML.Specification.NeuralNetworkImageShapeMapping
	211, // 291: CoreML.Specification.NeuralNetworkClassifier.updateParams:type_name -> CoreML.Specification.NetworkUpdateParameters
	225, // 292: CoreML.Specification.NeuralNetworkClassifier.stringClassLabels:type_name -> CoreML.Specification.StringVector
	226, // 293: CoreML.Specification.NeuralNetworkClassifier.int64ClassLabels:type_name -> CoreML.Specification.Int64Vector
	40,  // 294: CoreML.Specification.NeuralNetworkRegressor.layers:type_name -> CoreML.Specification.NeuralNetworkLayer
	24,  // 295: CoreML.Specification.NeuralNetworkRegressor.preprocessing:type_name -> CoreML.Specification.NeuralNetworkPreprocessing
	0,   // 296: CoreML.Specification.NeuralNetworkRegressor.arrayInputShapeMapping:type_name -> CoreML.Specification.NeuralNetworkMultiArrayShapeMapping
	1,   // 297: CoreML.Specification.NeuralNetworkRegressor.imageInputShapeMapping:type_name -> CoreML.Specification.NeuralNetworkImageShapeMapping
	211, // 298: CoreML.Specification.NeuralNetworkRegressor.updateParams:type_name -> CoreML.Specification.NetworkUpdateParameters
	212, // 299: CoreML.Specification.NetworkUpdateParameters.lossLayers:type_name -> CoreML.Specification.LossLayer
	215, // 300: CoreML.Specification.NetworkUpdateParameters.optimizer:type_name -> CoreML.Specification.Optimizer
	227, // 301: CoreML.Specification.NetworkUpdateParameters.epochs:type_name -> CoreML.Specification.Int64Parameter
	228, // 302: CoreML.Specification.NetworkUpdateParameters.shuffle:type_name -> CoreML.Specification.BoolParameter
	227, // 303: CoreML.Specification.NetworkUpdateParameters.seed:type_name -> CoreML.Specification.Int64Parameter
	213, // 304: CoreML.Specification.LossLayer.categoricalCrossEntropyLossLayer:type_name -> CoreML.Specification.CategoricalCrossEntropyLossLayer
	214, // 305: CoreML.Specification.LossLayer.meanSquaredErrorLossLayer:type_name -> CoreML.Specification.MeanSquaredErrorLossLayer
	216, // 306: CoreML.Specification.Optimizer.sgdOptimizer:type_name -> CoreML.Specification.SGDOptimizer
	217, // 307: CoreML.Specification.Optimizer.adamOptimizer:type_name -> CoreML.Specification.AdamOptimizer
	229, // 308: CoreML.Specification.SGDOptimizer.learningRate:type_name -> CoreML.Specification.DoubleParameter
	227, // 309: CoreML.Specification.SGDOptimizer.miniBatchSize:type_name -> CoreML.Specification.Int64Parameter
	229, // 310: CoreML.Specification.SGDOptimizer.momentum:type_name -> CoreML.Specification.DoubleParameter
	229, // 311: CoreML.Specification.AdamOptimizer.learningRate:type_name -> CoreML.Specification.DoubleParameter
	227, // 312: CoreML.Specification.AdamOptimizer.miniBatchSize:type_name -> CoreML.Specification.Int64Parameter
	229, // 313: CoreML.Specification.AdamOptimizer.beta1:type_name -> CoreML.Specification.DoubleParameter
	229, // 314: CoreML.Specification.AdamOptimizer.beta2:type_name -> CoreML.Specification.DoubleParameter
	229, // 315: CoreML.Specification.AdamOptimizer.eps:type_name -> CoreML.Specification.DoubleParameter
	223, // 316: CoreML.Specification.CustomLayerParams.ParametersEntry.value:type_name -> CoreML.Specification.CustomLayerParams.CustomLayerParamValue
	317, // [317:317] is the sub-list for method output_type
	317, // [317:317] is the sub-list for method input_type
	317, // [317:317] is the sub-list for extension type_name
	317, // [317:317] is the sub-list for extension extendee
	0,   // [0:317] is the sub-list for field type_name
}

func init() { file_NeuralNetwork_proto_init() }
func file_NeuralNetwork_proto_init() {
	if File_NeuralNetwork_proto != nil {
		return
	}
	file_DataStructures_proto_init()
	file_Parameters_proto_init()
	file_NeuralNetwork_proto_msgTypes[3].OneofWrappers = []any{
		(*NeuralNetworkPreprocessing_Scaler)(nil),
		(*NeuralNetworkPreprocessing_MeanImage)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[17].OneofWrappers = []any{
		(*ActivationParams_Linear)(nil),
		(*ActivationParams_ReLU)(nil),
		(*ActivationParams_LeakyReLU)(nil),
		(*ActivationParams_ThresholdedReLU)(nil),
		(*ActivationParams_PReLU)(nil),
		(*ActivationParams_Tanh)(nil),
		(*ActivationParams_ScaledTanh)(nil),
		(*ActivationParams_Sigmoid)(nil),
		(*ActivationParams_SigmoidHard)(nil),
		(*ActivationParams_ELU)(nil),
		(*ActivationParams_Softsign)(nil),
		(*ActivationParams_Softplus)(nil),
		(*ActivationParams_ParametricSoftplus)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[19].OneofWrappers = []any{
		(*NeuralNetworkLayer_Convolution)(nil),
		(*NeuralNetworkLayer_Pooling)(nil),
		(*NeuralNetworkLayer_Activation)(nil),
		(*NeuralNetworkLayer_InnerProduct)(nil),
		(*NeuralNetworkLayer_Embedding)(nil),
		(*NeuralNetworkLayer_Batchnorm)(nil),
		(*NeuralNetworkLayer_Mvn)(nil),
		(*NeuralNetworkLayer_L2Normalize)(nil),
		(*NeuralNetworkLayer_Softmax)(nil),
		(*NeuralNetworkLayer_Lrn)(nil),
		(*NeuralNetworkLayer_Crop)(nil),
		(*NeuralNetworkLayer_Padding)(nil),
		(*NeuralNetworkLayer_Upsample)(nil),
		(*NeuralNetworkLayer_ResizeBilinear)(nil),
		(*NeuralNetworkLayer_CropResize)(nil),
		(*NeuralNetworkLayer_Unary)(nil),
		(*NeuralNetworkLayer_Add)(nil),
		(*NeuralNetworkLayer_Multiply)(nil),
		(*NeuralNetworkLayer_Average)(nil),
		(*NeuralNetworkLayer_Scale)(nil),
		(*NeuralNetworkLayer_Bias)(nil),
		(*NeuralNetworkLayer_Max)(nil),
		(*NeuralNetworkLayer_Min)(nil),
		(*NeuralNetworkLayer_Dot)(nil),
		(*NeuralNetworkLayer_Reduce)(nil),
		(*NeuralNetworkLayer_LoadConstant)(nil),
		(*NeuralNetworkLayer_Reshape)(nil),
		(*NeuralNetworkLayer_Flatten)(nil),
		(*NeuralNetworkLayer_Permute)(nil),
		(*NeuralNetworkLayer_Concat)(nil),
		(*NeuralNetworkLayer_Split)(nil),
		(*NeuralNetworkLayer_SequenceRepeat)(nil),
		(*NeuralNetworkLayer_ReorganizeData)(nil),
		(*NeuralNetworkLayer_Slice)(nil),
		(*NeuralNetworkLayer_SimpleRecurrent)(nil),
		(*NeuralNetworkLayer_Gru)(nil),
		(*NeuralNetworkLayer_UniDirectionalLSTM)(nil),
		(*NeuralNetworkLayer_BiDirectionalLSTM)(nil),
		(*NeuralNetworkLayer_Custom)(nil),
		(*NeuralNetworkLayer_Copy)(nil),
		(*NeuralNetworkLayer_Branch)(nil),
		(*NeuralNetworkLayer_Loop)(nil),
		(*NeuralNetworkLayer_LoopBreak)(nil),
		(*NeuralNetworkLayer_LoopContinue)(nil),
		(*NeuralNetworkLayer_RangeStatic)(nil),
		(*NeuralNetworkLayer_RangeDynamic)(nil),
		(*NeuralNetworkLayer_Clip)(nil),
		(*NeuralNetworkLayer_Ceil)(nil),
		(*NeuralNetworkLayer_Floor)(nil),
		(*NeuralNetworkLayer_Sign)(nil),
		(*NeuralNetworkLayer_Round)(nil),
		(*NeuralNetworkLayer_Exp2)(nil),
		(*NeuralNetworkLayer_Sin)(nil),
		(*NeuralNetworkLayer_Cos)(nil),
		(*NeuralNetworkLayer_Tan)(nil),
		(*NeuralNetworkLayer_Asin)(nil),
		(*NeuralNetworkLayer_Acos)(nil),
		(*NeuralNetworkLayer_Atan)(nil),
		(*NeuralNetworkLayer_Sinh)(nil),
		(*NeuralNetworkLayer_Cosh)(nil),
		(*NeuralNetworkLayer_Tanh)(nil),
		(*NeuralNetworkLayer_Asinh)(nil),
		(*NeuralNetworkLayer_Acosh)(nil),
		(*NeuralNetworkLayer_Atanh)(nil),
		(*NeuralNetworkLayer_Erf)(nil),
		(*NeuralNetworkLayer_Gelu)(nil),
		(*NeuralNetworkLayer_Equal)(nil),
		(*NeuralNetworkLayer_NotEqual)(nil),
		(*NeuralNetworkLayer_LessThan)(nil),
		(*NeuralNetworkLayer_LessEqual)(nil),
		(*NeuralNetworkLayer_GreaterThan)(nil),
		(*NeuralNetworkLayer_GreaterEqual)(nil),
		(*NeuralNetworkLayer_LogicalOr)(nil),
		(*NeuralNetworkLayer_LogicalXor)(nil),
		(*NeuralNetworkLayer_LogicalNot)(nil),
		(*NeuralNetworkLayer_LogicalAnd)(nil),
		(*NeuralNetworkLayer_ModBroadcastable)(nil),
		(*NeuralNetworkLayer_MinBroadcastable)(nil),
		(*NeuralNetworkLayer_MaxBroadcastable)(nil),
		(*NeuralNetworkLayer_AddBroadcastable)(nil),
		(*NeuralNetworkLayer_PowBroadcastable)(nil),
		(*NeuralNetworkLayer_DivideBroadcastable)(nil),
		(*NeuralNetworkLayer_FloorDivBroadcastable)(nil),
		(*NeuralNetworkLayer_MultiplyBroadcastable)(nil),
		(*NeuralNetworkLayer_SubtractBroadcastable)(nil),
		(*NeuralNetworkLayer_Tile)(nil),
		(*NeuralNetworkLayer_Stack)(nil),
		(*NeuralNetworkLayer_Gather)(nil),
		(*NeuralNetworkLayer_Scatter)(nil),
		(*NeuralNetworkLayer_GatherND)(nil),
		(*NeuralNetworkLayer_ScatterND)(nil),
		(*NeuralNetworkLayer_SoftmaxND)(nil),
		(*NeuralNetworkLayer_GatherAlongAxis)(nil),
		(*NeuralNetworkLayer_ScatterAlongAxis)(nil),
		(*NeuralNetworkLayer_Reverse)(nil),
		(*NeuralNetworkLayer_ReverseSeq)(nil),
		(*NeuralNetworkLayer_SplitND)(nil),
		(*NeuralNetworkLayer_ConcatND)(nil),
		(*NeuralNetworkLayer_Transpose)(nil),
		(*NeuralNetworkLayer_SliceStatic)(nil),
		(*NeuralNetworkLayer_SliceDynamic)(nil),
		(*NeuralNetworkLayer_SlidingWindows)(nil),
		(*NeuralNetworkLayer_TopK)(nil),
		(*NeuralNetworkLayer_ArgMin)(nil),
		(*NeuralNetworkLayer_ArgMax)(nil),
		(*NeuralNetworkLayer_EmbeddingND)(nil),
		(*NeuralNetworkLayer_BatchedMatmul)(nil),
		(*NeuralNetworkLayer_GetShape)(nil),
		(*NeuralNetworkLayer_LoadConstantND)(nil),
		(*NeuralNetworkLayer_FillLike)(nil),
		(*NeuralNetworkLayer_FillStatic)(nil),
		(*NeuralNetworkLayer_FillDynamic)(nil),
		(*NeuralNetworkLayer_BroadcastToLike)(nil),
		(*NeuralNetworkLayer_BroadcastToStatic)(nil),
		(*NeuralNetworkLayer_BroadcastToDynamic)(nil),
		(*NeuralNetworkLayer_Squeeze)(nil),
		(*NeuralNetworkLayer_ExpandDims)(nil),
		(*NeuralNetworkLayer_FlattenTo2D)(nil),
		(*NeuralNetworkLayer_ReshapeLike)(nil),
		(*NeuralNetworkLayer_ReshapeStatic)(nil),
		(*NeuralNetworkLayer_ReshapeDynamic)(nil),
		(*NeuralNetworkLayer_RankPreservingReshape)(nil),
		(*NeuralNetworkLayer_ConstantPad)(nil),
		(*NeuralNetworkLayer_RandomNormalLike)(nil),
		(*NeuralNetworkLayer_RandomNormalStatic)(nil),
		(*NeuralNetworkLayer_RandomNormalDynamic)(nil),
		(*NeuralNetworkLayer_RandomUniformLike)(nil),
		(*NeuralNetworkLayer_RandomUniformStatic)(nil),
		(*NeuralNetworkLayer_RandomUniformDynamic)(nil),
		(*NeuralNetworkLayer_RandomBernoulliLike)(nil),
		(*NeuralNetworkLayer_RandomBernoulliStatic)(nil),
		(*NeuralNetworkLayer_RandomBernoulliDynamic)(nil),
		(*NeuralNetworkLayer_CategoricalDistribution)(nil),
		(*NeuralNetworkLayer_ReduceL1)(nil),
		(*NeuralNetworkLayer_ReduceL2)(nil),
		(*NeuralNetworkLayer_ReduceMax)(nil),
		(*NeuralNetworkLayer_ReduceMin)(nil),
		(*NeuralNetworkLayer_ReduceSum)(nil),
		(*NeuralNetworkLayer_ReduceProd)(nil),
		(*NeuralNetworkLayer_ReduceMean)(nil),
		(*NeuralNetworkLayer_ReduceLogSum)(nil),
		(*NeuralNetworkLayer_ReduceSumSquare)(nil),
		(*NeuralNetworkLayer_ReduceLogSumExp)(nil),
		(*NeuralNetworkLayer_WhereNonZero)(nil),
		(*NeuralNetworkLayer_MatrixBandPart)(nil),
		(*NeuralNetworkLayer_LowerTriangular)(nil),
		(*NeuralNetworkLayer_UpperTriangular)(nil),
		(*NeuralNetworkLayer_WhereBroadcastable)(nil),
		(*NeuralNetworkLayer_LayerNormalization)(nil),
		(*NeuralNetworkLayer_NonMaximumSuppression)(nil),
		(*NeuralNetworkLayer_OneHot)(nil),
		(*NeuralNetworkLayer_CumSum)(nil),
		(*NeuralNetworkLayer_ClampedReLU)(nil),
		(*NeuralNetworkLayer_ArgSort)(nil),
		(*NeuralNetworkLayer_Pooling3D)(nil),
		(*NeuralNetworkLayer_GlobalPooling3D)(nil),
		(*NeuralNetworkLayer_SliceBySize)(nil),
		(*NeuralNetworkLayer_Convolution3D)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[41].OneofWrappers = []any{
		(*QuantizationParams_LinearQuantization)(nil),
		(*QuantizationParams_LookupTableQuantization)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[44].OneofWrappers = []any{
		(*ConvolutionLayerParams_Valid)(nil),
		(*ConvolutionLayerParams_Same)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[50].OneofWrappers = []any{
		(*PoolingLayerParams_Valid)(nil),
		(*PoolingLayerParams_Same)(nil),
		(*PoolingLayerParams_IncludeLastPixel)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[53].OneofWrappers = []any{
		(*PaddingLayerParams_Constant)(nil),
		(*PaddingLayerParams_Reflection)(nil),
		(*PaddingLayerParams_Replication)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[186].OneofWrappers = []any{
		(*NeuralNetworkClassifier_StringClassLabels)(nil),
		(*NeuralNetworkClassifier_Int64ClassLabels)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[191].OneofWrappers = []any{
		(*LossLayer_CategoricalCrossEntropyLossLayer)(nil),
		(*LossLayer_MeanSquaredErrorLossLayer)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[194].OneofWrappers = []any{
		(*Optimizer_SgdOptimizer)(nil),
		(*Optimizer_AdamOptimizer)(nil),
	}
	file_NeuralNetwork_proto_msgTypes[202].OneofWrappers = []any{
		(*CustomLayerParams_CustomLayerParamValue_DoubleValue)(nil),
		(*CustomLayerParams_CustomLayerParamValue_StringValue)(nil),
		(*CustomLayerParams_CustomLayerParamValue_IntValue)(nil),
		(*CustomLayerParams_CustomLayerParamValue_LongValue)(nil),
		(*CustomLayerParams_CustomLayerParamValue_BoolValue)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_NeuralNetwork_proto_rawDesc), len(file_NeuralNetwork_proto_rawDesc)),
			NumEnums:      21,
			NumMessages:   204,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_NeuralNetwork_proto_goTypes,
		DependencyIndexes: file_NeuralNetwork_proto_depIdxs,
		EnumInfos:         file_NeuralNetwork_proto_enumTypes,
		MessageInfos:      file_NeuralNetwork_proto_msgTypes,
	}.Build()
	File_NeuralNetwork_proto = out.File
	file_NeuralNetwork_proto_goTypes = nil
	file_NeuralNetwork_proto_depIdxs = nil
}
